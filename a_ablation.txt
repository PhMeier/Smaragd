Matplotlib created a temporary config/cache directory at /tmp/matplotlib-426d3asb because the default path (/home/students/meier/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
2022-01-19 23:40:51,432 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2022-01-19 23:40:51,517 - INFO - joeynmt.data - Loading training data...
2022-01-19 23:41:23,845 - INFO - joeynmt.data - Building vocabulary...
2022-01-19 23:41:32,222 - INFO - joeynmt.data - Loading dev data...
2022-01-19 23:41:34,402 - INFO - joeynmt.data - Loading test data...
2022-01-19 23:41:34,468 - INFO - joeynmt.data - Data loaded.
2022-01-19 23:41:34,468 - INFO - joeynmt.model - Building an encoder-decoder model...
2022-01-19 23:41:34,942 - INFO - joeynmt.model - Enc-dec model built.
2022-01-19 23:41:34,951 - INFO - joeynmt.training - Total params: 29898752
2022-01-19 23:41:34,952 - WARNING - joeynmt.training - `keep_last_ckpts` option is outdated. Please use `keep_best_ckpts`, instead.
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.name                           : amr_Transformer_short_800_A
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.data.src                       : src
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.data.trg                       : tgt
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.data.train                     : ~/AMR_ablation/data/A_data/train/a_train
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.data.dev                       : ~/AMR_ablation/data/A_data/dev/a_dev
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.data.test                      : ~/AMR_ablation/data/A_data/test/a_test
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.data.level                     : word
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 800
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]
2022-01-19 23:41:38,259 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0002
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 2
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 5000
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.batch_size            : 8192
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.batch_type            : token
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.epochs                : 30
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/a_model
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2]
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 1
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : False
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 4
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 4
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.0
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.1
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 4
2022-01-19 23:41:38,260 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 4
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.0
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.1
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - Data set sizes: 
	train 542230,
	valid 34999,
	test 1500
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - First training example:
	[SRC] ( 28 / 5 :8 ( 10 / 30 :14 ( 29 / 21 ) :26 ( 9 / 13 :12 ( 22 / 12 :8 23 ) :18 17 :27 1 ) ) :0 ( 17 / 15 :14 29 ) ) SEP ( 24 / 5 :8 ( 19 / 30 :14 ( 7 / 21 ) :26 ( 3 / 2 :12 ( 4 / 12 :8 23 ) :27 1 ) ) :0 ( 25 / 15 :14 7 :26 3 ) )
	[TRG] 28 24 | 10 19 | 29 7 | 9 3 | 22 4 | 17 25
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ( (5) ) (6) / (7) 0 (8) 4 (9) 5
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) | (5) None (6) 2 (7) 3 (8) 4 (9) 0
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - Number of Src words (types): 685
2022-01-19 23:41:38,261 - INFO - joeynmt.helpers - Number of Trg words (types): 235
2022-01-19 23:41:38,261 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=4),
	decoder=TransformerDecoder(num_layers=4, num_heads=4),
	src_embed=Embeddings(embedding_dim=512, vocab_size=685),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=235))
2022-01-19 23:41:38,267 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 8192
	total batch size (w. parallel & accumulation): 8192
2022-01-19 23:41:38,267 - INFO - joeynmt.training - EPOCH 1
2022-01-19 23:41:57,079 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:    93.445351, Tokens per Sec:     3590, Lr: 0.000200
2022-01-19 23:42:15,572 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:    91.897530, Tokens per Sec:     3633, Lr: 0.000200
2022-01-19 23:42:34,149 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:   107.841461, Tokens per Sec:     3660, Lr: 0.000200
2022-01-19 23:42:52,466 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:    91.905113, Tokens per Sec:     3616, Lr: 0.000200
2022-01-19 23:43:11,038 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:    98.616936, Tokens per Sec:     3701, Lr: 0.000200
2022-01-19 23:43:29,764 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:   109.501427, Tokens per Sec:     3644, Lr: 0.000200
2022-01-19 23:43:48,414 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:    79.599785, Tokens per Sec:     3721, Lr: 0.000200
2022-01-19 23:44:07,554 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:    71.078011, Tokens per Sec:     3570, Lr: 0.000200
2022-01-19 23:44:26,068 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:    83.694405, Tokens per Sec:     3611, Lr: 0.000200
2022-01-19 23:44:44,855 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:    60.484898, Tokens per Sec:     3697, Lr: 0.000200
2022-01-20 00:10:15,928 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 00:10:48,747 - INFO - joeynmt.training - Example #0
2022-01-20 00:10:48,747 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 00:10:48,747 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 00:10:48,747 - INFO - joeynmt.training - 	Hypothesis: 18 None | 5 None | 5 None | 8 None | 18 None | 18 None | 29 None | 29 None | 5 None | 29 None | 5 None
2022-01-20 00:10:48,747 - INFO - joeynmt.training - Example #1
2022-01-20 00:10:48,747 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 00:10:48,747 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 00:10:48,748 - INFO - joeynmt.training - 	Hypothesis: 18 None | 5 None | 29 None | 18 None | 29 None | 18 None | 5 None | 29 None | 5 None | 29 None | 5 None
2022-01-20 00:10:48,748 - INFO - joeynmt.training - Example #2
2022-01-20 00:10:48,748 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 00:10:48,748 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 00:10:48,748 - INFO - joeynmt.training - 	Hypothesis: 18 None | 5 None | 29 None | 18 None | 29 None | 18 None | 5 None | 29 None | 5 None | 29 None | 5 None
2022-01-20 00:10:48,749 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     1000: bleu:   1.29, loss: 4293219.5000, ppl:  14.3877, duration: 1563.8932s
2022-01-20 00:11:07,621 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:    82.743057, Tokens per Sec:     3667, Lr: 0.000200
2022-01-20 00:11:26,006 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:    92.815147, Tokens per Sec:     3567, Lr: 0.000200
2022-01-20 00:11:44,194 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:    94.023087, Tokens per Sec:     3813, Lr: 0.000200
2022-01-20 00:12:02,735 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:    67.974243, Tokens per Sec:     3677, Lr: 0.000200
2022-01-20 00:12:21,418 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:    78.690468, Tokens per Sec:     3620, Lr: 0.000200
2022-01-20 00:12:39,757 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:   108.114319, Tokens per Sec:     3710, Lr: 0.000200
2022-01-20 00:12:58,125 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:    80.384094, Tokens per Sec:     3782, Lr: 0.000200
2022-01-20 00:13:16,194 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:    92.453255, Tokens per Sec:     3624, Lr: 0.000200
2022-01-20 00:13:34,643 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:    84.600166, Tokens per Sec:     3763, Lr: 0.000200
2022-01-20 00:13:53,172 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:    84.719032, Tokens per Sec:     3641, Lr: 0.000200
2022-01-20 00:38:39,825 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 00:39:12,522 - INFO - joeynmt.helpers - delete models/a_model/1000.ckpt
2022-01-20 00:39:12,604 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/1000.ckpt
2022-01-20 00:39:12,605 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/1000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/1000.ckpt')
2022-01-20 00:39:12,692 - INFO - joeynmt.training - Example #0
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Hypothesis: 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None
2022-01-20 00:39:12,693 - INFO - joeynmt.training - Example #1
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Hypothesis: 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 34 None | 34 None | 34 None
2022-01-20 00:39:12,693 - INFO - joeynmt.training - Example #2
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 00:39:12,693 - INFO - joeynmt.training - 	Hypothesis: 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 13 None | 34 None | 34 None | 34 None
2022-01-20 00:39:12,694 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     2000: bleu:   1.41, loss: 4210487.5000, ppl:  13.6671, duration: 1519.5214s
2022-01-20 00:39:31,689 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:    96.552536, Tokens per Sec:     3594, Lr: 0.000200
2022-01-20 00:39:50,106 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:    59.320210, Tokens per Sec:     3762, Lr: 0.000200
2022-01-20 00:40:08,492 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:    62.258293, Tokens per Sec:     3617, Lr: 0.000200
2022-01-20 00:40:26,802 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:    92.425758, Tokens per Sec:     3598, Lr: 0.000200
2022-01-20 00:40:45,184 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:    97.266869, Tokens per Sec:     3839, Lr: 0.000200
2022-01-20 00:41:03,557 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:    79.492569, Tokens per Sec:     3658, Lr: 0.000200
2022-01-20 00:41:22,109 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:    95.123253, Tokens per Sec:     3613, Lr: 0.000200
2022-01-20 00:41:40,769 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:    75.231468, Tokens per Sec:     3610, Lr: 0.000200
2022-01-20 00:41:59,119 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:    84.825806, Tokens per Sec:     3647, Lr: 0.000200
2022-01-20 00:42:17,587 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:    89.914757, Tokens per Sec:     3676, Lr: 0.000200
2022-01-20 01:04:52,076 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 01:05:24,776 - INFO - joeynmt.helpers - delete models/a_model/2000.ckpt
2022-01-20 01:05:24,861 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/2000.ckpt
2022-01-20 01:05:24,861 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/2000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/2000.ckpt')
2022-01-20 01:05:24,950 - INFO - joeynmt.training - Example #0
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Hypothesis: 32 None | 32 None | 32 None | 32 None | 32 None | 32 None | 32 None | 32 None | 32 None
2022-01-20 01:05:24,951 - INFO - joeynmt.training - Example #1
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Hypothesis: 32 None | 35 35 | 32 None | 35 None | 32 None | 32 None | 32 None | 32 None | 32 None | 31 None
2022-01-20 01:05:24,951 - INFO - joeynmt.training - Example #2
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 01:05:24,951 - INFO - joeynmt.training - 	Hypothesis: 32 None | 35 35 | 35 None | 35 None | 35 None | 32 None | 32 None | 32 None | 32 None
2022-01-20 01:05:24,952 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     3000: bleu:   1.46, loss: 4135375.7500, ppl:  13.0441, duration: 1387.3642s
2022-01-20 01:05:43,734 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:   112.126801, Tokens per Sec:     3507, Lr: 0.000200
2022-01-20 01:06:02,260 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:    72.738113, Tokens per Sec:     3568, Lr: 0.000200
2022-01-20 01:06:20,480 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:   114.270149, Tokens per Sec:     3602, Lr: 0.000200
2022-01-20 01:06:38,938 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:    77.144684, Tokens per Sec:     3640, Lr: 0.000200
2022-01-20 01:06:57,537 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:    69.612846, Tokens per Sec:     3713, Lr: 0.000200
2022-01-20 01:07:15,997 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:    81.923691, Tokens per Sec:     3649, Lr: 0.000200
2022-01-20 01:07:34,444 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:    91.649490, Tokens per Sec:     3757, Lr: 0.000200
2022-01-20 01:07:52,758 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:    55.290581, Tokens per Sec:     3711, Lr: 0.000200
2022-01-20 01:08:11,303 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:    87.990074, Tokens per Sec:     3526, Lr: 0.000200
2022-01-20 01:08:29,782 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:    62.456142, Tokens per Sec:     3709, Lr: 0.000200
2022-01-20 01:32:43,356 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 01:33:16,106 - INFO - joeynmt.helpers - delete models/a_model/3000.ckpt
2022-01-20 01:33:16,191 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/3000.ckpt
2022-01-20 01:33:16,192 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/3000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/3000.ckpt')
2022-01-20 01:33:16,389 - INFO - joeynmt.training - Example #0
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Hypothesis: 34 None | 32 None | 36 None | 36 None | 36 None | 36 None | 36 None | 36 None | 36 None | 36 None
2022-01-20 01:33:16,389 - INFO - joeynmt.training - Example #1
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Hypothesis: 40 None | 26 None | 28 None | 27 None | 28 None | 27 None | 39 39 | 27 None | 39 None | 29 None | 1 None
2022-01-20 01:33:16,389 - INFO - joeynmt.training - Example #2
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 01:33:16,389 - INFO - joeynmt.training - 	Hypothesis: 37 None | 2 None | 35 None | 35 None | 4 None | 35 None | 35 None | 29 None | 39 None | 27 None
2022-01-20 01:33:16,390 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     4000: bleu:   2.83, loss: 3937604.5000, ppl:  11.5364, duration: 1486.6074s
2022-01-20 01:33:34,945 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:   109.592560, Tokens per Sec:     3597, Lr: 0.000200
2022-01-20 01:33:53,346 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:    89.051338, Tokens per Sec:     3721, Lr: 0.000200
2022-01-20 01:34:11,691 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:    83.292610, Tokens per Sec:     3696, Lr: 0.000200
2022-01-20 01:34:29,945 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:    58.888557, Tokens per Sec:     3696, Lr: 0.000200
2022-01-20 01:34:47,993 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:    89.800270, Tokens per Sec:     3715, Lr: 0.000200
2022-01-20 01:35:06,115 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:    91.497604, Tokens per Sec:     3772, Lr: 0.000200
2022-01-20 01:35:24,415 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:    49.846756, Tokens per Sec:     3680, Lr: 0.000200
2022-01-20 01:35:42,927 - INFO - joeynmt.training - Epoch   1, Step:     4800, Batch Loss:    82.907578, Tokens per Sec:     3581, Lr: 0.000200
2022-01-20 01:36:01,609 - INFO - joeynmt.training - Epoch   1, Step:     4900, Batch Loss:    73.271118, Tokens per Sec:     3563, Lr: 0.000200
2022-01-20 01:36:20,004 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:    94.560371, Tokens per Sec:     3823, Lr: 0.000200
2022-01-20 01:58:16,521 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 01:58:49,298 - INFO - joeynmt.helpers - delete models/a_model/4000.ckpt
2022-01-20 01:58:49,379 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/4000.ckpt
2022-01-20 01:58:49,380 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/4000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/4000.ckpt')
2022-01-20 01:58:49,484 - INFO - joeynmt.training - Example #0
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Hypothesis: 34 None | 32 None | 31 None | 35 None | 28 None | 28 None | 25 None | 25 None | 33 None
2022-01-20 01:58:49,485 - INFO - joeynmt.training - Example #1
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Hypothesis: 40 None | 26 None | 37 None | 9 None | 25 None | 33 None | 33 None | 35 None | 23 None
2022-01-20 01:58:49,485 - INFO - joeynmt.training - Example #2
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 01:58:49,485 - INFO - joeynmt.training - 	Hypothesis: 37 None | 2 None | 10 None | 23 None | 19 None | 0 None | 22 None | 0 None | 35 None
2022-01-20 01:58:49,486 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     5000: bleu:   6.08, loss: 3646628.2500, ppl:   9.6292, duration: 1349.4821s
2022-01-20 01:59:08,764 - INFO - joeynmt.training - Epoch   1, Step:     5100, Batch Loss:    60.042927, Tokens per Sec:     3463, Lr: 0.000200
2022-01-20 01:59:27,193 - INFO - joeynmt.training - Epoch   1, Step:     5200, Batch Loss:    59.192127, Tokens per Sec:     3625, Lr: 0.000200
2022-01-20 01:59:45,572 - INFO - joeynmt.training - Epoch   1, Step:     5300, Batch Loss:    80.247551, Tokens per Sec:     3742, Lr: 0.000200
2022-01-20 02:00:04,076 - INFO - joeynmt.training - Epoch   1, Step:     5400, Batch Loss:    73.935066, Tokens per Sec:     3573, Lr: 0.000200
2022-01-20 02:00:22,617 - INFO - joeynmt.training - Epoch   1, Step:     5500, Batch Loss:    70.196136, Tokens per Sec:     3540, Lr: 0.000200
2022-01-20 02:00:40,998 - INFO - joeynmt.training - Epoch   1, Step:     5600, Batch Loss:    58.337257, Tokens per Sec:     3674, Lr: 0.000200
2022-01-20 02:00:59,313 - INFO - joeynmt.training - Epoch   1, Step:     5700, Batch Loss:    76.321190, Tokens per Sec:     3591, Lr: 0.000200
2022-01-20 02:01:17,618 - INFO - joeynmt.training - Epoch   1, Step:     5800, Batch Loss:    61.341633, Tokens per Sec:     3805, Lr: 0.000200
2022-01-20 02:01:35,825 - INFO - joeynmt.training - Epoch   1, Step:     5900, Batch Loss:    58.585060, Tokens per Sec:     3720, Lr: 0.000200
2022-01-20 02:01:54,492 - INFO - joeynmt.training - Epoch   1, Step:     6000, Batch Loss:    74.963852, Tokens per Sec:     3704, Lr: 0.000200
2022-01-20 02:25:22,793 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 02:25:55,516 - INFO - joeynmt.helpers - delete models/a_model/5000.ckpt
2022-01-20 02:25:55,596 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/5000.ckpt
2022-01-20 02:25:55,597 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/5000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/5000.ckpt')
2022-01-20 02:25:55,639 - INFO - joeynmt.training - Example #0
2022-01-20 02:25:55,639 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 02:25:55,639 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 02:25:55,639 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 24 | 31 17 | 35 None | 2 17 | 38 38 | 37 17 | 8 None | 33 None | 33 None
2022-01-20 02:25:55,639 - INFO - joeynmt.training - Example #1
2022-01-20 02:25:55,639 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 02:25:55,639 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 02:25:55,639 - INFO - joeynmt.training - 	Hypothesis: 40 0 | 26 18 | 37 18 | 9 18 | 21 18 | 27 18 | 33 18 | 33 18 | 23 18 | 23 None
2022-01-20 02:25:55,639 - INFO - joeynmt.training - Example #2
2022-01-20 02:25:55,640 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 02:25:55,640 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 02:25:55,640 - INFO - joeynmt.training - 	Hypothesis: 37 14 | 2 14 | 10 7 | 23 25 | 9 12 | 36 33 | 32 33 | 0 33 | 30 33
2022-01-20 02:25:55,641 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     6000: bleu:  12.85, loss: 3217627.0000, ppl:   7.3769, duration: 1441.1477s
2022-01-20 02:26:14,135 - INFO - joeynmt.training - Epoch   1, Step:     6100, Batch Loss:    61.067802, Tokens per Sec:     3635, Lr: 0.000200
2022-01-20 02:26:32,313 - INFO - joeynmt.training - Epoch   1, Step:     6200, Batch Loss:    68.133354, Tokens per Sec:     3813, Lr: 0.000200
2022-01-20 02:26:50,367 - INFO - joeynmt.training - Epoch   1, Step:     6300, Batch Loss:    57.076866, Tokens per Sec:     3805, Lr: 0.000200
2022-01-20 02:27:08,333 - INFO - joeynmt.training - Epoch   1, Step:     6400, Batch Loss:    72.054260, Tokens per Sec:     3800, Lr: 0.000200
2022-01-20 02:27:26,355 - INFO - joeynmt.training - Epoch   1, Step:     6500, Batch Loss:    49.332630, Tokens per Sec:     3800, Lr: 0.000200
2022-01-20 02:27:44,553 - INFO - joeynmt.training - Epoch   1, Step:     6600, Batch Loss:    59.852436, Tokens per Sec:     3711, Lr: 0.000200
2022-01-20 02:28:02,626 - INFO - joeynmt.training - Epoch   1, Step:     6700, Batch Loss:    37.895012, Tokens per Sec:     3731, Lr: 0.000200
2022-01-20 02:28:20,802 - INFO - joeynmt.training - Epoch   1, Step:     6800, Batch Loss:    51.894989, Tokens per Sec:     3715, Lr: 0.000200
2022-01-20 02:28:39,227 - INFO - joeynmt.training - Epoch   1, Step:     6900, Batch Loss:    93.091797, Tokens per Sec:     3636, Lr: 0.000200
2022-01-20 02:28:57,454 - INFO - joeynmt.training - Epoch   1, Step:     7000, Batch Loss:    33.448311, Tokens per Sec:     3691, Lr: 0.000200
2022-01-20 02:51:25,481 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 02:51:58,219 - INFO - joeynmt.helpers - delete models/a_model/6000.ckpt
2022-01-20 02:51:58,305 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/6000.ckpt
2022-01-20 02:51:58,306 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/6000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/6000.ckpt')
2022-01-20 02:51:58,403 - INFO - joeynmt.training - Example #0
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 36 | 31 19 | 35 30 | 2 7 | 25 30 | 37 13 | 8 5 | 33 13 | 33 17
2022-01-20 02:51:58,404 - INFO - joeynmt.training - Example #1
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 18 | 9 0 | 21 10 | 38 8 | 33 34 | 35 34 | 23 34
2022-01-20 02:51:58,404 - INFO - joeynmt.training - Example #2
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 02:51:58,404 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 27 | 23 14 | 9 27 | 32 27 | 0 27 | 18 5 | 30 27
2022-01-20 02:51:58,405 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     7000: bleu:  16.28, loss: 2948511.5000, ppl:   6.2415, duration: 1380.9508s
2022-01-20 02:52:17,226 - INFO - joeynmt.training - Epoch   1, Step:     7100, Batch Loss:    40.832829, Tokens per Sec:     3500, Lr: 0.000200
2022-01-20 02:52:35,969 - INFO - joeynmt.training - Epoch   1, Step:     7200, Batch Loss:    67.812691, Tokens per Sec:     3594, Lr: 0.000200
2022-01-20 02:52:54,510 - INFO - joeynmt.training - Epoch   1, Step:     7300, Batch Loss:    38.769901, Tokens per Sec:     3641, Lr: 0.000200
2022-01-20 02:53:12,909 - INFO - joeynmt.training - Epoch   1, Step:     7400, Batch Loss:    52.474255, Tokens per Sec:     3733, Lr: 0.000200
2022-01-20 02:53:31,639 - INFO - joeynmt.training - Epoch   1, Step:     7500, Batch Loss:    50.881336, Tokens per Sec:     3569, Lr: 0.000200
2022-01-20 02:53:50,417 - INFO - joeynmt.training - Epoch   1, Step:     7600, Batch Loss:    29.862211, Tokens per Sec:     3629, Lr: 0.000200
2022-01-20 02:54:09,176 - INFO - joeynmt.training - Epoch   1, Step:     7700, Batch Loss:    34.866978, Tokens per Sec:     3508, Lr: 0.000200
2022-01-20 02:54:27,901 - INFO - joeynmt.training - Epoch   1, Step:     7800, Batch Loss:    46.017448, Tokens per Sec:     3574, Lr: 0.000200
2022-01-20 02:54:46,630 - INFO - joeynmt.training - Epoch   1, Step:     7900, Batch Loss:    52.040630, Tokens per Sec:     3722, Lr: 0.000200
2022-01-20 02:55:05,486 - INFO - joeynmt.training - Epoch   1, Step:     8000, Batch Loss:    47.509834, Tokens per Sec:     3440, Lr: 0.000200
2022-01-20 03:17:34,161 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 03:18:06,948 - INFO - joeynmt.helpers - delete models/a_model/7000.ckpt
2022-01-20 03:18:07,038 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/7000.ckpt
2022-01-20 03:18:07,039 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/7000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/7000.ckpt')
2022-01-20 03:18:07,141 - INFO - joeynmt.training - Example #0
2022-01-20 03:18:07,141 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 03:18:07,142 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 03:18:07,142 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 30 | 35 13 | 2 5 | 25 13 | 37 7 | 8 17 | 33 13
2022-01-20 03:18:07,142 - INFO - joeynmt.training - Example #1
2022-01-20 03:18:07,142 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 03:18:07,142 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 03:18:07,142 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 15 | 38 8 | 33 34 | 35 15 | 23 34
2022-01-20 03:18:07,142 - INFO - joeynmt.training - Example #2
2022-01-20 03:18:07,142 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 03:18:07,142 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 03:18:07,142 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 27 | 23 5 | 9 25 | 32 6 | 0 33 | 18 33 | 30 6
2022-01-20 03:18:07,143 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     8000: bleu:  18.79, loss: 2752187.7500, ppl:   5.5250, duration: 1381.6561s
2022-01-20 03:18:26,399 - INFO - joeynmt.training - Epoch   1, Step:     8100, Batch Loss:    43.298096, Tokens per Sec:     3411, Lr: 0.000200
2022-01-20 03:18:45,245 - INFO - joeynmt.training - Epoch   1, Step:     8200, Batch Loss:    47.680401, Tokens per Sec:     3697, Lr: 0.000200
2022-01-20 03:19:04,003 - INFO - joeynmt.training - Epoch   1, Step:     8300, Batch Loss:    42.444447, Tokens per Sec:     3568, Lr: 0.000200
2022-01-20 03:19:23,034 - INFO - joeynmt.training - Epoch   1, Step:     8400, Batch Loss:    41.312435, Tokens per Sec:     3570, Lr: 0.000200
2022-01-20 03:19:41,878 - INFO - joeynmt.training - Epoch   1, Step:     8500, Batch Loss:    43.552299, Tokens per Sec:     3661, Lr: 0.000200
2022-01-20 03:20:00,577 - INFO - joeynmt.training - Epoch   1, Step:     8600, Batch Loss:    39.573364, Tokens per Sec:     3675, Lr: 0.000200
2022-01-20 03:20:19,700 - INFO - joeynmt.training - Epoch   1, Step:     8700, Batch Loss:    49.450207, Tokens per Sec:     3544, Lr: 0.000200
2022-01-20 03:20:38,551 - INFO - joeynmt.training - Epoch   1, Step:     8800, Batch Loss:    34.730953, Tokens per Sec:     3698, Lr: 0.000200
2022-01-20 03:20:57,172 - INFO - joeynmt.training - Epoch   1, Step:     8900, Batch Loss:    25.238626, Tokens per Sec:     3652, Lr: 0.000200
2022-01-20 03:21:15,899 - INFO - joeynmt.training - Epoch   1, Step:     9000, Batch Loss:    62.643242, Tokens per Sec:     3581, Lr: 0.000200
2022-01-20 03:43:44,581 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 03:44:17,350 - INFO - joeynmt.helpers - delete models/a_model/8000.ckpt
2022-01-20 03:44:17,450 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/8000.ckpt
2022-01-20 03:44:17,451 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/8000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/8000.ckpt')
2022-01-20 03:44:17,487 - INFO - joeynmt.training - Example #0
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 36 | 25 7 | 37 17 | 8 13 | 33 12
2022-01-20 03:44:17,488 - INFO - joeynmt.training - Example #1
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 18 | 9 15 | 21 7 | 38 3 | 33 8 | 35 7 | 23 7
2022-01-20 03:44:17,488 - INFO - joeynmt.training - Example #2
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 03:44:17,488 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 6 | 32 5 | 0 7 | 18 28 | 30 25
2022-01-20 03:44:17,489 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     9000: bleu:  20.72, loss: 2561501.5000, ppl:   4.9080, duration: 1381.5896s
2022-01-20 03:44:36,535 - INFO - joeynmt.training - Epoch   1, Step:     9100, Batch Loss:    36.822960, Tokens per Sec:     3707, Lr: 0.000200
2022-01-20 03:44:55,231 - INFO - joeynmt.training - Epoch   1, Step:     9200, Batch Loss:    29.383125, Tokens per Sec:     3618, Lr: 0.000200
2022-01-20 03:45:13,704 - INFO - joeynmt.training - Epoch   1, Step:     9300, Batch Loss:    47.223858, Tokens per Sec:     3615, Lr: 0.000200
2022-01-20 03:45:32,242 - INFO - joeynmt.training - Epoch   1, Step:     9400, Batch Loss:    49.964508, Tokens per Sec:     3561, Lr: 0.000200
2022-01-20 03:45:50,864 - INFO - joeynmt.training - Epoch   1, Step:     9500, Batch Loss:    28.946442, Tokens per Sec:     3518, Lr: 0.000200
2022-01-20 03:46:09,500 - INFO - joeynmt.training - Epoch   1, Step:     9600, Batch Loss:    60.086941, Tokens per Sec:     3633, Lr: 0.000200
2022-01-20 03:46:28,032 - INFO - joeynmt.training - Epoch   1, Step:     9700, Batch Loss:    35.875206, Tokens per Sec:     3635, Lr: 0.000200
2022-01-20 03:46:46,640 - INFO - joeynmt.training - Epoch   1, Step:     9800, Batch Loss:    44.512032, Tokens per Sec:     3758, Lr: 0.000200
2022-01-20 03:47:05,077 - INFO - joeynmt.training - Epoch   1, Step:     9900, Batch Loss:    66.473999, Tokens per Sec:     3646, Lr: 0.000200
2022-01-20 03:47:23,393 - INFO - joeynmt.training - Epoch   1, Step:    10000, Batch Loss:    39.000595, Tokens per Sec:     3612, Lr: 0.000200
2022-01-20 04:09:51,940 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 04:10:24,540 - INFO - joeynmt.helpers - delete models/a_model/9000.ckpt
2022-01-20 04:10:24,620 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/9000.ckpt
2022-01-20 04:10:24,621 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/9000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/9000.ckpt')
2022-01-20 04:10:24,710 - INFO - joeynmt.training - Example #0
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 12 | 33 13
2022-01-20 04:10:24,710 - INFO - joeynmt.training - Example #1
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 34
2022-01-20 04:10:24,710 - INFO - joeynmt.training - Example #2
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 04:10:24,710 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 28 | 9 25 | 32 6 | 0 33 | 18 5 | 30 27
2022-01-20 04:10:24,711 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    10000: bleu:  22.88, loss: 2420365.2500, ppl:   4.4961, duration: 1381.3184s
2022-01-20 04:10:43,722 - INFO - joeynmt.training - Epoch   1, Step:    10100, Batch Loss:    32.107883, Tokens per Sec:     3535, Lr: 0.000200
2022-01-20 04:11:02,535 - INFO - joeynmt.training - Epoch   1, Step:    10200, Batch Loss:    45.645901, Tokens per Sec:     3602, Lr: 0.000200
2022-01-20 04:11:21,139 - INFO - joeynmt.training - Epoch   1, Step:    10300, Batch Loss:    39.634075, Tokens per Sec:     3578, Lr: 0.000200
2022-01-20 04:11:39,758 - INFO - joeynmt.training - Epoch   1, Step:    10400, Batch Loss:    42.860912, Tokens per Sec:     3716, Lr: 0.000200
2022-01-20 04:11:58,291 - INFO - joeynmt.training - Epoch   1, Step:    10500, Batch Loss:    83.980606, Tokens per Sec:     3610, Lr: 0.000200
2022-01-20 04:12:16,610 - INFO - joeynmt.training - Epoch   1, Step:    10600, Batch Loss:    51.821297, Tokens per Sec:     3688, Lr: 0.000200
2022-01-20 04:12:34,980 - INFO - joeynmt.training - Epoch   1, Step:    10700, Batch Loss:    36.576805, Tokens per Sec:     3505, Lr: 0.000200
2022-01-20 04:12:53,522 - INFO - joeynmt.training - Epoch   1, Step:    10800, Batch Loss:    37.707287, Tokens per Sec:     3707, Lr: 0.000200
2022-01-20 04:13:11,955 - INFO - joeynmt.training - Epoch   1, Step:    10900, Batch Loss:    28.602713, Tokens per Sec:     3780, Lr: 0.000200
2022-01-20 04:13:30,700 - INFO - joeynmt.training - Epoch   1, Step:    11000, Batch Loss:    27.557030, Tokens per Sec:     3651, Lr: 0.000200
2022-01-20 04:36:17,268 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 04:36:50,012 - INFO - joeynmt.helpers - delete models/a_model/10000.ckpt
2022-01-20 04:36:50,086 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/10000.ckpt
2022-01-20 04:36:50,086 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/10000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/10000.ckpt')
2022-01-20 04:36:50,129 - INFO - joeynmt.training - Example #0
2022-01-20 04:36:50,129 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 04:36:50,129 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 04:36:50,129 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 04:36:50,129 - INFO - joeynmt.training - Example #1
2022-01-20 04:36:50,129 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 04:36:50,129 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 04:36:50,130 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 18 | 9 0 | 21 3 | 38 8 | 33 7 | 35 34 | 23 15
2022-01-20 04:36:50,130 - INFO - joeynmt.training - Example #2
2022-01-20 04:36:50,130 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 04:36:50,130 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 04:36:50,130 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 6 | 18 5 | 30 28
2022-01-20 04:36:50,131 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    11000: bleu:  25.68, loss: 2013445.8750, ppl:   3.4920, duration: 1399.4302s
2022-01-20 04:37:09,250 - INFO - joeynmt.training - Epoch   1, Step:    11100, Batch Loss:    27.894733, Tokens per Sec:     3564, Lr: 0.000200
2022-01-20 04:37:27,824 - INFO - joeynmt.training - Epoch   1, Step:    11200, Batch Loss:    23.218140, Tokens per Sec:     3583, Lr: 0.000200
2022-01-20 04:37:46,501 - INFO - joeynmt.training - Epoch   1, Step:    11300, Batch Loss:    49.732079, Tokens per Sec:     3619, Lr: 0.000200
2022-01-20 04:38:05,663 - INFO - joeynmt.training - Epoch   1, Step:    11400, Batch Loss:    65.495338, Tokens per Sec:     3550, Lr: 0.000200
2022-01-20 04:38:24,197 - INFO - joeynmt.training - Epoch   1, Step:    11500, Batch Loss:    28.698782, Tokens per Sec:     3665, Lr: 0.000200
2022-01-20 04:38:42,765 - INFO - joeynmt.training - Epoch   1, Step:    11600, Batch Loss:    65.761292, Tokens per Sec:     3484, Lr: 0.000200
2022-01-20 04:39:01,250 - INFO - joeynmt.training - Epoch   1, Step:    11700, Batch Loss:    32.224522, Tokens per Sec:     3662, Lr: 0.000200
2022-01-20 04:39:19,786 - INFO - joeynmt.training - Epoch   1, Step:    11800, Batch Loss:    16.221388, Tokens per Sec:     3643, Lr: 0.000200
2022-01-20 04:39:38,469 - INFO - joeynmt.training - Epoch   1, Step:    11900, Batch Loss:    33.012764, Tokens per Sec:     3574, Lr: 0.000200
2022-01-20 04:39:57,237 - INFO - joeynmt.training - Epoch   1, Step:    12000, Batch Loss:    36.276161, Tokens per Sec:     3540, Lr: 0.000200
2022-01-20 05:02:32,019 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 05:03:04,755 - INFO - joeynmt.helpers - delete models/a_model/11000.ckpt
2022-01-20 05:03:04,841 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/11000.ckpt
2022-01-20 05:03:04,841 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/11000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/11000.ckpt')
2022-01-20 05:03:04,875 - INFO - joeynmt.training - Example #0
2022-01-20 05:03:04,875 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 05:03:04,875 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 05:03:04,875 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 7 | 2 30 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 05:03:04,875 - INFO - joeynmt.training - Example #1
2022-01-20 05:03:04,875 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 05:03:04,876 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 05:03:04,876 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 15 | 35 34 | 23 7
2022-01-20 05:03:04,876 - INFO - joeynmt.training - Example #2
2022-01-20 05:03:04,876 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 05:03:04,876 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 05:03:04,876 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 05:03:04,877 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    12000: bleu:  28.81, loss: 1718771.0000, ppl:   2.9080, duration: 1387.6396s
2022-01-20 05:03:23,661 - INFO - joeynmt.training - Epoch   1, Step:    12100, Batch Loss:    26.069860, Tokens per Sec:     3582, Lr: 0.000200
2022-01-20 05:03:42,049 - INFO - joeynmt.training - Epoch   1, Step:    12200, Batch Loss:    20.092323, Tokens per Sec:     3708, Lr: 0.000200
2022-01-20 05:04:00,614 - INFO - joeynmt.training - Epoch   1, Step:    12300, Batch Loss:    23.994843, Tokens per Sec:     3648, Lr: 0.000200
2022-01-20 05:04:19,092 - INFO - joeynmt.training - Epoch   1, Step:    12400, Batch Loss:    43.595634, Tokens per Sec:     3722, Lr: 0.000200
2022-01-20 05:04:37,677 - INFO - joeynmt.training - Epoch   1, Step:    12500, Batch Loss:    35.510788, Tokens per Sec:     3635, Lr: 0.000200
2022-01-20 05:04:56,273 - INFO - joeynmt.training - Epoch   1, Step:    12600, Batch Loss:    24.848537, Tokens per Sec:     3571, Lr: 0.000200
2022-01-20 05:05:14,474 - INFO - joeynmt.training - Epoch   1, Step:    12700, Batch Loss:    27.757364, Tokens per Sec:     3775, Lr: 0.000200
2022-01-20 05:05:33,106 - INFO - joeynmt.training - Epoch   1, Step:    12800, Batch Loss:    21.931831, Tokens per Sec:     3637, Lr: 0.000200
2022-01-20 05:05:51,623 - INFO - joeynmt.training - Epoch   1, Step:    12900, Batch Loss:    43.319546, Tokens per Sec:     3641, Lr: 0.000200
2022-01-20 05:06:10,152 - INFO - joeynmt.training - Epoch   1, Step:    13000, Batch Loss:    20.333466, Tokens per Sec:     3565, Lr: 0.000200
2022-01-20 05:28:10,862 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 05:28:43,549 - INFO - joeynmt.helpers - delete models/a_model/12000.ckpt
2022-01-20 05:28:43,623 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/12000.ckpt
2022-01-20 05:28:43,623 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/12000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/12000.ckpt')
2022-01-20 05:28:43,682 - INFO - joeynmt.training - Example #0
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 05:28:43,682 - INFO - joeynmt.training - Example #1
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 05:28:43,682 - INFO - joeynmt.training - Example #2
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 05:28:43,682 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 5 | 0 33 | 18 6
2022-01-20 05:28:43,683 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    13000: bleu:  30.21, loss: 1584077.8750, ppl:   2.6746, duration: 1353.5311s
2022-01-20 05:29:02,264 - INFO - joeynmt.training - Epoch   1, Step:    13100, Batch Loss:    18.917938, Tokens per Sec:     3510, Lr: 0.000200
2022-01-20 05:29:20,775 - INFO - joeynmt.training - Epoch   1, Step:    13200, Batch Loss:    15.884299, Tokens per Sec:     3562, Lr: 0.000200
2022-01-20 05:29:39,029 - INFO - joeynmt.training - Epoch   1, Step:    13300, Batch Loss:    33.036724, Tokens per Sec:     3752, Lr: 0.000200
2022-01-20 05:29:57,671 - INFO - joeynmt.training - Epoch   1, Step:    13400, Batch Loss:    22.635540, Tokens per Sec:     3648, Lr: 0.000200
2022-01-20 05:30:16,228 - INFO - joeynmt.training - Epoch   1, Step:    13500, Batch Loss:    26.041656, Tokens per Sec:     3653, Lr: 0.000200
2022-01-20 05:30:34,715 - INFO - joeynmt.training - Epoch   1, Step:    13600, Batch Loss:    40.300171, Tokens per Sec:     3660, Lr: 0.000200
2022-01-20 05:30:53,267 - INFO - joeynmt.training - Epoch   1, Step:    13700, Batch Loss:    20.019417, Tokens per Sec:     3634, Lr: 0.000200
2022-01-20 05:31:11,751 - INFO - joeynmt.training - Epoch   1, Step:    13800, Batch Loss:    18.054829, Tokens per Sec:     3662, Lr: 0.000200
2022-01-20 05:31:30,357 - INFO - joeynmt.training - Epoch   1, Step:    13900, Batch Loss:    19.892420, Tokens per Sec:     3684, Lr: 0.000200
2022-01-20 05:31:48,795 - INFO - joeynmt.training - Epoch   1, Step:    14000, Batch Loss:    15.996872, Tokens per Sec:     3651, Lr: 0.000200
2022-01-20 05:54:11,603 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 05:54:44,363 - INFO - joeynmt.helpers - delete models/a_model/13000.ckpt
2022-01-20 05:54:44,446 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/13000.ckpt
2022-01-20 05:54:44,447 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/13000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/13000.ckpt')
2022-01-20 05:54:44,553 - INFO - joeynmt.training - Example #0
2022-01-20 05:54:44,554 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 05:54:44,554 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 05:54:44,554 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 05:54:44,554 - INFO - joeynmt.training - Example #1
2022-01-20 05:54:44,554 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 05:54:44,554 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 05:54:44,554 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 05:54:44,554 - INFO - joeynmt.training - Example #2
2022-01-20 05:54:44,554 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 05:54:44,554 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 05:54:44,555 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 05:54:44,555 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    14000: bleu:  32.12, loss: 1507191.2500, ppl:   2.5499, duration: 1375.7602s
2022-01-20 05:55:03,340 - INFO - joeynmt.training - Epoch   1, Step:    14100, Batch Loss:    27.614594, Tokens per Sec:     3525, Lr: 0.000200
2022-01-20 05:55:21,608 - INFO - joeynmt.training - Epoch   1, Step:    14200, Batch Loss:    23.142204, Tokens per Sec:     3619, Lr: 0.000200
2022-01-20 05:55:39,872 - INFO - joeynmt.training - Epoch   1, Step:    14300, Batch Loss:    32.994579, Tokens per Sec:     3704, Lr: 0.000200
2022-01-20 05:55:58,256 - INFO - joeynmt.training - Epoch   1, Step:    14400, Batch Loss:    69.440407, Tokens per Sec:     3604, Lr: 0.000200
2022-01-20 05:56:16,582 - INFO - joeynmt.training - Epoch   1, Step:    14500, Batch Loss:    32.279156, Tokens per Sec:     3607, Lr: 0.000200
2022-01-20 05:56:35,080 - INFO - joeynmt.training - Epoch   1, Step:    14600, Batch Loss:    23.529604, Tokens per Sec:     3544, Lr: 0.000200
2022-01-20 05:56:53,690 - INFO - joeynmt.training - Epoch   1, Step:    14700, Batch Loss:    25.587820, Tokens per Sec:     3677, Lr: 0.000200
2022-01-20 05:57:12,050 - INFO - joeynmt.training - Epoch   1, Step:    14800, Batch Loss:    25.242279, Tokens per Sec:     3577, Lr: 0.000200
2022-01-20 05:57:30,552 - INFO - joeynmt.training - Epoch   1, Step:    14900, Batch Loss:    18.069962, Tokens per Sec:     3687, Lr: 0.000200
2022-01-20 05:57:48,944 - INFO - joeynmt.training - Epoch   1, Step:    15000, Batch Loss:    20.336172, Tokens per Sec:     3588, Lr: 0.000200
2022-01-20 06:19:52,547 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 06:20:25,294 - INFO - joeynmt.helpers - delete models/a_model/14000.ckpt
2022-01-20 06:20:25,375 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/14000.ckpt
2022-01-20 06:20:25,376 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/14000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/14000.ckpt')
2022-01-20 06:20:25,416 - INFO - joeynmt.training - Example #0
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 12 | 33 5
2022-01-20 06:20:25,416 - INFO - joeynmt.training - Example #1
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 06:20:25,416 - INFO - joeynmt.training - Example #2
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 06:20:25,416 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 06:20:25,417 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    15000: bleu:  32.23, loss: 1410953.2500, ppl:   2.4020, duration: 1356.4732s
2022-01-20 06:20:44,119 - INFO - joeynmt.training - Epoch   1, Step:    15100, Batch Loss:    22.052525, Tokens per Sec:     3622, Lr: 0.000200
2022-01-20 06:21:02,489 - INFO - joeynmt.training - Epoch   1, Step:    15200, Batch Loss:    20.154062, Tokens per Sec:     3571, Lr: 0.000200
2022-01-20 06:21:20,819 - INFO - joeynmt.training - Epoch   1, Step:    15300, Batch Loss:    23.247843, Tokens per Sec:     3770, Lr: 0.000200
2022-01-20 06:21:39,569 - INFO - joeynmt.training - Epoch   1, Step:    15400, Batch Loss:    41.066597, Tokens per Sec:     3549, Lr: 0.000200
2022-01-20 06:21:58,049 - INFO - joeynmt.training - Epoch   1, Step:    15500, Batch Loss:    61.636440, Tokens per Sec:     3572, Lr: 0.000200
2022-01-20 06:22:16,446 - INFO - joeynmt.training - Epoch   1, Step:    15600, Batch Loss:    35.236618, Tokens per Sec:     3721, Lr: 0.000200
2022-01-20 06:22:34,879 - INFO - joeynmt.training - Epoch   1, Step:    15700, Batch Loss:    20.003569, Tokens per Sec:     3626, Lr: 0.000200
2022-01-20 06:22:53,438 - INFO - joeynmt.training - Epoch   1, Step:    15800, Batch Loss:    36.202232, Tokens per Sec:     3470, Lr: 0.000200
2022-01-20 06:23:12,213 - INFO - joeynmt.training - Epoch   1, Step:    15900, Batch Loss:    18.135725, Tokens per Sec:     3679, Lr: 0.000200
2022-01-20 06:23:30,850 - INFO - joeynmt.training - Epoch   1, Step:    16000, Batch Loss:    26.707083, Tokens per Sec:     3664, Lr: 0.000200
2022-01-20 06:45:16,625 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 06:45:49,325 - INFO - joeynmt.helpers - delete models/a_model/15000.ckpt
2022-01-20 06:45:49,408 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/15000.ckpt
2022-01-20 06:45:49,409 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/15000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/15000.ckpt')
2022-01-20 06:45:49,447 - INFO - joeynmt.training - Example #0
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 06:45:49,448 - INFO - joeynmt.training - Example #1
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 8 | 38 7 | 33 15 | 35 34
2022-01-20 06:45:49,448 - INFO - joeynmt.training - Example #2
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 06:45:49,448 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 06:45:49,449 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    16000: bleu:  34.16, loss: 1293026.6250, ppl:   2.2323, duration: 1338.5986s
2022-01-20 06:46:08,312 - INFO - joeynmt.training - Epoch   1, Step:    16100, Batch Loss:    21.028696, Tokens per Sec:     3570, Lr: 0.000200
2022-01-20 06:46:26,669 - INFO - joeynmt.training - Epoch   1, Step:    16200, Batch Loss:    26.118515, Tokens per Sec:     3673, Lr: 0.000200
2022-01-20 06:46:45,222 - INFO - joeynmt.training - Epoch   1, Step:    16300, Batch Loss:    35.312225, Tokens per Sec:     3529, Lr: 0.000200
2022-01-20 06:47:04,023 - INFO - joeynmt.training - Epoch   1, Step:    16400, Batch Loss:    23.001844, Tokens per Sec:     3606, Lr: 0.000200
2022-01-20 06:47:22,377 - INFO - joeynmt.training - Epoch   1, Step:    16500, Batch Loss:    21.554987, Tokens per Sec:     3761, Lr: 0.000200
2022-01-20 06:47:40,921 - INFO - joeynmt.training - Epoch   1, Step:    16600, Batch Loss:    37.041679, Tokens per Sec:     3607, Lr: 0.000200
2022-01-20 06:47:59,291 - INFO - joeynmt.training - Epoch   1, Step:    16700, Batch Loss:    24.631847, Tokens per Sec:     3880, Lr: 0.000200
2022-01-20 06:48:17,860 - INFO - joeynmt.training - Epoch   1, Step:    16800, Batch Loss:    23.007980, Tokens per Sec:     3646, Lr: 0.000200
2022-01-20 06:48:36,362 - INFO - joeynmt.training - Epoch   1, Step:    16900, Batch Loss:    30.895630, Tokens per Sec:     3827, Lr: 0.000200
2022-01-20 06:48:54,587 - INFO - joeynmt.training - Epoch   1, Step:    17000, Batch Loss:    14.195994, Tokens per Sec:     3675, Lr: 0.000200
2022-01-20 07:10:29,513 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 07:11:02,215 - INFO - joeynmt.helpers - delete models/a_model/16000.ckpt
2022-01-20 07:11:02,299 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/16000.ckpt
2022-01-20 07:11:02,300 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/16000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/16000.ckpt')
2022-01-20 07:11:02,472 - INFO - joeynmt.training - Example #0
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 07:11:02,473 - INFO - joeynmt.training - Example #1
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 07:11:02,473 - INFO - joeynmt.training - Example #2
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 07:11:02,473 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 07:11:02,474 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    17000: bleu:  36.03, loss: 1221426.6250, ppl:   2.1353, duration: 1327.8862s
2022-01-20 07:11:20,840 - INFO - joeynmt.training - Epoch   1, Step:    17100, Batch Loss:    17.092167, Tokens per Sec:     3639, Lr: 0.000200
2022-01-20 07:11:39,389 - INFO - joeynmt.training - Epoch   1, Step:    17200, Batch Loss:    18.841282, Tokens per Sec:     3649, Lr: 0.000200
2022-01-20 07:11:57,591 - INFO - joeynmt.training - Epoch   1, Step:    17300, Batch Loss:    15.032067, Tokens per Sec:     3721, Lr: 0.000200
2022-01-20 07:12:15,616 - INFO - joeynmt.training - Epoch   1, Step:    17400, Batch Loss:    19.968149, Tokens per Sec:     3775, Lr: 0.000200
2022-01-20 07:12:33,641 - INFO - joeynmt.training - Epoch   1, Step:    17500, Batch Loss:    13.212521, Tokens per Sec:     3765, Lr: 0.000200
2022-01-20 07:12:51,795 - INFO - joeynmt.training - Epoch   1, Step:    17600, Batch Loss:    21.312908, Tokens per Sec:     3785, Lr: 0.000200
2022-01-20 07:13:10,273 - INFO - joeynmt.training - Epoch   1, Step:    17700, Batch Loss:    29.193830, Tokens per Sec:     3681, Lr: 0.000200
2022-01-20 07:13:28,670 - INFO - joeynmt.training - Epoch   1, Step:    17800, Batch Loss:    16.294056, Tokens per Sec:     3652, Lr: 0.000200
2022-01-20 07:13:47,686 - INFO - joeynmt.training - Epoch   1, Step:    17900, Batch Loss:    22.466990, Tokens per Sec:     3538, Lr: 0.000200
2022-01-20 07:14:06,621 - INFO - joeynmt.training - Epoch   1, Step:    18000, Batch Loss:    34.276222, Tokens per Sec:     3518, Lr: 0.000200
2022-01-20 07:36:02,029 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 07:36:34,777 - INFO - joeynmt.helpers - delete models/a_model/17000.ckpt
2022-01-20 07:36:34,862 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/17000.ckpt
2022-01-20 07:36:34,863 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/17000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/17000.ckpt')
2022-01-20 07:36:34,958 - INFO - joeynmt.training - Example #0
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 07:36:34,958 - INFO - joeynmt.training - Example #1
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-20 07:36:34,958 - INFO - joeynmt.training - Example #2
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 07:36:34,958 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 07:36:34,960 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    18000: bleu:  38.05, loss: 1129824.8750, ppl:   2.0172, duration: 1348.3386s
2022-01-20 07:36:53,431 - INFO - joeynmt.training - Epoch   1, Step:    18100, Batch Loss:    55.509872, Tokens per Sec:     3553, Lr: 0.000200
2022-01-20 07:37:11,923 - INFO - joeynmt.training - Epoch   1, Step:    18200, Batch Loss:    13.547007, Tokens per Sec:     3731, Lr: 0.000200
2022-01-20 07:37:30,682 - INFO - joeynmt.training - Epoch   1, Step:    18300, Batch Loss:    42.008095, Tokens per Sec:     3663, Lr: 0.000200
2022-01-20 07:37:49,310 - INFO - joeynmt.training - Epoch   1, Step:    18400, Batch Loss:    15.460871, Tokens per Sec:     3576, Lr: 0.000200
2022-01-20 07:38:07,896 - INFO - joeynmt.training - Epoch   1, Step:    18500, Batch Loss:    14.071748, Tokens per Sec:     3706, Lr: 0.000200
2022-01-20 07:38:26,733 - INFO - joeynmt.training - Epoch   1, Step:    18600, Batch Loss:    28.430735, Tokens per Sec:     3551, Lr: 0.000200
2022-01-20 07:38:44,855 - INFO - joeynmt.training - Epoch   1, Step:    18700, Batch Loss:    19.260426, Tokens per Sec:     3718, Lr: 0.000200
2022-01-20 07:39:03,473 - INFO - joeynmt.training - Epoch   1, Step:    18800, Batch Loss:     9.394341, Tokens per Sec:     3724, Lr: 0.000200
2022-01-20 07:39:22,044 - INFO - joeynmt.training - Epoch   1, Step:    18900, Batch Loss:    14.948193, Tokens per Sec:     3609, Lr: 0.000200
2022-01-20 07:39:40,771 - INFO - joeynmt.training - Epoch   1, Step:    19000, Batch Loss:    13.985149, Tokens per Sec:     3583, Lr: 0.000200
2022-01-20 08:01:39,354 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 08:02:12,126 - INFO - joeynmt.helpers - delete models/a_model/18000.ckpt
2022-01-20 08:02:12,206 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/18000.ckpt
2022-01-20 08:02:12,207 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/18000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/18000.ckpt')
2022-01-20 08:02:12,301 - INFO - joeynmt.training - Example #0
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 08:02:12,302 - INFO - joeynmt.training - Example #1
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 08:02:12,302 - INFO - joeynmt.training - Example #2
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 08:02:12,302 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 08:02:12,303 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    19000: bleu:  40.09, loss: 1055096.8750, ppl:   1.9257, duration: 1351.5321s
2022-01-20 08:02:31,210 - INFO - joeynmt.training - Epoch   1, Step:    19100, Batch Loss:    17.847094, Tokens per Sec:     3391, Lr: 0.000200
2022-01-20 08:02:49,844 - INFO - joeynmt.training - Epoch   1, Step:    19200, Batch Loss:    24.872469, Tokens per Sec:     3610, Lr: 0.000200
2022-01-20 08:03:08,535 - INFO - joeynmt.training - Epoch   1, Step:    19300, Batch Loss:    18.519650, Tokens per Sec:     3534, Lr: 0.000200
2022-01-20 08:03:27,474 - INFO - joeynmt.training - Epoch   1, Step:    19400, Batch Loss:    22.942266, Tokens per Sec:     3595, Lr: 0.000200
2022-01-20 08:03:46,480 - INFO - joeynmt.training - Epoch   1, Step:    19500, Batch Loss:    19.538040, Tokens per Sec:     3523, Lr: 0.000200
2022-01-20 08:04:05,506 - INFO - joeynmt.training - Epoch   1, Step:    19600, Batch Loss:    12.008224, Tokens per Sec:     3543, Lr: 0.000200
2022-01-20 08:04:24,356 - INFO - joeynmt.training - Epoch   1, Step:    19700, Batch Loss:    23.079527, Tokens per Sec:     3628, Lr: 0.000200
2022-01-20 08:04:43,293 - INFO - joeynmt.training - Epoch   1, Step:    19800, Batch Loss:    11.949383, Tokens per Sec:     3703, Lr: 0.000200
2022-01-20 08:05:02,339 - INFO - joeynmt.training - Epoch   1, Step:    19900, Batch Loss:    17.103603, Tokens per Sec:     3421, Lr: 0.000200
2022-01-20 08:05:20,962 - INFO - joeynmt.training - Epoch   1, Step:    20000, Batch Loss:    17.300138, Tokens per Sec:     3727, Lr: 0.000200
2022-01-20 08:27:14,440 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 08:27:47,166 - INFO - joeynmt.helpers - delete models/a_model/19000.ckpt
2022-01-20 08:27:47,246 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/19000.ckpt
2022-01-20 08:27:47,247 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/19000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/19000.ckpt')
2022-01-20 08:27:47,413 - INFO - joeynmt.training - Example #0
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 08:27:47,414 - INFO - joeynmt.training - Example #1
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 08:27:47,414 - INFO - joeynmt.training - Example #2
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 08:27:47,414 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 08:27:47,415 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    20000: bleu:  46.71, loss: 954069.4375, ppl:   1.8086, duration: 1346.4528s
2022-01-20 08:28:06,283 - INFO - joeynmt.training - Epoch   1, Step:    20100, Batch Loss:    10.293468, Tokens per Sec:     3535, Lr: 0.000200
2022-01-20 08:28:25,020 - INFO - joeynmt.training - Epoch   1, Step:    20200, Batch Loss:    24.077930, Tokens per Sec:     3642, Lr: 0.000200
2022-01-20 08:28:43,474 - INFO - joeynmt.training - Epoch   1, Step:    20300, Batch Loss:    23.057631, Tokens per Sec:     3623, Lr: 0.000200
2022-01-20 08:29:02,258 - INFO - joeynmt.training - Epoch   1, Step:    20400, Batch Loss:    11.121913, Tokens per Sec:     3603, Lr: 0.000200
2022-01-20 08:29:20,903 - INFO - joeynmt.training - Epoch   1, Step:    20500, Batch Loss:     6.501517, Tokens per Sec:     3615, Lr: 0.000200
2022-01-20 08:29:39,551 - INFO - joeynmt.training - Epoch   1, Step:    20600, Batch Loss:    16.645853, Tokens per Sec:     3610, Lr: 0.000200
2022-01-20 08:29:58,088 - INFO - joeynmt.training - Epoch   1, Step:    20700, Batch Loss:    24.943068, Tokens per Sec:     3601, Lr: 0.000200
2022-01-20 08:30:16,681 - INFO - joeynmt.training - Epoch   1, Step:    20800, Batch Loss:    14.146176, Tokens per Sec:     3701, Lr: 0.000200
2022-01-20 08:30:35,245 - INFO - joeynmt.training - Epoch   1, Step:    20900, Batch Loss:     7.151443, Tokens per Sec:     3601, Lr: 0.000200
2022-01-20 08:30:53,883 - INFO - joeynmt.training - Epoch   1, Step:    21000, Batch Loss:    18.833149, Tokens per Sec:     3524, Lr: 0.000200
2022-01-20 08:52:43,725 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 08:53:16,482 - INFO - joeynmt.helpers - delete models/a_model/20000.ckpt
2022-01-20 08:53:16,571 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/20000.ckpt
2022-01-20 08:53:16,572 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/20000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/20000.ckpt')
2022-01-20 08:53:16,667 - INFO - joeynmt.training - Example #0
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 08:53:16,667 - INFO - joeynmt.training - Example #1
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 23 34 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 08:53:16,667 - INFO - joeynmt.training - Example #2
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 08:53:16,667 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 30 28 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 08:53:16,668 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    21000: bleu:  54.16, loss: 883341.1875, ppl:   1.7309, duration: 1342.7852s
2022-01-20 08:53:35,569 - INFO - joeynmt.training - Epoch   1, Step:    21100, Batch Loss:    17.234221, Tokens per Sec:     3550, Lr: 0.000200
2022-01-20 08:53:54,206 - INFO - joeynmt.training - Epoch   1, Step:    21200, Batch Loss:    16.303234, Tokens per Sec:     3613, Lr: 0.000200
2022-01-20 08:54:12,628 - INFO - joeynmt.training - Epoch   1, Step:    21300, Batch Loss:    20.576597, Tokens per Sec:     3683, Lr: 0.000200
2022-01-20 08:54:31,150 - INFO - joeynmt.training - Epoch   1, Step:    21400, Batch Loss:    14.102761, Tokens per Sec:     3698, Lr: 0.000200
2022-01-20 08:54:49,820 - INFO - joeynmt.training - Epoch   1, Step:    21500, Batch Loss:    17.823965, Tokens per Sec:     3570, Lr: 0.000200
2022-01-20 08:55:08,249 - INFO - joeynmt.training - Epoch   1, Step:    21600, Batch Loss:    11.062035, Tokens per Sec:     3567, Lr: 0.000200
2022-01-20 08:55:26,998 - INFO - joeynmt.training - Epoch   1, Step:    21700, Batch Loss:    13.294416, Tokens per Sec:     3658, Lr: 0.000200
2022-01-20 08:55:45,431 - INFO - joeynmt.training - Epoch   1, Step:    21800, Batch Loss:    10.153499, Tokens per Sec:     3531, Lr: 0.000200
2022-01-20 08:56:03,920 - INFO - joeynmt.training - Epoch   1, Step:    21900, Batch Loss:    15.244783, Tokens per Sec:     3546, Lr: 0.000200
2022-01-20 08:56:22,528 - INFO - joeynmt.training - Epoch   1, Step:    22000, Batch Loss:    12.469631, Tokens per Sec:     3678, Lr: 0.000200
2022-01-20 09:18:25,967 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 09:19:09,877 - INFO - joeynmt.helpers - delete models/a_model/21000.ckpt
2022-01-20 09:19:09,984 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/21000.ckpt
2022-01-20 09:19:09,999 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/21000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/21000.ckpt')
2022-01-20 09:19:10,179 - INFO - joeynmt.training - Example #0
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 09:19:10,180 - INFO - joeynmt.training - Example #1
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 09:19:10,180 - INFO - joeynmt.training - Example #2
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 09:19:10,180 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 09:19:10,181 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    22000: bleu:  68.07, loss: 725595.6875, ppl:   1.5693, duration: 1367.6526s
2022-01-20 09:19:36,983 - INFO - joeynmt.training - Epoch   1, Step:    22100, Batch Loss:    15.759741, Tokens per Sec:     2480, Lr: 0.000200
2022-01-20 09:20:01,560 - INFO - joeynmt.training - Epoch   1, Step:    22200, Batch Loss:    12.992899, Tokens per Sec:     2756, Lr: 0.000200
2022-01-20 09:20:44,431 - INFO - joeynmt.training - Epoch   1, Step:    22300, Batch Loss:    20.477024, Tokens per Sec:     1555, Lr: 0.000200
2022-01-20 09:21:16,154 - INFO - joeynmt.training - Epoch   1, Step:    22400, Batch Loss:    13.424657, Tokens per Sec:     2129, Lr: 0.000200
2022-01-20 09:21:35,122 - INFO - joeynmt.training - Epoch   1, Step:    22500, Batch Loss:     8.860216, Tokens per Sec:     3617, Lr: 0.000200
2022-01-20 09:21:53,666 - INFO - joeynmt.training - Epoch   1, Step:    22600, Batch Loss:    10.479477, Tokens per Sec:     3511, Lr: 0.000200
2022-01-20 09:22:11,994 - INFO - joeynmt.training - Epoch   1, Step:    22700, Batch Loss:    13.952871, Tokens per Sec:     3606, Lr: 0.000200
2022-01-20 09:22:30,149 - INFO - joeynmt.training - Epoch   1, Step:    22800, Batch Loss:    13.451606, Tokens per Sec:     3663, Lr: 0.000200
2022-01-20 09:22:48,374 - INFO - joeynmt.training - Epoch   1, Step:    22900, Batch Loss:    15.458262, Tokens per Sec:     3638, Lr: 0.000200
2022-01-20 09:23:06,712 - INFO - joeynmt.training - Epoch   1, Step:    23000, Batch Loss:    49.808929, Tokens per Sec:     3550, Lr: 0.000200
2022-01-20 09:45:17,289 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 09:45:49,709 - INFO - joeynmt.helpers - delete models/a_model/22000.ckpt
2022-01-20 09:45:49,798 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/22000.ckpt
2022-01-20 09:45:49,799 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/22000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/22000.ckpt')
2022-01-20 09:45:49,824 - INFO - joeynmt.training - Example #0
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 33 12 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 09:45:49,824 - INFO - joeynmt.training - Example #1
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 23 34 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 09:45:49,824 - INFO - joeynmt.training - Example #2
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 09:45:49,824 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 09:45:49,825 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    23000: bleu:  73.87, loss: 624648.8125, ppl:   1.4740, duration: 1363.1131s
2022-01-20 09:46:08,900 - INFO - joeynmt.training - Epoch   1, Step:    23100, Batch Loss:     6.318592, Tokens per Sec:     3508, Lr: 0.000200
2022-01-20 09:46:27,807 - INFO - joeynmt.training - Epoch   1, Step:    23200, Batch Loss:     9.746749, Tokens per Sec:     3485, Lr: 0.000200
2022-01-20 09:46:46,699 - INFO - joeynmt.training - Epoch   1, Step:    23300, Batch Loss:     8.348201, Tokens per Sec:     3735, Lr: 0.000200
2022-01-20 09:47:05,551 - INFO - joeynmt.training - Epoch   1, Step:    23400, Batch Loss:    13.193182, Tokens per Sec:     3557, Lr: 0.000200
2022-01-20 09:47:24,183 - INFO - joeynmt.training - Epoch   1, Step:    23500, Batch Loss:    11.550974, Tokens per Sec:     3601, Lr: 0.000200
2022-01-20 09:47:43,012 - INFO - joeynmt.training - Epoch   1, Step:    23600, Batch Loss:     5.788533, Tokens per Sec:     3671, Lr: 0.000200
2022-01-20 09:48:01,779 - INFO - joeynmt.training - Epoch   1, Step:    23700, Batch Loss:     7.298871, Tokens per Sec:     3479, Lr: 0.000200
2022-01-20 09:48:20,716 - INFO - joeynmt.training - Epoch   1, Step:    23800, Batch Loss:     7.540003, Tokens per Sec:     3579, Lr: 0.000200
2022-01-20 09:48:39,667 - INFO - joeynmt.training - Epoch   1, Step:    23900, Batch Loss:    11.115016, Tokens per Sec:     3578, Lr: 0.000200
2022-01-20 09:48:58,591 - INFO - joeynmt.training - Epoch   1, Step:    24000, Batch Loss:    16.814642, Tokens per Sec:     3668, Lr: 0.000200
2022-01-20 10:11:00,935 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 10:11:33,719 - INFO - joeynmt.helpers - delete models/a_model/23000.ckpt
2022-01-20 10:11:33,796 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/23000.ckpt
2022-01-20 10:11:33,797 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/23000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/23000.ckpt')
2022-01-20 10:11:33,974 - INFO - joeynmt.training - Example #0
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 10:11:33,974 - INFO - joeynmt.training - Example #1
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 10:11:33,974 - INFO - joeynmt.training - Example #2
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 10:11:33,974 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 10:11:33,975 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    24000: bleu:  76.94, loss: 578558.7500, ppl:   1.4324, duration: 1355.3834s
2022-01-20 10:11:53,059 - INFO - joeynmt.training - Epoch   1, Step:    24100, Batch Loss:    12.668376, Tokens per Sec:     3549, Lr: 0.000200
2022-01-20 10:12:12,182 - INFO - joeynmt.training - Epoch   1, Step:    24200, Batch Loss:     7.223161, Tokens per Sec:     3462, Lr: 0.000200
2022-01-20 10:12:30,773 - INFO - joeynmt.training - Epoch   1, Step:    24300, Batch Loss:     8.168931, Tokens per Sec:     3606, Lr: 0.000200
2022-01-20 10:12:49,537 - INFO - joeynmt.training - Epoch   1, Step:    24400, Batch Loss:     6.862274, Tokens per Sec:     3680, Lr: 0.000200
2022-01-20 10:13:08,161 - INFO - joeynmt.training - Epoch   1, Step:    24500, Batch Loss:     8.275586, Tokens per Sec:     3564, Lr: 0.000200
2022-01-20 10:13:26,649 - INFO - joeynmt.training - Epoch   1, Step:    24600, Batch Loss:     9.011068, Tokens per Sec:     3631, Lr: 0.000200
2022-01-20 10:13:45,309 - INFO - joeynmt.training - Epoch   1, Step:    24700, Batch Loss:    10.759116, Tokens per Sec:     3555, Lr: 0.000200
2022-01-20 10:14:04,366 - INFO - joeynmt.training - Epoch   1, Step:    24800, Batch Loss:    19.829443, Tokens per Sec:     3538, Lr: 0.000200
2022-01-20 10:14:23,064 - INFO - joeynmt.training - Epoch   1, Step:    24900, Batch Loss:     8.674593, Tokens per Sec:     3693, Lr: 0.000200
2022-01-20 10:14:41,770 - INFO - joeynmt.training - Epoch   1, Step:    25000, Batch Loss:     6.529742, Tokens per Sec:     3713, Lr: 0.000200
2022-01-20 10:36:36,006 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 10:37:08,725 - INFO - joeynmt.helpers - delete models/a_model/24000.ckpt
2022-01-20 10:37:08,809 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/24000.ckpt
2022-01-20 10:37:08,810 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/24000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/24000.ckpt')
2022-01-20 10:37:08,900 - INFO - joeynmt.training - Example #0
2022-01-20 10:37:08,900 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 10:37:08,900 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 10:37:08,900 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 10:37:08,900 - INFO - joeynmt.training - Example #1
2022-01-20 10:37:08,900 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 10:37:08,900 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 10:37:08,900 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 10:37:08,901 - INFO - joeynmt.training - Example #2
2022-01-20 10:37:08,901 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 10:37:08,901 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 10:37:08,901 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 10:37:08,901 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    25000: bleu:  78.34, loss: 548910.1250, ppl:   1.4062, duration: 1347.1312s
2022-01-20 10:37:27,764 - INFO - joeynmt.training - Epoch   1, Step:    25100, Batch Loss:    17.928812, Tokens per Sec:     3486, Lr: 0.000200
2022-01-20 10:37:46,335 - INFO - joeynmt.training - Epoch   1, Step:    25200, Batch Loss:     6.705783, Tokens per Sec:     3567, Lr: 0.000200
2022-01-20 10:38:04,814 - INFO - joeynmt.training - Epoch   1, Step:    25300, Batch Loss:    12.276720, Tokens per Sec:     3609, Lr: 0.000200
2022-01-20 10:38:23,583 - INFO - joeynmt.training - Epoch   1, Step:    25400, Batch Loss:     5.724455, Tokens per Sec:     3652, Lr: 0.000200
2022-01-20 10:38:42,056 - INFO - joeynmt.training - Epoch   1, Step:    25500, Batch Loss:    10.776844, Tokens per Sec:     3755, Lr: 0.000200
2022-01-20 10:39:01,239 - INFO - joeynmt.training - Epoch   1, Step:    25600, Batch Loss:     8.709221, Tokens per Sec:     3554, Lr: 0.000200
2022-01-20 10:39:20,299 - INFO - joeynmt.training - Epoch   1, Step:    25700, Batch Loss:     5.794562, Tokens per Sec:     3511, Lr: 0.000200
2022-01-20 10:39:39,090 - INFO - joeynmt.training - Epoch   1, Step:    25800, Batch Loss:     6.509163, Tokens per Sec:     3599, Lr: 0.000200
2022-01-20 10:39:57,696 - INFO - joeynmt.training - Epoch   1, Step:    25900, Batch Loss:    19.556089, Tokens per Sec:     3619, Lr: 0.000200
2022-01-20 10:40:16,252 - INFO - joeynmt.training - Epoch   1, Step:    26000, Batch Loss:     6.938833, Tokens per Sec:     3690, Lr: 0.000200
2022-01-20 11:01:57,395 - INFO - joeynmt.training - Example #0
2022-01-20 11:01:57,396 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 11:01:57,396 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 11:01:57,396 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 11:01:57,396 - INFO - joeynmt.training - Example #1
2022-01-20 11:01:57,396 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 11:01:57,396 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 11:01:57,396 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 11:01:57,396 - INFO - joeynmt.training - Example #2
2022-01-20 11:01:57,397 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 11:01:57,397 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 11:01:57,397 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 11:01:57,398 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step    26000: bleu:  77.99, loss: 537188.8750, ppl:   1.3960, duration: 1301.1451s
2022-01-20 11:02:16,669 - INFO - joeynmt.training - Epoch   1, Step:    26100, Batch Loss:     8.370090, Tokens per Sec:     3543, Lr: 0.000200
2022-01-20 11:02:35,668 - INFO - joeynmt.training - Epoch   1, Step:    26200, Batch Loss:    22.022276, Tokens per Sec:     3473, Lr: 0.000200
2022-01-20 11:02:54,457 - INFO - joeynmt.training - Epoch   1, Step:    26300, Batch Loss:    13.656793, Tokens per Sec:     3731, Lr: 0.000200
2022-01-20 11:03:13,077 - INFO - joeynmt.training - Epoch   1, Step:    26400, Batch Loss:    21.000607, Tokens per Sec:     3570, Lr: 0.000200
2022-01-20 11:03:31,955 - INFO - joeynmt.training - Epoch   1, Step:    26500, Batch Loss:    10.453995, Tokens per Sec:     3513, Lr: 0.000200
2022-01-20 11:03:46,639 - INFO - joeynmt.training - Epoch   1: total training loss 1034636.54
2022-01-20 11:03:46,639 - INFO - joeynmt.training - EPOCH 2
2022-01-20 11:03:50,995 - INFO - joeynmt.training - Epoch   2, Step:    26600, Batch Loss:    10.287015, Tokens per Sec:     3261, Lr: 0.000200
2022-01-20 11:04:09,404 - INFO - joeynmt.training - Epoch   2, Step:    26700, Batch Loss:     4.723565, Tokens per Sec:     3623, Lr: 0.000200
2022-01-20 11:04:28,649 - INFO - joeynmt.training - Epoch   2, Step:    26800, Batch Loss:     4.736748, Tokens per Sec:     3409, Lr: 0.000200
2022-01-20 11:04:48,195 - INFO - joeynmt.training - Epoch   2, Step:    26900, Batch Loss:    17.587383, Tokens per Sec:     3462, Lr: 0.000200
2022-01-20 11:05:06,892 - INFO - joeynmt.training - Epoch   2, Step:    27000, Batch Loss:    10.247025, Tokens per Sec:     3541, Lr: 0.000200
2022-01-20 11:27:24,433 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 11:27:57,138 - INFO - joeynmt.helpers - delete models/a_model/25000.ckpt
2022-01-20 11:27:57,224 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/25000.ckpt
2022-01-20 11:27:57,225 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/25000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/25000.ckpt')
2022-01-20 11:27:57,258 - INFO - joeynmt.training - Example #0
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 11:27:57,258 - INFO - joeynmt.training - Example #1
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 11:27:57,258 - INFO - joeynmt.training - Example #2
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 11:27:57,258 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 11:27:57,259 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    27000: bleu:  79.07, loss: 522023.7500, ppl:   1.3829, duration: 1370.3667s
2022-01-20 11:28:16,154 - INFO - joeynmt.training - Epoch   2, Step:    27100, Batch Loss:     5.183824, Tokens per Sec:     3617, Lr: 0.000200
2022-01-20 11:28:34,670 - INFO - joeynmt.training - Epoch   2, Step:    27200, Batch Loss:     5.693811, Tokens per Sec:     3588, Lr: 0.000200
2022-01-20 11:28:53,416 - INFO - joeynmt.training - Epoch   2, Step:    27300, Batch Loss:     5.378184, Tokens per Sec:     3495, Lr: 0.000200
2022-01-20 11:29:12,063 - INFO - joeynmt.training - Epoch   2, Step:    27400, Batch Loss:     5.444917, Tokens per Sec:     3620, Lr: 0.000200
2022-01-20 11:29:30,600 - INFO - joeynmt.training - Epoch   2, Step:    27500, Batch Loss:     5.604947, Tokens per Sec:     3694, Lr: 0.000200
2022-01-20 11:29:49,369 - INFO - joeynmt.training - Epoch   2, Step:    27600, Batch Loss:     9.716610, Tokens per Sec:     3692, Lr: 0.000200
2022-01-20 11:30:07,924 - INFO - joeynmt.training - Epoch   2, Step:    27700, Batch Loss:     5.943924, Tokens per Sec:     3571, Lr: 0.000200
2022-01-20 11:30:26,198 - INFO - joeynmt.training - Epoch   2, Step:    27800, Batch Loss:     7.220613, Tokens per Sec:     3657, Lr: 0.000200
2022-01-20 11:30:44,801 - INFO - joeynmt.training - Epoch   2, Step:    27900, Batch Loss:     4.609797, Tokens per Sec:     3588, Lr: 0.000200
2022-01-20 11:31:03,603 - INFO - joeynmt.training - Epoch   2, Step:    28000, Batch Loss:    11.186515, Tokens per Sec:     3628, Lr: 0.000200
2022-01-20 11:52:49,417 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 11:53:22,126 - INFO - joeynmt.helpers - delete models/a_model/27000.ckpt
2022-01-20 11:53:22,210 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/27000.ckpt
2022-01-20 11:53:22,211 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/27000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/27000.ckpt')
2022-01-20 11:53:22,331 - INFO - joeynmt.training - Example #0
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 11:53:22,332 - INFO - joeynmt.training - Example #1
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 11:53:22,332 - INFO - joeynmt.training - Example #2
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 11:53:22,332 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 11:53:22,333 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    28000: bleu:  79.68, loss: 497043.0938, ppl:   1.3616, duration: 1338.7291s
2022-01-20 11:53:40,825 - INFO - joeynmt.training - Epoch   2, Step:    28100, Batch Loss:     6.564835, Tokens per Sec:     3619, Lr: 0.000200
2022-01-20 11:53:59,513 - INFO - joeynmt.training - Epoch   2, Step:    28200, Batch Loss:    19.537645, Tokens per Sec:     3643, Lr: 0.000200
2022-01-20 11:54:17,940 - INFO - joeynmt.training - Epoch   2, Step:    28300, Batch Loss:     8.819186, Tokens per Sec:     3691, Lr: 0.000200
2022-01-20 11:54:36,742 - INFO - joeynmt.training - Epoch   2, Step:    28400, Batch Loss:     6.863934, Tokens per Sec:     3641, Lr: 0.000200
2022-01-20 11:54:55,337 - INFO - joeynmt.training - Epoch   2, Step:    28500, Batch Loss:     7.237684, Tokens per Sec:     3713, Lr: 0.000200
2022-01-20 11:55:14,090 - INFO - joeynmt.training - Epoch   2, Step:    28600, Batch Loss:    16.804642, Tokens per Sec:     3541, Lr: 0.000200
2022-01-20 11:55:32,722 - INFO - joeynmt.training - Epoch   2, Step:    28700, Batch Loss:     6.335901, Tokens per Sec:     3744, Lr: 0.000200
2022-01-20 11:55:51,319 - INFO - joeynmt.training - Epoch   2, Step:    28800, Batch Loss:    12.493641, Tokens per Sec:     3667, Lr: 0.000200
2022-01-20 11:56:10,137 - INFO - joeynmt.training - Epoch   2, Step:    28900, Batch Loss:     5.891391, Tokens per Sec:     3582, Lr: 0.000200
2022-01-20 11:56:28,820 - INFO - joeynmt.training - Epoch   2, Step:    29000, Batch Loss:    15.555470, Tokens per Sec:     3592, Lr: 0.000200
2022-01-20 12:18:23,535 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 12:18:56,272 - INFO - joeynmt.helpers - delete models/a_model/28000.ckpt
2022-01-20 12:18:56,361 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/28000.ckpt
2022-01-20 12:18:56,361 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/28000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/28000.ckpt')
2022-01-20 12:18:56,397 - INFO - joeynmt.training - Example #0
2022-01-20 12:18:56,397 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 12:18:56,397 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 12:18:56,397 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 12:18:56,397 - INFO - joeynmt.training - Example #1
2022-01-20 12:18:56,397 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 12:18:56,397 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 12:18:56,397 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 12:18:56,397 - INFO - joeynmt.training - Example #2
2022-01-20 12:18:56,398 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 12:18:56,398 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 12:18:56,398 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 12:18:56,399 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    29000: bleu:  80.67, loss: 476839.8438, ppl:   1.3447, duration: 1347.5786s
2022-01-20 12:19:15,581 - INFO - joeynmt.training - Epoch   2, Step:    29100, Batch Loss:    10.831663, Tokens per Sec:     3529, Lr: 0.000200
2022-01-20 12:19:34,262 - INFO - joeynmt.training - Epoch   2, Step:    29200, Batch Loss:     7.553224, Tokens per Sec:     3651, Lr: 0.000200
2022-01-20 12:19:53,043 - INFO - joeynmt.training - Epoch   2, Step:    29300, Batch Loss:     4.724627, Tokens per Sec:     3583, Lr: 0.000200
2022-01-20 12:20:11,706 - INFO - joeynmt.training - Epoch   2, Step:    29400, Batch Loss:     8.661110, Tokens per Sec:     3605, Lr: 0.000200
2022-01-20 12:20:30,329 - INFO - joeynmt.training - Epoch   2, Step:    29500, Batch Loss:     8.256997, Tokens per Sec:     3605, Lr: 0.000200
2022-01-20 12:20:48,927 - INFO - joeynmt.training - Epoch   2, Step:    29600, Batch Loss:     6.520786, Tokens per Sec:     3642, Lr: 0.000200
2022-01-20 12:21:07,635 - INFO - joeynmt.training - Epoch   2, Step:    29700, Batch Loss:    10.452068, Tokens per Sec:     3731, Lr: 0.000200
2022-01-20 12:21:26,319 - INFO - joeynmt.training - Epoch   2, Step:    29800, Batch Loss:     6.717732, Tokens per Sec:     3552, Lr: 0.000200
2022-01-20 12:21:44,743 - INFO - joeynmt.training - Epoch   2, Step:    29900, Batch Loss:     8.522704, Tokens per Sec:     3632, Lr: 0.000200
2022-01-20 12:22:03,280 - INFO - joeynmt.training - Epoch   2, Step:    30000, Batch Loss:     7.501328, Tokens per Sec:     3655, Lr: 0.000200
2022-01-20 12:44:15,167 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 12:44:47,912 - INFO - joeynmt.helpers - delete models/a_model/29000.ckpt
2022-01-20 12:44:47,993 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/29000.ckpt
2022-01-20 12:44:47,994 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/29000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/29000.ckpt')
2022-01-20 12:44:48,171 - INFO - joeynmt.training - Example #0
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 12:44:48,172 - INFO - joeynmt.training - Example #1
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 12:44:48,172 - INFO - joeynmt.training - Example #2
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 12:44:48,172 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 12:44:48,173 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    30000: bleu:  81.17, loss: 466391.0312, ppl:   1.3360, duration: 1364.8928s
2022-01-20 12:45:07,226 - INFO - joeynmt.training - Epoch   2, Step:    30100, Batch Loss:     8.050341, Tokens per Sec:     3582, Lr: 0.000200
2022-01-20 12:45:25,625 - INFO - joeynmt.training - Epoch   2, Step:    30200, Batch Loss:    14.681471, Tokens per Sec:     3652, Lr: 0.000200
2022-01-20 12:45:44,327 - INFO - joeynmt.training - Epoch   2, Step:    30300, Batch Loss:     5.041252, Tokens per Sec:     3545, Lr: 0.000200
2022-01-20 12:46:03,310 - INFO - joeynmt.training - Epoch   2, Step:    30400, Batch Loss:    10.607938, Tokens per Sec:     3627, Lr: 0.000200
2022-01-20 12:46:22,032 - INFO - joeynmt.training - Epoch   2, Step:    30500, Batch Loss:    35.571022, Tokens per Sec:     3672, Lr: 0.000200
2022-01-20 12:46:40,539 - INFO - joeynmt.training - Epoch   2, Step:    30600, Batch Loss:     8.333279, Tokens per Sec:     3756, Lr: 0.000200
2022-01-20 12:46:59,264 - INFO - joeynmt.training - Epoch   2, Step:    30700, Batch Loss:    11.096891, Tokens per Sec:     3709, Lr: 0.000200
2022-01-20 12:47:17,580 - INFO - joeynmt.training - Epoch   2, Step:    30800, Batch Loss:     5.999718, Tokens per Sec:     3508, Lr: 0.000200
2022-01-20 12:47:36,325 - INFO - joeynmt.training - Epoch   2, Step:    30900, Batch Loss:    12.866078, Tokens per Sec:     3599, Lr: 0.000200
2022-01-20 12:47:55,082 - INFO - joeynmt.training - Epoch   2, Step:    31000, Batch Loss:     7.166855, Tokens per Sec:     3691, Lr: 0.000200
2022-01-20 13:09:52,630 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 13:10:25,339 - INFO - joeynmt.helpers - delete models/a_model/30000.ckpt
2022-01-20 13:10:25,423 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/30000.ckpt
2022-01-20 13:10:25,424 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/30000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/30000.ckpt')
2022-01-20 13:10:25,520 - INFO - joeynmt.training - Example #0
2022-01-20 13:10:25,520 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 13:10:25,520 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 13:10:25,520 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 13:10:25,520 - INFO - joeynmt.training - Example #1
2022-01-20 13:10:25,520 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 13:10:25,520 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 13:10:25,520 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 13:10:25,520 - INFO - joeynmt.training - Example #2
2022-01-20 13:10:25,521 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 13:10:25,521 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 13:10:25,521 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 13:10:25,522 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    31000: bleu:  81.73, loss: 460031.8125, ppl:   1.3307, duration: 1350.4393s
2022-01-20 13:10:44,363 - INFO - joeynmt.training - Epoch   2, Step:    31100, Batch Loss:     6.241998, Tokens per Sec:     3602, Lr: 0.000200
2022-01-20 13:11:03,485 - INFO - joeynmt.training - Epoch   2, Step:    31200, Batch Loss:     5.720558, Tokens per Sec:     3630, Lr: 0.000200
2022-01-20 13:11:22,860 - INFO - joeynmt.training - Epoch   2, Step:    31300, Batch Loss:     4.661444, Tokens per Sec:     3565, Lr: 0.000200
2022-01-20 13:11:42,184 - INFO - joeynmt.training - Epoch   2, Step:    31400, Batch Loss:     2.954305, Tokens per Sec:     3499, Lr: 0.000200
2022-01-20 13:12:01,053 - INFO - joeynmt.training - Epoch   2, Step:    31500, Batch Loss:     5.737988, Tokens per Sec:     3534, Lr: 0.000200
2022-01-20 13:12:19,700 - INFO - joeynmt.training - Epoch   2, Step:    31600, Batch Loss:     8.450088, Tokens per Sec:     3694, Lr: 0.000200
2022-01-20 13:12:38,367 - INFO - joeynmt.training - Epoch   2, Step:    31700, Batch Loss:     6.256102, Tokens per Sec:     3633, Lr: 0.000200
2022-01-20 13:12:56,975 - INFO - joeynmt.training - Epoch   2, Step:    31800, Batch Loss:     6.971071, Tokens per Sec:     3539, Lr: 0.000200
2022-01-20 13:13:15,748 - INFO - joeynmt.training - Epoch   2, Step:    31900, Batch Loss:    10.248834, Tokens per Sec:     3621, Lr: 0.000200
2022-01-20 13:13:34,512 - INFO - joeynmt.training - Epoch   2, Step:    32000, Batch Loss:    33.536297, Tokens per Sec:     3533, Lr: 0.000200
2022-01-20 13:35:35,585 - INFO - joeynmt.training - Example #0
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 13:35:35,586 - INFO - joeynmt.training - Example #1
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 13:35:35,586 - INFO - joeynmt.training - Example #2
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 13:35:35,586 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 13:35:35,587 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    32000: bleu:  81.35, loss: 465680.3750, ppl:   1.3354, duration: 1321.0746s
2022-01-20 13:35:54,744 - INFO - joeynmt.training - Epoch   2, Step:    32100, Batch Loss:     7.923689, Tokens per Sec:     3588, Lr: 0.000200
2022-01-20 13:36:13,813 - INFO - joeynmt.training - Epoch   2, Step:    32200, Batch Loss:     7.529157, Tokens per Sec:     3614, Lr: 0.000200
2022-01-20 13:36:32,946 - INFO - joeynmt.training - Epoch   2, Step:    32300, Batch Loss:    16.740421, Tokens per Sec:     3643, Lr: 0.000200
2022-01-20 13:36:52,067 - INFO - joeynmt.training - Epoch   2, Step:    32400, Batch Loss:     5.240136, Tokens per Sec:     3362, Lr: 0.000200
2022-01-20 13:37:10,625 - INFO - joeynmt.training - Epoch   2, Step:    32500, Batch Loss:     2.839876, Tokens per Sec:     3656, Lr: 0.000200
2022-01-20 13:37:29,414 - INFO - joeynmt.training - Epoch   2, Step:    32600, Batch Loss:    14.434333, Tokens per Sec:     3520, Lr: 0.000200
2022-01-20 13:37:48,294 - INFO - joeynmt.training - Epoch   2, Step:    32700, Batch Loss:     5.328563, Tokens per Sec:     3640, Lr: 0.000200
2022-01-20 13:38:07,572 - INFO - joeynmt.training - Epoch   2, Step:    32800, Batch Loss:     4.183789, Tokens per Sec:     3519, Lr: 0.000200
2022-01-20 13:38:27,138 - INFO - joeynmt.training - Epoch   2, Step:    32900, Batch Loss:     8.274856, Tokens per Sec:     3487, Lr: 0.000200
2022-01-20 13:38:45,778 - INFO - joeynmt.training - Epoch   2, Step:    33000, Batch Loss:     6.083523, Tokens per Sec:     3601, Lr: 0.000200
2022-01-20 14:00:49,873 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 14:01:22,611 - INFO - joeynmt.helpers - delete models/a_model/31000.ckpt
2022-01-20 14:01:22,697 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/31000.ckpt
2022-01-20 14:01:22,698 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/31000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/31000.ckpt')
2022-01-20 14:01:22,730 - INFO - joeynmt.training - Example #0
2022-01-20 14:01:22,730 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 14:01:22,730 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 14:01:22,730 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 14:01:22,731 - INFO - joeynmt.training - Example #1
2022-01-20 14:01:22,731 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 14:01:22,731 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 14:01:22,731 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 14:01:22,731 - INFO - joeynmt.training - Example #2
2022-01-20 14:01:22,731 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 14:01:22,731 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 14:01:22,731 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 14:01:22,732 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    33000: bleu:  82.29, loss: 446054.3125, ppl:   1.3192, duration: 1356.9531s
2022-01-20 14:01:41,652 - INFO - joeynmt.training - Epoch   2, Step:    33100, Batch Loss:     5.703814, Tokens per Sec:     3571, Lr: 0.000200
2022-01-20 14:02:00,731 - INFO - joeynmt.training - Epoch   2, Step:    33200, Batch Loss:     7.648195, Tokens per Sec:     3555, Lr: 0.000200
2022-01-20 14:02:19,598 - INFO - joeynmt.training - Epoch   2, Step:    33300, Batch Loss:     6.338770, Tokens per Sec:     3570, Lr: 0.000200
2022-01-20 14:02:38,353 - INFO - joeynmt.training - Epoch   2, Step:    33400, Batch Loss:     5.696527, Tokens per Sec:     3753, Lr: 0.000200
2022-01-20 14:02:57,179 - INFO - joeynmt.training - Epoch   2, Step:    33500, Batch Loss:     2.910241, Tokens per Sec:     3539, Lr: 0.000200
2022-01-20 14:03:15,829 - INFO - joeynmt.training - Epoch   2, Step:    33600, Batch Loss:     6.302162, Tokens per Sec:     3586, Lr: 0.000200
2022-01-20 14:03:34,610 - INFO - joeynmt.training - Epoch   2, Step:    33700, Batch Loss:     9.186490, Tokens per Sec:     3664, Lr: 0.000200
2022-01-20 14:03:54,137 - INFO - joeynmt.training - Epoch   2, Step:    33800, Batch Loss:     9.917810, Tokens per Sec:     3532, Lr: 0.000200
2022-01-20 14:04:13,335 - INFO - joeynmt.training - Epoch   2, Step:    33900, Batch Loss:     4.275121, Tokens per Sec:     3501, Lr: 0.000200
2022-01-20 14:04:32,201 - INFO - joeynmt.training - Epoch   2, Step:    34000, Batch Loss:     5.373729, Tokens per Sec:     3577, Lr: 0.000200
2022-01-20 14:26:18,815 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 14:26:51,545 - INFO - joeynmt.helpers - delete models/a_model/33000.ckpt
2022-01-20 14:26:51,629 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/33000.ckpt
2022-01-20 14:26:51,629 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/33000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/33000.ckpt')
2022-01-20 14:26:51,727 - INFO - joeynmt.training - Example #0
2022-01-20 14:26:51,727 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 14:26:51,727 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 14:26:51,727 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 14:26:51,727 - INFO - joeynmt.training - Example #1
2022-01-20 14:26:51,728 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 14:26:51,728 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 14:26:51,728 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 14:26:51,728 - INFO - joeynmt.training - Example #2
2022-01-20 14:26:51,728 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 14:26:51,728 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 14:26:51,728 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 14:26:51,729 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    34000: bleu:  82.36, loss: 434855.8125, ppl:   1.3101, duration: 1339.5278s
2022-01-20 14:27:10,902 - INFO - joeynmt.training - Epoch   2, Step:    34100, Batch Loss:    11.502706, Tokens per Sec:     3473, Lr: 0.000200
2022-01-20 14:27:29,751 - INFO - joeynmt.training - Epoch   2, Step:    34200, Batch Loss:    48.599022, Tokens per Sec:     3683, Lr: 0.000200
2022-01-20 14:27:48,285 - INFO - joeynmt.training - Epoch   2, Step:    34300, Batch Loss:     5.871789, Tokens per Sec:     3688, Lr: 0.000200
2022-01-20 14:28:07,164 - INFO - joeynmt.training - Epoch   2, Step:    34400, Batch Loss:     4.892831, Tokens per Sec:     3670, Lr: 0.000200
2022-01-20 14:28:26,000 - INFO - joeynmt.training - Epoch   2, Step:    34500, Batch Loss:     3.890262, Tokens per Sec:     3563, Lr: 0.000200
2022-01-20 14:28:44,696 - INFO - joeynmt.training - Epoch   2, Step:    34600, Batch Loss:     3.349720, Tokens per Sec:     3711, Lr: 0.000200
2022-01-20 14:29:03,433 - INFO - joeynmt.training - Epoch   2, Step:    34700, Batch Loss:    11.058162, Tokens per Sec:     3691, Lr: 0.000200
2022-01-20 14:29:22,253 - INFO - joeynmt.training - Epoch   2, Step:    34800, Batch Loss:     5.435122, Tokens per Sec:     3635, Lr: 0.000200
2022-01-20 14:29:41,308 - INFO - joeynmt.training - Epoch   2, Step:    34900, Batch Loss:     9.453697, Tokens per Sec:     3515, Lr: 0.000200
2022-01-20 14:30:00,214 - INFO - joeynmt.training - Epoch   2, Step:    35000, Batch Loss:     4.312974, Tokens per Sec:     3573, Lr: 0.000200
2022-01-20 14:52:01,837 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 14:52:34,563 - INFO - joeynmt.helpers - delete models/a_model/34000.ckpt
2022-01-20 14:52:34,646 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/34000.ckpt
2022-01-20 14:52:34,647 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/34000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/34000.ckpt')
2022-01-20 14:52:34,773 - INFO - joeynmt.training - Example #0
2022-01-20 14:52:34,773 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 14:52:34,773 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 14:52:34,773 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 14:52:34,773 - INFO - joeynmt.training - Example #1
2022-01-20 14:52:34,773 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 14:52:34,774 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 14:52:34,774 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 14:52:34,774 - INFO - joeynmt.training - Example #2
2022-01-20 14:52:34,774 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 14:52:34,774 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 14:52:34,774 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 14:52:34,775 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    35000: bleu:  82.66, loss: 423383.5625, ppl:   1.3008, duration: 1354.5607s
2022-01-20 14:52:53,785 - INFO - joeynmt.training - Epoch   2, Step:    35100, Batch Loss:     6.784171, Tokens per Sec:     3445, Lr: 0.000200
2022-01-20 14:53:12,622 - INFO - joeynmt.training - Epoch   2, Step:    35200, Batch Loss:     6.524579, Tokens per Sec:     3591, Lr: 0.000200
2022-01-20 14:53:31,327 - INFO - joeynmt.training - Epoch   2, Step:    35300, Batch Loss:     3.540226, Tokens per Sec:     3411, Lr: 0.000200
2022-01-20 14:53:49,894 - INFO - joeynmt.training - Epoch   2, Step:    35400, Batch Loss:     6.693564, Tokens per Sec:     3724, Lr: 0.000200
2022-01-20 14:54:08,542 - INFO - joeynmt.training - Epoch   2, Step:    35500, Batch Loss:     4.424348, Tokens per Sec:     3569, Lr: 0.000200
2022-01-20 14:54:26,990 - INFO - joeynmt.training - Epoch   2, Step:    35600, Batch Loss:     6.588016, Tokens per Sec:     3536, Lr: 0.000200
2022-01-20 14:54:46,089 - INFO - joeynmt.training - Epoch   2, Step:    35700, Batch Loss:    23.266745, Tokens per Sec:     3602, Lr: 0.000200
2022-01-20 14:55:04,884 - INFO - joeynmt.training - Epoch   2, Step:    35800, Batch Loss:     7.982826, Tokens per Sec:     3664, Lr: 0.000200
2022-01-20 14:55:23,871 - INFO - joeynmt.training - Epoch   2, Step:    35900, Batch Loss:    10.189501, Tokens per Sec:     3587, Lr: 0.000200
2022-01-20 14:55:42,231 - INFO - joeynmt.training - Epoch   2, Step:    36000, Batch Loss:     2.732823, Tokens per Sec:     3561, Lr: 0.000200
2022-01-20 15:17:46,611 - INFO - joeynmt.training - Example #0
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 15:17:46,612 - INFO - joeynmt.training - Example #1
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 15:17:46,612 - INFO - joeynmt.training - Example #2
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 15:17:46,612 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 15:17:46,613 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    36000: bleu:  82.55, loss: 429250.0000, ppl:   1.3055, duration: 1324.3814s
2022-01-20 15:18:05,452 - INFO - joeynmt.training - Epoch   2, Step:    36100, Batch Loss:     6.551771, Tokens per Sec:     3556, Lr: 0.000200
2022-01-20 15:18:24,558 - INFO - joeynmt.training - Epoch   2, Step:    36200, Batch Loss:     5.882257, Tokens per Sec:     3491, Lr: 0.000200
2022-01-20 15:18:43,074 - INFO - joeynmt.training - Epoch   2, Step:    36300, Batch Loss:     4.546839, Tokens per Sec:     3659, Lr: 0.000200
2022-01-20 15:19:01,755 - INFO - joeynmt.training - Epoch   2, Step:    36400, Batch Loss:     7.500669, Tokens per Sec:     3646, Lr: 0.000200
2022-01-20 15:19:21,026 - INFO - joeynmt.training - Epoch   2, Step:    36500, Batch Loss:     5.349262, Tokens per Sec:     3625, Lr: 0.000200
2022-01-20 15:19:39,516 - INFO - joeynmt.training - Epoch   2, Step:    36600, Batch Loss:     7.944008, Tokens per Sec:     3689, Lr: 0.000200
2022-01-20 15:19:58,283 - INFO - joeynmt.training - Epoch   2, Step:    36700, Batch Loss:     5.324954, Tokens per Sec:     3526, Lr: 0.000200
2022-01-20 15:20:17,079 - INFO - joeynmt.training - Epoch   2, Step:    36800, Batch Loss:     4.397637, Tokens per Sec:     3573, Lr: 0.000200
2022-01-20 15:20:35,837 - INFO - joeynmt.training - Epoch   2, Step:    36900, Batch Loss:     3.566838, Tokens per Sec:     3546, Lr: 0.000200
2022-01-20 15:20:54,808 - INFO - joeynmt.training - Epoch   2, Step:    37000, Batch Loss:     2.880947, Tokens per Sec:     3568, Lr: 0.000200
2022-01-20 15:42:42,620 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 15:43:15,373 - INFO - joeynmt.helpers - delete models/a_model/35000.ckpt
2022-01-20 15:43:15,458 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/35000.ckpt
2022-01-20 15:43:15,459 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/35000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/35000.ckpt')
2022-01-20 15:43:15,555 - INFO - joeynmt.training - Example #0
2022-01-20 15:43:15,555 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 15:43:15,555 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 15:43:15,555 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 15:43:15,555 - INFO - joeynmt.training - Example #1
2022-01-20 15:43:15,555 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 15:43:15,555 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 15:43:15,555 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 15:43:15,555 - INFO - joeynmt.training - Example #2
2022-01-20 15:43:15,555 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 15:43:15,555 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 15:43:15,556 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 15:43:15,556 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    37000: bleu:  82.89, loss: 411220.2188, ppl:   1.2910, duration: 1340.7471s
2022-01-20 15:43:34,626 - INFO - joeynmt.training - Epoch   2, Step:    37100, Batch Loss:     4.566508, Tokens per Sec:     3428, Lr: 0.000200
2022-01-20 15:43:53,162 - INFO - joeynmt.training - Epoch   2, Step:    37200, Batch Loss:     8.632888, Tokens per Sec:     3715, Lr: 0.000200
2022-01-20 15:44:11,732 - INFO - joeynmt.training - Epoch   2, Step:    37300, Batch Loss:     9.757383, Tokens per Sec:     3593, Lr: 0.000200
2022-01-20 15:44:30,659 - INFO - joeynmt.training - Epoch   2, Step:    37400, Batch Loss:     6.254944, Tokens per Sec:     3506, Lr: 0.000200
2022-01-20 15:44:49,747 - INFO - joeynmt.training - Epoch   2, Step:    37500, Batch Loss:     5.655094, Tokens per Sec:     3504, Lr: 0.000200
2022-01-20 15:45:08,440 - INFO - joeynmt.training - Epoch   2, Step:    37600, Batch Loss:     6.707881, Tokens per Sec:     3574, Lr: 0.000200
2022-01-20 15:45:26,684 - INFO - joeynmt.training - Epoch   2, Step:    37700, Batch Loss:     8.971461, Tokens per Sec:     3572, Lr: 0.000200
2022-01-20 15:45:45,113 - INFO - joeynmt.training - Epoch   2, Step:    37800, Batch Loss:     6.650384, Tokens per Sec:     3597, Lr: 0.000200
2022-01-20 15:46:04,523 - INFO - joeynmt.training - Epoch   2, Step:    37900, Batch Loss:     4.879927, Tokens per Sec:     3455, Lr: 0.000200
2022-01-20 15:46:23,167 - INFO - joeynmt.training - Epoch   2, Step:    38000, Batch Loss:     3.693783, Tokens per Sec:     3689, Lr: 0.000200
2022-01-20 16:08:14,357 - INFO - joeynmt.training - Example #0
2022-01-20 16:08:14,358 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 16:08:14,358 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 16:08:14,358 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 16:08:14,358 - INFO - joeynmt.training - Example #1
2022-01-20 16:08:14,358 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 16:08:14,358 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 16:08:14,358 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 16:08:14,358 - INFO - joeynmt.training - Example #2
2022-01-20 16:08:14,359 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 16:08:14,359 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 16:08:14,359 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 16:08:14,359 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    38000: bleu:  82.85, loss: 415794.4688, ppl:   1.2946, duration: 1311.1917s
2022-01-20 16:08:33,392 - INFO - joeynmt.training - Epoch   2, Step:    38100, Batch Loss:     8.032789, Tokens per Sec:     3545, Lr: 0.000200
2022-01-20 16:08:51,808 - INFO - joeynmt.training - Epoch   2, Step:    38200, Batch Loss:    11.286988, Tokens per Sec:     3611, Lr: 0.000200
2022-01-20 16:09:10,501 - INFO - joeynmt.training - Epoch   2, Step:    38300, Batch Loss:     9.677620, Tokens per Sec:     3491, Lr: 0.000200
2022-01-20 16:09:29,100 - INFO - joeynmt.training - Epoch   2, Step:    38400, Batch Loss:     3.428346, Tokens per Sec:     3663, Lr: 0.000200
2022-01-20 16:09:47,568 - INFO - joeynmt.training - Epoch   2, Step:    38500, Batch Loss:     6.283384, Tokens per Sec:     3579, Lr: 0.000200
2022-01-20 16:10:06,240 - INFO - joeynmt.training - Epoch   2, Step:    38600, Batch Loss:     8.220464, Tokens per Sec:     3664, Lr: 0.000200
2022-01-20 16:10:24,872 - INFO - joeynmt.training - Epoch   2, Step:    38700, Batch Loss:     1.800638, Tokens per Sec:     3618, Lr: 0.000200
2022-01-20 16:10:43,634 - INFO - joeynmt.training - Epoch   2, Step:    38800, Batch Loss:     7.701101, Tokens per Sec:     3539, Lr: 0.000200
2022-01-20 16:11:02,461 - INFO - joeynmt.training - Epoch   2, Step:    38900, Batch Loss:     7.325748, Tokens per Sec:     3768, Lr: 0.000200
2022-01-20 16:11:21,222 - INFO - joeynmt.training - Epoch   2, Step:    39000, Batch Loss:     5.877913, Tokens per Sec:     3626, Lr: 0.000200
2022-01-20 16:33:06,803 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 16:33:40,456 - INFO - joeynmt.helpers - delete models/a_model/37000.ckpt
2022-01-20 16:33:40,493 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/37000.ckpt
2022-01-20 16:33:40,494 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/37000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/37000.ckpt')
2022-01-20 16:33:40,602 - INFO - joeynmt.training - Example #0
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 16:33:40,603 - INFO - joeynmt.training - Example #1
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 16:33:40,603 - INFO - joeynmt.training - Example #2
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 16:33:40,603 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 16:33:40,604 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    39000: bleu:  83.08, loss: 401898.1875, ppl:   1.2835, duration: 1339.3820s
2022-01-20 16:33:59,887 - INFO - joeynmt.training - Epoch   2, Step:    39100, Batch Loss:     6.660637, Tokens per Sec:     3450, Lr: 0.000200
2022-01-20 16:34:18,554 - INFO - joeynmt.training - Epoch   2, Step:    39200, Batch Loss:     9.415044, Tokens per Sec:     3598, Lr: 0.000200
2022-01-20 16:34:37,163 - INFO - joeynmt.training - Epoch   2, Step:    39300, Batch Loss:     7.194554, Tokens per Sec:     3666, Lr: 0.000200
2022-01-20 16:34:56,461 - INFO - joeynmt.training - Epoch   2, Step:    39400, Batch Loss:     6.212277, Tokens per Sec:     3513, Lr: 0.000200
2022-01-20 16:35:15,818 - INFO - joeynmt.training - Epoch   2, Step:    39500, Batch Loss:     4.561399, Tokens per Sec:     3505, Lr: 0.000200
2022-01-20 16:35:35,384 - INFO - joeynmt.training - Epoch   2, Step:    39600, Batch Loss:    17.475620, Tokens per Sec:     3570, Lr: 0.000200
2022-01-20 16:35:54,997 - INFO - joeynmt.training - Epoch   2, Step:    39700, Batch Loss:     6.077570, Tokens per Sec:     3458, Lr: 0.000200
2022-01-20 16:36:14,622 - INFO - joeynmt.training - Epoch   2, Step:    39800, Batch Loss:     4.818726, Tokens per Sec:     3494, Lr: 0.000200
2022-01-20 16:36:33,127 - INFO - joeynmt.training - Epoch   2, Step:    39900, Batch Loss:     5.659976, Tokens per Sec:     3615, Lr: 0.000200
2022-01-20 16:36:51,699 - INFO - joeynmt.training - Epoch   2, Step:    40000, Batch Loss:     5.418540, Tokens per Sec:     3623, Lr: 0.000200
2022-01-20 16:58:47,948 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 16:59:20,705 - INFO - joeynmt.helpers - delete models/a_model/39000.ckpt
2022-01-20 16:59:20,742 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/39000.ckpt
2022-01-20 16:59:20,743 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/39000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/39000.ckpt')
2022-01-20 16:59:20,924 - INFO - joeynmt.training - Example #0
2022-01-20 16:59:20,924 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 16:59:20,924 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 16:59:20,924 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 16:59:20,924 - INFO - joeynmt.training - Example #1
2022-01-20 16:59:20,924 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 16:59:20,924 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 16:59:20,924 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-20 16:59:20,925 - INFO - joeynmt.training - Example #2
2022-01-20 16:59:20,925 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 16:59:20,925 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 16:59:20,925 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-20 16:59:20,926 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    40000: bleu:  83.16, loss: 399534.2500, ppl:   1.2816, duration: 1349.2262s
2022-01-20 16:59:40,289 - INFO - joeynmt.training - Epoch   2, Step:    40100, Batch Loss:     6.611701, Tokens per Sec:     3440, Lr: 0.000200
2022-01-20 16:59:59,242 - INFO - joeynmt.training - Epoch   2, Step:    40200, Batch Loss:     7.164934, Tokens per Sec:     3600, Lr: 0.000200
2022-01-20 17:00:18,079 - INFO - joeynmt.training - Epoch   2, Step:    40300, Batch Loss:     4.690217, Tokens per Sec:     3531, Lr: 0.000200
2022-01-20 17:00:37,101 - INFO - joeynmt.training - Epoch   2, Step:    40400, Batch Loss:     2.174352, Tokens per Sec:     3577, Lr: 0.000200
2022-01-20 17:00:56,129 - INFO - joeynmt.training - Epoch   2, Step:    40500, Batch Loss:     4.506619, Tokens per Sec:     3566, Lr: 0.000200
2022-01-20 17:01:15,144 - INFO - joeynmt.training - Epoch   2, Step:    40600, Batch Loss:     7.323452, Tokens per Sec:     3414, Lr: 0.000200
2022-01-20 17:01:34,106 - INFO - joeynmt.training - Epoch   2, Step:    40700, Batch Loss:     6.048880, Tokens per Sec:     3584, Lr: 0.000200
2022-01-20 17:01:52,895 - INFO - joeynmt.training - Epoch   2, Step:    40800, Batch Loss:     9.502399, Tokens per Sec:     3461, Lr: 0.000200
2022-01-20 17:02:11,814 - INFO - joeynmt.training - Epoch   2, Step:    40900, Batch Loss:     5.305133, Tokens per Sec:     3614, Lr: 0.000200
2022-01-20 17:02:30,666 - INFO - joeynmt.training - Epoch   2, Step:    41000, Batch Loss:     3.442413, Tokens per Sec:     3547, Lr: 0.000200
2022-01-20 17:24:18,551 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 17:24:51,263 - INFO - joeynmt.helpers - delete models/a_model/40000.ckpt
2022-01-20 17:24:51,345 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/40000.ckpt
2022-01-20 17:24:51,346 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/40000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/40000.ckpt')
2022-01-20 17:24:51,531 - INFO - joeynmt.training - Example #0
2022-01-20 17:24:51,532 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 17:24:51,532 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 17:24:51,532 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 17:24:51,532 - INFO - joeynmt.training - Example #1
2022-01-20 17:24:51,532 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 17:24:51,532 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 17:24:51,532 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 17:24:51,532 - INFO - joeynmt.training - Example #2
2022-01-20 17:24:51,533 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 17:24:51,533 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 17:24:51,533 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-20 17:24:51,533 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    41000: bleu:  83.23, loss: 404923.1250, ppl:   1.2859, duration: 1340.8673s
2022-01-20 17:25:10,536 - INFO - joeynmt.training - Epoch   2, Step:    41100, Batch Loss:     7.979258, Tokens per Sec:     3594, Lr: 0.000200
2022-01-20 17:25:28,650 - INFO - joeynmt.training - Epoch   2, Step:    41200, Batch Loss:     4.769358, Tokens per Sec:     3745, Lr: 0.000200
2022-01-20 17:25:47,239 - INFO - joeynmt.training - Epoch   2, Step:    41300, Batch Loss:     5.217213, Tokens per Sec:     3650, Lr: 0.000200
2022-01-20 17:26:06,231 - INFO - joeynmt.training - Epoch   2, Step:    41400, Batch Loss:     3.137954, Tokens per Sec:     3551, Lr: 0.000200
2022-01-20 17:26:24,893 - INFO - joeynmt.training - Epoch   2, Step:    41500, Batch Loss:     5.036587, Tokens per Sec:     3696, Lr: 0.000200
2022-01-20 17:26:43,908 - INFO - joeynmt.training - Epoch   2, Step:    41600, Batch Loss:     6.594646, Tokens per Sec:     3494, Lr: 0.000200
2022-01-20 17:27:02,527 - INFO - joeynmt.training - Epoch   2, Step:    41700, Batch Loss:     5.863863, Tokens per Sec:     3682, Lr: 0.000200
2022-01-20 17:27:21,060 - INFO - joeynmt.training - Epoch   2, Step:    41800, Batch Loss:     7.024818, Tokens per Sec:     3655, Lr: 0.000200
2022-01-20 17:27:40,170 - INFO - joeynmt.training - Epoch   2, Step:    41900, Batch Loss:     4.790027, Tokens per Sec:     3583, Lr: 0.000200
2022-01-20 17:27:58,882 - INFO - joeynmt.training - Epoch   2, Step:    42000, Batch Loss:     7.082546, Tokens per Sec:     3517, Lr: 0.000200
2022-01-20 17:49:48,266 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 17:50:21,029 - INFO - joeynmt.helpers - delete models/a_model/41000.ckpt
2022-01-20 17:50:21,060 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/41000.ckpt
2022-01-20 17:50:21,061 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/41000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/41000.ckpt')
2022-01-20 17:50:21,178 - INFO - joeynmt.training - Example #0
2022-01-20 17:50:21,178 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 17:50:21,178 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 17:50:21,178 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 17:50:21,178 - INFO - joeynmt.training - Example #1
2022-01-20 17:50:21,179 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 17:50:21,179 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 17:50:21,179 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 17:50:21,179 - INFO - joeynmt.training - Example #2
2022-01-20 17:50:21,179 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 17:50:21,179 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 17:50:21,179 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 17:50:21,180 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    42000: bleu:  83.73, loss: 390661.7812, ppl:   1.2746, duration: 1342.2973s
2022-01-20 17:50:40,047 - INFO - joeynmt.training - Epoch   2, Step:    42100, Batch Loss:    14.477052, Tokens per Sec:     3527, Lr: 0.000200
2022-01-20 17:50:58,488 - INFO - joeynmt.training - Epoch   2, Step:    42200, Batch Loss:     3.751588, Tokens per Sec:     3674, Lr: 0.000200
2022-01-20 17:51:16,850 - INFO - joeynmt.training - Epoch   2, Step:    42300, Batch Loss:     1.879483, Tokens per Sec:     3685, Lr: 0.000200
2022-01-20 17:51:35,420 - INFO - joeynmt.training - Epoch   2, Step:    42400, Batch Loss:     4.190084, Tokens per Sec:     3662, Lr: 0.000200
2022-01-20 17:51:54,229 - INFO - joeynmt.training - Epoch   2, Step:    42500, Batch Loss:     7.475971, Tokens per Sec:     3524, Lr: 0.000200
2022-01-20 17:52:13,086 - INFO - joeynmt.training - Epoch   2, Step:    42600, Batch Loss:     9.728180, Tokens per Sec:     3550, Lr: 0.000200
2022-01-20 17:52:31,634 - INFO - joeynmt.training - Epoch   2, Step:    42700, Batch Loss:     3.878165, Tokens per Sec:     3652, Lr: 0.000200
2022-01-20 17:52:50,262 - INFO - joeynmt.training - Epoch   2, Step:    42800, Batch Loss:     5.369157, Tokens per Sec:     3637, Lr: 0.000200
2022-01-20 17:53:09,020 - INFO - joeynmt.training - Epoch   2, Step:    42900, Batch Loss:     7.967847, Tokens per Sec:     3592, Lr: 0.000200
2022-01-20 17:53:27,568 - INFO - joeynmt.training - Epoch   2, Step:    43000, Batch Loss:     4.988259, Tokens per Sec:     3535, Lr: 0.000200
2022-01-20 18:15:17,218 - INFO - joeynmt.training - Example #0
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 18:15:17,219 - INFO - joeynmt.training - Example #1
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 18:15:17,219 - INFO - joeynmt.training - Example #2
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 18:15:17,219 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 18:15:17,220 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    43000: bleu:  83.06, loss: 410676.0312, ppl:   1.2905, duration: 1309.6515s
2022-01-20 18:15:36,476 - INFO - joeynmt.training - Epoch   2, Step:    43100, Batch Loss:    12.356643, Tokens per Sec:     3419, Lr: 0.000200
2022-01-20 18:15:55,420 - INFO - joeynmt.training - Epoch   2, Step:    43200, Batch Loss:    11.177669, Tokens per Sec:     3607, Lr: 0.000200
2022-01-20 18:16:14,091 - INFO - joeynmt.training - Epoch   2, Step:    43300, Batch Loss:     5.005901, Tokens per Sec:     3608, Lr: 0.000200
2022-01-20 18:16:33,101 - INFO - joeynmt.training - Epoch   2, Step:    43400, Batch Loss:    26.909235, Tokens per Sec:     3501, Lr: 0.000200
2022-01-20 18:16:52,264 - INFO - joeynmt.training - Epoch   2, Step:    43500, Batch Loss:     6.873357, Tokens per Sec:     3605, Lr: 0.000200
2022-01-20 18:17:11,834 - INFO - joeynmt.training - Epoch   2, Step:    43600, Batch Loss:     6.398246, Tokens per Sec:     3444, Lr: 0.000200
2022-01-20 18:17:30,271 - INFO - joeynmt.training - Epoch   2, Step:    43700, Batch Loss:    10.125456, Tokens per Sec:     3674, Lr: 0.000200
2022-01-20 18:17:48,874 - INFO - joeynmt.training - Epoch   2, Step:    43800, Batch Loss:     4.170318, Tokens per Sec:     3838, Lr: 0.000200
2022-01-20 18:18:07,357 - INFO - joeynmt.training - Epoch   2, Step:    43900, Batch Loss:     5.331857, Tokens per Sec:     3665, Lr: 0.000200
2022-01-20 18:18:25,730 - INFO - joeynmt.training - Epoch   2, Step:    44000, Batch Loss:     4.859183, Tokens per Sec:     3768, Lr: 0.000200
2022-01-20 18:40:20,260 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 18:40:53,107 - INFO - joeynmt.helpers - delete models/a_model/42000.ckpt
2022-01-20 18:40:53,159 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/42000.ckpt
2022-01-20 18:40:53,160 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/42000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/42000.ckpt')
2022-01-20 18:40:53,192 - INFO - joeynmt.training - Example #0
2022-01-20 18:40:53,192 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 18:40:53,192 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 18:40:53,192 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 18:40:53,192 - INFO - joeynmt.training - Example #1
2022-01-20 18:40:53,193 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 18:40:53,193 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 18:40:53,193 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 18:40:53,193 - INFO - joeynmt.training - Example #2
2022-01-20 18:40:53,193 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 18:40:53,193 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 18:40:53,193 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 18:40:53,194 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    44000: bleu:  83.78, loss: 385438.2500, ppl:   1.2705, duration: 1347.4638s
2022-01-20 18:41:12,319 - INFO - joeynmt.training - Epoch   2, Step:    44100, Batch Loss:     8.708974, Tokens per Sec:     3615, Lr: 0.000200
2022-01-20 18:41:31,066 - INFO - joeynmt.training - Epoch   2, Step:    44200, Batch Loss:    16.236229, Tokens per Sec:     3664, Lr: 0.000200
2022-01-20 18:41:49,915 - INFO - joeynmt.training - Epoch   2, Step:    44300, Batch Loss:     3.991169, Tokens per Sec:     3541, Lr: 0.000200
2022-01-20 18:42:08,828 - INFO - joeynmt.training - Epoch   2, Step:    44400, Batch Loss:     4.592260, Tokens per Sec:     3659, Lr: 0.000200
2022-01-20 18:42:27,812 - INFO - joeynmt.training - Epoch   2, Step:    44500, Batch Loss:     4.244464, Tokens per Sec:     3511, Lr: 0.000200
2022-01-20 18:42:46,806 - INFO - joeynmt.training - Epoch   2, Step:    44600, Batch Loss:     5.008487, Tokens per Sec:     3560, Lr: 0.000200
2022-01-20 18:43:05,804 - INFO - joeynmt.training - Epoch   2, Step:    44700, Batch Loss:     5.180600, Tokens per Sec:     3596, Lr: 0.000200
2022-01-20 18:43:24,814 - INFO - joeynmt.training - Epoch   2, Step:    44800, Batch Loss:     5.028854, Tokens per Sec:     3568, Lr: 0.000200
2022-01-20 18:43:43,599 - INFO - joeynmt.training - Epoch   2, Step:    44900, Batch Loss:    16.109634, Tokens per Sec:     3679, Lr: 0.000200
2022-01-20 18:44:02,466 - INFO - joeynmt.training - Epoch   2, Step:    45000, Batch Loss:     9.656174, Tokens per Sec:     3495, Lr: 0.000200
2022-01-20 19:05:50,176 - INFO - joeynmt.training - Example #0
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 19:05:50,178 - INFO - joeynmt.training - Example #1
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-20 19:05:50,178 - INFO - joeynmt.training - Example #2
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 19:05:50,178 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 19:05:50,179 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    45000: bleu:  83.71, loss: 402676.8125, ppl:   1.2841, duration: 1307.7126s
2022-01-20 19:06:09,803 - INFO - joeynmt.training - Epoch   2, Step:    45100, Batch Loss:    14.675737, Tokens per Sec:     3518, Lr: 0.000200
2022-01-20 19:06:28,693 - INFO - joeynmt.training - Epoch   2, Step:    45200, Batch Loss:     4.923657, Tokens per Sec:     3496, Lr: 0.000200
2022-01-20 19:06:47,578 - INFO - joeynmt.training - Epoch   2, Step:    45300, Batch Loss:     2.957014, Tokens per Sec:     3606, Lr: 0.000200
2022-01-20 19:07:06,682 - INFO - joeynmt.training - Epoch   2, Step:    45400, Batch Loss:     5.718966, Tokens per Sec:     3528, Lr: 0.000200
2022-01-20 19:07:25,566 - INFO - joeynmt.training - Epoch   2, Step:    45500, Batch Loss:     4.749220, Tokens per Sec:     3639, Lr: 0.000200
2022-01-20 19:07:44,693 - INFO - joeynmt.training - Epoch   2, Step:    45600, Batch Loss:     4.965189, Tokens per Sec:     3560, Lr: 0.000200
2022-01-20 19:08:03,835 - INFO - joeynmt.training - Epoch   2, Step:    45700, Batch Loss:     2.011378, Tokens per Sec:     3493, Lr: 0.000200
2022-01-20 19:08:22,597 - INFO - joeynmt.training - Epoch   2, Step:    45800, Batch Loss:     3.674941, Tokens per Sec:     3623, Lr: 0.000200
2022-01-20 19:08:41,518 - INFO - joeynmt.training - Epoch   2, Step:    45900, Batch Loss:     7.402675, Tokens per Sec:     3494, Lr: 0.000200
2022-01-20 19:09:00,320 - INFO - joeynmt.training - Epoch   2, Step:    46000, Batch Loss:     6.630051, Tokens per Sec:     3597, Lr: 0.000200
2022-01-20 19:30:47,341 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 19:31:20,055 - INFO - joeynmt.helpers - delete models/a_model/44000.ckpt
2022-01-20 19:31:20,105 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/44000.ckpt
2022-01-20 19:31:20,106 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/44000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/44000.ckpt')
2022-01-20 19:31:20,266 - INFO - joeynmt.training - Example #0
2022-01-20 19:31:20,266 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 19:31:20,266 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 19:31:20,266 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 19:31:20,266 - INFO - joeynmt.training - Example #1
2022-01-20 19:31:20,266 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 19:31:20,266 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 19:31:20,266 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 19:31:20,266 - INFO - joeynmt.training - Example #2
2022-01-20 19:31:20,267 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 19:31:20,267 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 19:31:20,267 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-20 19:31:20,267 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    46000: bleu:  83.79, loss: 377120.5312, ppl:   1.2639, duration: 1339.9470s
2022-01-20 19:31:39,573 - INFO - joeynmt.training - Epoch   2, Step:    46100, Batch Loss:     7.283326, Tokens per Sec:     3549, Lr: 0.000200
2022-01-20 19:31:58,353 - INFO - joeynmt.training - Epoch   2, Step:    46200, Batch Loss:     4.897941, Tokens per Sec:     3576, Lr: 0.000200
2022-01-20 19:32:17,049 - INFO - joeynmt.training - Epoch   2, Step:    46300, Batch Loss:     4.634282, Tokens per Sec:     3658, Lr: 0.000200
2022-01-20 19:32:36,156 - INFO - joeynmt.training - Epoch   2, Step:    46400, Batch Loss:     7.901433, Tokens per Sec:     3466, Lr: 0.000200
2022-01-20 19:32:55,063 - INFO - joeynmt.training - Epoch   2, Step:    46500, Batch Loss:     5.997115, Tokens per Sec:     3515, Lr: 0.000200
2022-01-20 19:33:13,729 - INFO - joeynmt.training - Epoch   2, Step:    46600, Batch Loss:    11.490064, Tokens per Sec:     3576, Lr: 0.000200
2022-01-20 19:33:32,703 - INFO - joeynmt.training - Epoch   2, Step:    46700, Batch Loss:     4.247888, Tokens per Sec:     3498, Lr: 0.000200
2022-01-20 19:33:51,265 - INFO - joeynmt.training - Epoch   2, Step:    46800, Batch Loss:     3.300735, Tokens per Sec:     3656, Lr: 0.000200
2022-01-20 19:34:10,071 - INFO - joeynmt.training - Epoch   2, Step:    46900, Batch Loss:     8.499219, Tokens per Sec:     3564, Lr: 0.000200
2022-01-20 19:34:28,828 - INFO - joeynmt.training - Epoch   2, Step:    47000, Batch Loss:     7.496854, Tokens per Sec:     3712, Lr: 0.000200
2022-01-20 19:56:39,416 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 19:57:12,129 - INFO - joeynmt.helpers - delete models/a_model/46000.ckpt
2022-01-20 19:57:12,221 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/46000.ckpt
2022-01-20 19:57:12,222 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/46000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/46000.ckpt')
2022-01-20 19:57:12,321 - INFO - joeynmt.training - Example #0
2022-01-20 19:57:12,321 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 19:57:12,321 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 19:57:12,321 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 19:57:12,321 - INFO - joeynmt.training - Example #1
2022-01-20 19:57:12,321 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 19:57:12,322 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 19:57:12,322 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 19:57:12,322 - INFO - joeynmt.training - Example #2
2022-01-20 19:57:12,322 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 19:57:12,322 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 19:57:12,322 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 19:57:12,323 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    47000: bleu:  83.99, loss: 376241.8750, ppl:   1.2632, duration: 1363.4945s
2022-01-20 19:57:30,928 - INFO - joeynmt.training - Epoch   2, Step:    47100, Batch Loss:     4.345779, Tokens per Sec:     3566, Lr: 0.000200
2022-01-20 19:57:49,829 - INFO - joeynmt.training - Epoch   2, Step:    47200, Batch Loss:     9.633268, Tokens per Sec:     3596, Lr: 0.000200
2022-01-20 19:58:08,572 - INFO - joeynmt.training - Epoch   2, Step:    47300, Batch Loss:     2.905774, Tokens per Sec:     3673, Lr: 0.000200
2022-01-20 19:58:27,393 - INFO - joeynmt.training - Epoch   2, Step:    47400, Batch Loss:     8.380842, Tokens per Sec:     3616, Lr: 0.000200
2022-01-20 19:58:45,972 - INFO - joeynmt.training - Epoch   2, Step:    47500, Batch Loss:     5.021339, Tokens per Sec:     3675, Lr: 0.000200
2022-01-20 19:59:04,917 - INFO - joeynmt.training - Epoch   2, Step:    47600, Batch Loss:     4.802964, Tokens per Sec:     3588, Lr: 0.000200
2022-01-20 19:59:50,925 - INFO - joeynmt.training - Epoch   2, Step:    47700, Batch Loss:     4.223111, Tokens per Sec:     1469, Lr: 0.000200
2022-01-20 20:00:19,584 - INFO - joeynmt.training - Epoch   2, Step:    47800, Batch Loss:     6.729678, Tokens per Sec:     2380, Lr: 0.000200
2022-01-20 20:00:47,243 - INFO - joeynmt.training - Epoch   2, Step:    47900, Batch Loss:     6.215816, Tokens per Sec:     2513, Lr: 0.000200
2022-01-20 20:01:13,262 - INFO - joeynmt.training - Epoch   2, Step:    48000, Batch Loss:     5.370203, Tokens per Sec:     2651, Lr: 0.000200
2022-01-20 20:22:57,919 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 20:23:30,658 - INFO - joeynmt.helpers - delete models/a_model/47000.ckpt
2022-01-20 20:23:30,754 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/47000.ckpt
2022-01-20 20:23:30,755 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/47000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/47000.ckpt')
2022-01-20 20:23:30,854 - INFO - joeynmt.training - Example #0
2022-01-20 20:23:30,854 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 20:23:30,854 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 20:23:30,854 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 20:23:30,854 - INFO - joeynmt.training - Example #1
2022-01-20 20:23:30,854 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 20:23:30,854 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 20:23:30,854 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 20:23:30,854 - INFO - joeynmt.training - Example #2
2022-01-20 20:23:30,855 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 20:23:30,855 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 20:23:30,855 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 20:23:30,856 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    48000: bleu:  84.58, loss: 362227.8438, ppl:   1.2523, duration: 1337.5929s
2022-01-20 20:23:49,894 - INFO - joeynmt.training - Epoch   2, Step:    48100, Batch Loss:     5.573575, Tokens per Sec:     3474, Lr: 0.000200
2022-01-20 20:24:08,635 - INFO - joeynmt.training - Epoch   2, Step:    48200, Batch Loss:     6.677962, Tokens per Sec:     3508, Lr: 0.000200
2022-01-20 20:24:27,474 - INFO - joeynmt.training - Epoch   2, Step:    48300, Batch Loss:     9.337638, Tokens per Sec:     3601, Lr: 0.000200
2022-01-20 20:24:46,200 - INFO - joeynmt.training - Epoch   2, Step:    48400, Batch Loss:     2.111791, Tokens per Sec:     3569, Lr: 0.000200
2022-01-20 20:25:04,851 - INFO - joeynmt.training - Epoch   2, Step:    48500, Batch Loss:     4.859557, Tokens per Sec:     3548, Lr: 0.000200
2022-01-20 20:25:23,709 - INFO - joeynmt.training - Epoch   2, Step:    48600, Batch Loss:     5.364493, Tokens per Sec:     3554, Lr: 0.000200
2022-01-20 20:25:42,515 - INFO - joeynmt.training - Epoch   2, Step:    48700, Batch Loss:    11.819614, Tokens per Sec:     3577, Lr: 0.000200
2022-01-20 20:26:01,466 - INFO - joeynmt.training - Epoch   2, Step:    48800, Batch Loss:     5.269660, Tokens per Sec:     3427, Lr: 0.000200
2022-01-20 20:26:20,130 - INFO - joeynmt.training - Epoch   2, Step:    48900, Batch Loss:     4.712527, Tokens per Sec:     3497, Lr: 0.000200
2022-01-20 20:26:38,551 - INFO - joeynmt.training - Epoch   2, Step:    49000, Batch Loss:     5.802595, Tokens per Sec:     3660, Lr: 0.000200
2022-01-20 20:48:22,420 - INFO - joeynmt.training - Example #0
2022-01-20 20:48:22,421 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 20:48:22,422 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 20:48:22,422 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-20 20:48:22,422 - INFO - joeynmt.training - Example #1
2022-01-20 20:48:22,422 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 20:48:22,422 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 20:48:22,422 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 20:48:22,422 - INFO - joeynmt.training - Example #2
2022-01-20 20:48:22,422 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 20:48:22,422 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 20:48:22,422 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 20:48:22,423 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    49000: bleu:  84.17, loss: 366539.3750, ppl:   1.2556, duration: 1303.8716s
2022-01-20 20:48:41,842 - INFO - joeynmt.training - Epoch   2, Step:    49100, Batch Loss:     4.685862, Tokens per Sec:     3650, Lr: 0.000200
2022-01-20 20:49:00,451 - INFO - joeynmt.training - Epoch   2, Step:    49200, Batch Loss:     9.677899, Tokens per Sec:     3583, Lr: 0.000200
2022-01-20 20:49:19,223 - INFO - joeynmt.training - Epoch   2, Step:    49300, Batch Loss:     7.163769, Tokens per Sec:     3649, Lr: 0.000200
2022-01-20 20:49:37,955 - INFO - joeynmt.training - Epoch   2, Step:    49400, Batch Loss:     7.238617, Tokens per Sec:     3632, Lr: 0.000200
2022-01-20 20:49:56,423 - INFO - joeynmt.training - Epoch   2, Step:    49500, Batch Loss:     3.685340, Tokens per Sec:     3781, Lr: 0.000200
2022-01-20 20:50:15,017 - INFO - joeynmt.training - Epoch   2, Step:    49600, Batch Loss:     1.751838, Tokens per Sec:     3621, Lr: 0.000200
2022-01-20 20:50:33,744 - INFO - joeynmt.training - Epoch   2, Step:    49700, Batch Loss:    11.213584, Tokens per Sec:     3729, Lr: 0.000200
2022-01-20 20:50:52,172 - INFO - joeynmt.training - Epoch   2, Step:    49800, Batch Loss:     4.721979, Tokens per Sec:     3590, Lr: 0.000200
2022-01-20 20:51:10,608 - INFO - joeynmt.training - Epoch   2, Step:    49900, Batch Loss:     4.254849, Tokens per Sec:     3642, Lr: 0.000200
2022-01-20 20:51:29,374 - INFO - joeynmt.training - Epoch   2, Step:    50000, Batch Loss:     9.256652, Tokens per Sec:     3521, Lr: 0.000200
2022-01-20 21:13:30,587 - INFO - joeynmt.training - Example #0
2022-01-20 21:13:30,588 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 21:13:30,588 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 21:13:30,588 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 33 12 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 21:13:30,588 - INFO - joeynmt.training - Example #1
2022-01-20 21:13:30,588 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 21:13:30,589 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 21:13:30,589 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 21:13:30,589 - INFO - joeynmt.training - Example #2
2022-01-20 21:13:30,589 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 21:13:30,589 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 21:13:30,589 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 21:13:30,590 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    50000: bleu:  83.87, loss: 369371.5625, ppl:   1.2579, duration: 1321.2150s
2022-01-20 21:13:49,932 - INFO - joeynmt.training - Epoch   2, Step:    50100, Batch Loss:     5.339746, Tokens per Sec:     3468, Lr: 0.000200
2022-01-20 21:14:08,800 - INFO - joeynmt.training - Epoch   2, Step:    50200, Batch Loss:     5.489638, Tokens per Sec:     3535, Lr: 0.000200
2022-01-20 21:14:27,467 - INFO - joeynmt.training - Epoch   2, Step:    50300, Batch Loss:     5.273970, Tokens per Sec:     3586, Lr: 0.000200
2022-01-20 21:14:46,435 - INFO - joeynmt.training - Epoch   2, Step:    50400, Batch Loss:     3.331489, Tokens per Sec:     3589, Lr: 0.000200
2022-01-20 21:15:05,182 - INFO - joeynmt.training - Epoch   2, Step:    50500, Batch Loss:     4.324476, Tokens per Sec:     3570, Lr: 0.000200
2022-01-20 21:15:24,025 - INFO - joeynmt.training - Epoch   2, Step:    50600, Batch Loss:     2.852241, Tokens per Sec:     3492, Lr: 0.000200
2022-01-20 21:15:42,652 - INFO - joeynmt.training - Epoch   2, Step:    50700, Batch Loss:     5.423450, Tokens per Sec:     3608, Lr: 0.000200
2022-01-20 21:16:01,196 - INFO - joeynmt.training - Epoch   2, Step:    50800, Batch Loss:     4.712768, Tokens per Sec:     3436, Lr: 0.000200
2022-01-20 21:16:20,097 - INFO - joeynmt.training - Epoch   2, Step:    50900, Batch Loss:     5.737572, Tokens per Sec:     3537, Lr: 0.000200
2022-01-20 21:16:38,974 - INFO - joeynmt.training - Epoch   2, Step:    51000, Batch Loss:     5.883686, Tokens per Sec:     3578, Lr: 0.000200
2022-01-20 21:38:35,241 - INFO - joeynmt.training - Example #0
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 21:38:35,242 - INFO - joeynmt.training - Example #1
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 21:38:35,242 - INFO - joeynmt.training - Example #2
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 21:38:35,242 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 21:38:35,243 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    51000: bleu:  84.52, loss: 361546.5312, ppl:   1.2518, duration: 1316.2691s
2022-01-20 21:38:54,429 - INFO - joeynmt.training - Epoch   2, Step:    51100, Batch Loss:     4.870000, Tokens per Sec:     3512, Lr: 0.000200
2022-01-20 21:39:13,047 - INFO - joeynmt.training - Epoch   2, Step:    51200, Batch Loss:     5.589818, Tokens per Sec:     3649, Lr: 0.000200
2022-01-20 21:39:31,830 - INFO - joeynmt.training - Epoch   2, Step:    51300, Batch Loss:     7.199699, Tokens per Sec:     3600, Lr: 0.000200
2022-01-20 21:39:50,616 - INFO - joeynmt.training - Epoch   2, Step:    51400, Batch Loss:     6.102107, Tokens per Sec:     3614, Lr: 0.000200
2022-01-20 21:40:09,409 - INFO - joeynmt.training - Epoch   2, Step:    51500, Batch Loss:     8.974370, Tokens per Sec:     3599, Lr: 0.000200
2022-01-20 21:40:28,221 - INFO - joeynmt.training - Epoch   2, Step:    51600, Batch Loss:     2.916486, Tokens per Sec:     3740, Lr: 0.000200
2022-01-20 21:40:47,161 - INFO - joeynmt.training - Epoch   2, Step:    51700, Batch Loss:     5.881356, Tokens per Sec:     3500, Lr: 0.000200
2022-01-20 21:41:05,896 - INFO - joeynmt.training - Epoch   2, Step:    51800, Batch Loss:     9.991654, Tokens per Sec:     3666, Lr: 0.000200
2022-01-20 21:41:24,578 - INFO - joeynmt.training - Epoch   2, Step:    51900, Batch Loss:     4.594681, Tokens per Sec:     3613, Lr: 0.000200
2022-01-20 21:41:43,356 - INFO - joeynmt.training - Epoch   2, Step:    52000, Batch Loss:    21.970322, Tokens per Sec:     3747, Lr: 0.000200
2022-01-20 22:03:26,595 - INFO - joeynmt.training - Example #0
2022-01-20 22:03:26,596 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 22:03:26,596 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 22:03:26,596 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 22:03:26,596 - INFO - joeynmt.training - Example #1
2022-01-20 22:03:26,596 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 22:03:26,596 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 22:03:26,597 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 22:03:26,597 - INFO - joeynmt.training - Example #2
2022-01-20 22:03:26,597 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 22:03:26,597 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 22:03:26,597 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-20 22:03:26,598 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    52000: bleu:  83.78, loss: 365418.4062, ppl:   1.2548, duration: 1303.2415s
2022-01-20 22:03:45,901 - INFO - joeynmt.training - Epoch   2, Step:    52100, Batch Loss:     5.134559, Tokens per Sec:     3550, Lr: 0.000200
2022-01-20 22:04:04,745 - INFO - joeynmt.training - Epoch   2, Step:    52200, Batch Loss:     4.047046, Tokens per Sec:     3598, Lr: 0.000200
2022-01-20 22:04:23,452 - INFO - joeynmt.training - Epoch   2, Step:    52300, Batch Loss:     3.903418, Tokens per Sec:     3472, Lr: 0.000200
2022-01-20 22:04:42,201 - INFO - joeynmt.training - Epoch   2, Step:    52400, Batch Loss:     9.036310, Tokens per Sec:     3714, Lr: 0.000200
2022-01-20 22:05:00,800 - INFO - joeynmt.training - Epoch   2, Step:    52500, Batch Loss:     6.892829, Tokens per Sec:     3619, Lr: 0.000200
2022-01-20 22:05:19,291 - INFO - joeynmt.training - Epoch   2, Step:    52600, Batch Loss:     2.850310, Tokens per Sec:     3506, Lr: 0.000200
2022-01-20 22:05:38,161 - INFO - joeynmt.training - Epoch   2, Step:    52700, Batch Loss:     6.870107, Tokens per Sec:     3575, Lr: 0.000200
2022-01-20 22:05:56,983 - INFO - joeynmt.training - Epoch   2, Step:    52800, Batch Loss:     3.771825, Tokens per Sec:     3406, Lr: 0.000200
2022-01-20 22:06:15,765 - INFO - joeynmt.training - Epoch   2, Step:    52900, Batch Loss:     7.455969, Tokens per Sec:     3606, Lr: 0.000200
2022-01-20 22:06:34,688 - INFO - joeynmt.training - Epoch   2, Step:    53000, Batch Loss:     5.928380, Tokens per Sec:     3554, Lr: 0.000200
2022-01-20 22:28:22,615 - INFO - joeynmt.training - Example #0
2022-01-20 22:28:22,616 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 22:28:22,616 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 22:28:22,616 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 22:28:22,616 - INFO - joeynmt.training - Example #1
2022-01-20 22:28:22,616 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 22:28:22,617 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 22:28:22,617 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 22:28:22,617 - INFO - joeynmt.training - Example #2
2022-01-20 22:28:22,617 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 22:28:22,617 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 22:28:22,617 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 22:28:22,618 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    53000: bleu:  84.47, loss: 347627.5625, ppl:   1.2410, duration: 1307.9287s
2022-01-20 22:28:41,852 - INFO - joeynmt.training - Epoch   2, Step:    53100, Batch Loss:     5.610710, Tokens per Sec:     3551, Lr: 0.000200
2022-01-20 22:28:47,911 - INFO - joeynmt.training - Epoch   2: total training loss 187412.32
2022-01-20 22:28:47,911 - INFO - joeynmt.training - EPOCH 3
2022-01-20 22:29:01,098 - INFO - joeynmt.training - Epoch   3, Step:    53200, Batch Loss:     3.022897, Tokens per Sec:     3409, Lr: 0.000200
2022-01-20 22:29:19,852 - INFO - joeynmt.training - Epoch   3, Step:    53300, Batch Loss:     2.336434, Tokens per Sec:     3539, Lr: 0.000200
2022-01-20 22:29:38,663 - INFO - joeynmt.training - Epoch   3, Step:    53400, Batch Loss:     4.513680, Tokens per Sec:     3676, Lr: 0.000200
2022-01-20 22:29:57,437 - INFO - joeynmt.training - Epoch   3, Step:    53500, Batch Loss:     3.127044, Tokens per Sec:     3627, Lr: 0.000200
2022-01-20 22:30:16,366 - INFO - joeynmt.training - Epoch   3, Step:    53600, Batch Loss:     3.877979, Tokens per Sec:     3539, Lr: 0.000200
2022-01-20 22:30:35,379 - INFO - joeynmt.training - Epoch   3, Step:    53700, Batch Loss:     1.693192, Tokens per Sec:     3542, Lr: 0.000200
2022-01-20 22:30:54,270 - INFO - joeynmt.training - Epoch   3, Step:    53800, Batch Loss:     4.218831, Tokens per Sec:     3655, Lr: 0.000200
2022-01-20 22:31:12,763 - INFO - joeynmt.training - Epoch   3, Step:    53900, Batch Loss:    12.760912, Tokens per Sec:     3602, Lr: 0.000200
2022-01-20 22:31:31,605 - INFO - joeynmt.training - Epoch   3, Step:    54000, Batch Loss:     4.618977, Tokens per Sec:     3583, Lr: 0.000200
2022-01-20 22:53:12,010 - INFO - joeynmt.training - Example #0
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-20 22:53:12,012 - INFO - joeynmt.training - Example #1
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 22:53:12,012 - INFO - joeynmt.training - Example #2
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 22:53:12,012 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-20 22:53:12,013 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    54000: bleu:  84.38, loss: 357681.1875, ppl:   1.2488, duration: 1300.4078s
2022-01-20 22:53:31,525 - INFO - joeynmt.training - Epoch   3, Step:    54100, Batch Loss:     2.931286, Tokens per Sec:     3345, Lr: 0.000200
2022-01-20 22:53:50,117 - INFO - joeynmt.training - Epoch   3, Step:    54200, Batch Loss:     5.326023, Tokens per Sec:     3715, Lr: 0.000200
2022-01-20 22:54:08,686 - INFO - joeynmt.training - Epoch   3, Step:    54300, Batch Loss:     3.153016, Tokens per Sec:     3657, Lr: 0.000200
2022-01-20 22:54:27,453 - INFO - joeynmt.training - Epoch   3, Step:    54400, Batch Loss:    10.151545, Tokens per Sec:     3528, Lr: 0.000200
2022-01-20 22:54:46,189 - INFO - joeynmt.training - Epoch   3, Step:    54500, Batch Loss:     3.532507, Tokens per Sec:     3609, Lr: 0.000200
2022-01-20 22:55:04,779 - INFO - joeynmt.training - Epoch   3, Step:    54600, Batch Loss:     5.976254, Tokens per Sec:     3575, Lr: 0.000200
2022-01-20 22:55:23,317 - INFO - joeynmt.training - Epoch   3, Step:    54700, Batch Loss:     6.571660, Tokens per Sec:     3589, Lr: 0.000200
2022-01-20 22:55:42,046 - INFO - joeynmt.training - Epoch   3, Step:    54800, Batch Loss:     6.797694, Tokens per Sec:     3482, Lr: 0.000200
2022-01-20 22:56:00,628 - INFO - joeynmt.training - Epoch   3, Step:    54900, Batch Loss:     5.448352, Tokens per Sec:     3647, Lr: 0.000200
2022-01-20 22:56:19,076 - INFO - joeynmt.training - Epoch   3, Step:    55000, Batch Loss:     3.801357, Tokens per Sec:     3543, Lr: 0.000200
2022-01-20 23:18:09,793 - INFO - joeynmt.training - Example #0
2022-01-20 23:18:09,794 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 23:18:09,794 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 23:18:09,794 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-20 23:18:09,794 - INFO - joeynmt.training - Example #1
2022-01-20 23:18:09,794 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 23:18:09,795 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 23:18:09,795 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-20 23:18:09,795 - INFO - joeynmt.training - Example #2
2022-01-20 23:18:09,795 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 23:18:09,795 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 23:18:09,795 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-20 23:18:09,796 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    55000: bleu:  84.44, loss: 359475.8438, ppl:   1.2501, duration: 1310.7191s
2022-01-20 23:18:28,484 - INFO - joeynmt.training - Epoch   3, Step:    55100, Batch Loss:     4.421845, Tokens per Sec:     3629, Lr: 0.000200
2022-01-20 23:18:46,987 - INFO - joeynmt.training - Epoch   3, Step:    55200, Batch Loss:     2.396898, Tokens per Sec:     3693, Lr: 0.000200
2022-01-20 23:19:05,341 - INFO - joeynmt.training - Epoch   3, Step:    55300, Batch Loss:     5.450122, Tokens per Sec:     3648, Lr: 0.000200
2022-01-20 23:19:23,662 - INFO - joeynmt.training - Epoch   3, Step:    55400, Batch Loss:     2.819439, Tokens per Sec:     3601, Lr: 0.000200
2022-01-20 23:19:41,995 - INFO - joeynmt.training - Epoch   3, Step:    55500, Batch Loss:     4.693411, Tokens per Sec:     3616, Lr: 0.000200
2022-01-20 23:20:00,292 - INFO - joeynmt.training - Epoch   3, Step:    55600, Batch Loss:    21.226580, Tokens per Sec:     3719, Lr: 0.000200
2022-01-20 23:20:18,604 - INFO - joeynmt.training - Epoch   3, Step:    55700, Batch Loss:     3.372470, Tokens per Sec:     3678, Lr: 0.000200
2022-01-20 23:20:37,194 - INFO - joeynmt.training - Epoch   3, Step:    55800, Batch Loss:     8.551155, Tokens per Sec:     3610, Lr: 0.000200
2022-01-20 23:20:56,493 - INFO - joeynmt.training - Epoch   3, Step:    55900, Batch Loss:    16.005890, Tokens per Sec:     3634, Lr: 0.000200
2022-01-20 23:21:15,217 - INFO - joeynmt.training - Epoch   3, Step:    56000, Batch Loss:     6.667919, Tokens per Sec:     3560, Lr: 0.000200
2022-01-20 23:42:59,313 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-20 23:43:32,058 - INFO - joeynmt.helpers - delete models/a_model/48000.ckpt
2022-01-20 23:43:32,092 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/48000.ckpt
2022-01-20 23:43:32,092 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/48000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/48000.ckpt')
2022-01-20 23:43:32,191 - INFO - joeynmt.training - Example #0
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-20 23:43:32,192 - INFO - joeynmt.training - Example #1
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-20 23:43:32,192 - INFO - joeynmt.training - Example #2
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 23:43:32,192 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-20 23:43:32,193 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    56000: bleu:  84.80, loss: 353211.7188, ppl:   1.2453, duration: 1336.9761s
2022-01-20 23:43:51,891 - INFO - joeynmt.training - Epoch   3, Step:    56100, Batch Loss:     3.993672, Tokens per Sec:     3596, Lr: 0.000200
2022-01-20 23:44:10,473 - INFO - joeynmt.training - Epoch   3, Step:    56200, Batch Loss:     3.923676, Tokens per Sec:     3643, Lr: 0.000200
2022-01-20 23:44:28,998 - INFO - joeynmt.training - Epoch   3, Step:    56300, Batch Loss:     5.498606, Tokens per Sec:     3624, Lr: 0.000200
2022-01-20 23:44:47,544 - INFO - joeynmt.training - Epoch   3, Step:    56400, Batch Loss:     4.275804, Tokens per Sec:     3620, Lr: 0.000200
2022-01-20 23:45:06,164 - INFO - joeynmt.training - Epoch   3, Step:    56500, Batch Loss:     2.212553, Tokens per Sec:     3575, Lr: 0.000200
2022-01-20 23:45:24,844 - INFO - joeynmt.training - Epoch   3, Step:    56600, Batch Loss:     7.957911, Tokens per Sec:     3697, Lr: 0.000200
2022-01-20 23:45:43,553 - INFO - joeynmt.training - Epoch   3, Step:    56700, Batch Loss:     4.230816, Tokens per Sec:     3628, Lr: 0.000200
2022-01-20 23:46:02,359 - INFO - joeynmt.training - Epoch   3, Step:    56800, Batch Loss:     8.473007, Tokens per Sec:     3594, Lr: 0.000200
2022-01-20 23:46:21,035 - INFO - joeynmt.training - Epoch   3, Step:    56900, Batch Loss:    10.513232, Tokens per Sec:     3484, Lr: 0.000200
2022-01-20 23:46:39,819 - INFO - joeynmt.training - Epoch   3, Step:    57000, Batch Loss:    11.307626, Tokens per Sec:     3530, Lr: 0.000200
2022-01-21 00:08:22,526 - INFO - joeynmt.training - Example #0
2022-01-21 00:08:22,527 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 00:08:22,528 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 00:08:22,528 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 00:08:22,528 - INFO - joeynmt.training - Example #1
2022-01-21 00:08:22,528 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 00:08:22,528 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 00:08:22,528 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 00:08:22,528 - INFO - joeynmt.training - Example #2
2022-01-21 00:08:22,528 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 00:08:22,528 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 00:08:22,528 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 00:08:22,529 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    57000: bleu:  84.57, loss: 353855.8438, ppl:   1.2458, duration: 1302.7098s
2022-01-21 00:08:41,316 - INFO - joeynmt.training - Epoch   3, Step:    57100, Batch Loss:     8.956538, Tokens per Sec:     3543, Lr: 0.000200
2022-01-21 00:08:59,534 - INFO - joeynmt.training - Epoch   3, Step:    57200, Batch Loss:     3.964020, Tokens per Sec:     3696, Lr: 0.000200
2022-01-21 00:09:18,096 - INFO - joeynmt.training - Epoch   3, Step:    57300, Batch Loss:     3.170938, Tokens per Sec:     3632, Lr: 0.000200
2022-01-21 00:09:36,637 - INFO - joeynmt.training - Epoch   3, Step:    57400, Batch Loss:     4.323154, Tokens per Sec:     3694, Lr: 0.000200
2022-01-21 00:09:55,035 - INFO - joeynmt.training - Epoch   3, Step:    57500, Batch Loss:     5.267064, Tokens per Sec:     3606, Lr: 0.000200
2022-01-21 00:10:13,744 - INFO - joeynmt.training - Epoch   3, Step:    57600, Batch Loss:     5.784999, Tokens per Sec:     3717, Lr: 0.000200
2022-01-21 00:10:32,352 - INFO - joeynmt.training - Epoch   3, Step:    57700, Batch Loss:     3.463163, Tokens per Sec:     3674, Lr: 0.000200
2022-01-21 00:10:51,014 - INFO - joeynmt.training - Epoch   3, Step:    57800, Batch Loss:     7.151124, Tokens per Sec:     3530, Lr: 0.000200
2022-01-21 00:11:09,449 - INFO - joeynmt.training - Epoch   3, Step:    57900, Batch Loss:     2.962350, Tokens per Sec:     3664, Lr: 0.000200
2022-01-21 00:11:28,321 - INFO - joeynmt.training - Epoch   3, Step:    58000, Batch Loss:     4.494886, Tokens per Sec:     3591, Lr: 0.000200
2022-01-21 00:33:23,922 - INFO - joeynmt.training - Example #0
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 00:33:23,924 - INFO - joeynmt.training - Example #1
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 00:33:23,924 - INFO - joeynmt.training - Example #2
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 00:33:23,924 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 00:33:23,925 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    58000: bleu:  84.74, loss: 349301.5312, ppl:   1.2423, duration: 1315.6033s
2022-01-21 00:33:42,644 - INFO - joeynmt.training - Epoch   3, Step:    58100, Batch Loss:     5.606874, Tokens per Sec:     3524, Lr: 0.000200
2022-01-21 00:34:01,201 - INFO - joeynmt.training - Epoch   3, Step:    58200, Batch Loss:     5.958742, Tokens per Sec:     3545, Lr: 0.000200
2022-01-21 00:34:19,564 - INFO - joeynmt.training - Epoch   3, Step:    58300, Batch Loss:     3.598681, Tokens per Sec:     3768, Lr: 0.000200
2022-01-21 00:34:37,927 - INFO - joeynmt.training - Epoch   3, Step:    58400, Batch Loss:     3.898513, Tokens per Sec:     3719, Lr: 0.000200
2022-01-21 00:34:56,267 - INFO - joeynmt.training - Epoch   3, Step:    58500, Batch Loss:     3.409531, Tokens per Sec:     3680, Lr: 0.000200
2022-01-21 00:35:14,406 - INFO - joeynmt.training - Epoch   3, Step:    58600, Batch Loss:     4.697628, Tokens per Sec:     3693, Lr: 0.000200
2022-01-21 00:35:32,769 - INFO - joeynmt.training - Epoch   3, Step:    58700, Batch Loss:     8.706799, Tokens per Sec:     3704, Lr: 0.000200
2022-01-21 00:35:51,120 - INFO - joeynmt.training - Epoch   3, Step:    58800, Batch Loss:     2.495651, Tokens per Sec:     3648, Lr: 0.000200
2022-01-21 00:36:09,441 - INFO - joeynmt.training - Epoch   3, Step:    58900, Batch Loss:     4.680500, Tokens per Sec:     3709, Lr: 0.000200
2022-01-21 00:36:28,058 - INFO - joeynmt.training - Epoch   3, Step:    59000, Batch Loss:     4.610183, Tokens per Sec:     3662, Lr: 0.000200
2022-01-21 00:58:21,057 - INFO - joeynmt.training - Example #0
2022-01-21 00:58:21,058 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 00:58:21,058 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 00:58:21,059 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 00:58:21,059 - INFO - joeynmt.training - Example #1
2022-01-21 00:58:21,059 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 00:58:21,059 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 00:58:21,059 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-21 00:58:21,059 - INFO - joeynmt.training - Example #2
2022-01-21 00:58:21,059 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 00:58:21,059 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 00:58:21,059 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-21 00:58:21,060 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    59000: bleu:  84.69, loss: 347721.4062, ppl:   1.2411, duration: 1313.0017s
2022-01-21 00:58:40,392 - INFO - joeynmt.training - Epoch   3, Step:    59100, Batch Loss:     6.932395, Tokens per Sec:     3399, Lr: 0.000200
2022-01-21 00:58:59,307 - INFO - joeynmt.training - Epoch   3, Step:    59200, Batch Loss:     3.984179, Tokens per Sec:     3524, Lr: 0.000200
2022-01-21 00:59:18,117 - INFO - joeynmt.training - Epoch   3, Step:    59300, Batch Loss:     4.589490, Tokens per Sec:     3601, Lr: 0.000200
2022-01-21 00:59:36,727 - INFO - joeynmt.training - Epoch   3, Step:    59400, Batch Loss:     6.467637, Tokens per Sec:     3655, Lr: 0.000200
2022-01-21 00:59:55,517 - INFO - joeynmt.training - Epoch   3, Step:    59500, Batch Loss:     3.670567, Tokens per Sec:     3595, Lr: 0.000200
2022-01-21 01:00:14,296 - INFO - joeynmt.training - Epoch   3, Step:    59600, Batch Loss:     3.303499, Tokens per Sec:     3625, Lr: 0.000200
2022-01-21 01:00:33,121 - INFO - joeynmt.training - Epoch   3, Step:    59700, Batch Loss:     3.953943, Tokens per Sec:     3531, Lr: 0.000200
2022-01-21 01:00:51,561 - INFO - joeynmt.training - Epoch   3, Step:    59800, Batch Loss:     5.125750, Tokens per Sec:     3670, Lr: 0.000200
2022-01-21 01:01:10,320 - INFO - joeynmt.training - Epoch   3, Step:    59900, Batch Loss:     6.623527, Tokens per Sec:     3564, Lr: 0.000200
2022-01-21 01:01:29,031 - INFO - joeynmt.training - Epoch   3, Step:    60000, Batch Loss:     5.028863, Tokens per Sec:     3618, Lr: 0.000200
2022-01-21 01:23:24,023 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 01:23:57,019 - INFO - joeynmt.helpers - delete models/a_model/56000.ckpt
2022-01-21 01:23:57,102 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/56000.ckpt
2022-01-21 01:23:57,103 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/56000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/56000.ckpt')
2022-01-21 01:23:57,146 - INFO - joeynmt.training - Example #0
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 01:23:57,147 - INFO - joeynmt.training - Example #1
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 01:23:57,147 - INFO - joeynmt.training - Example #2
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 01:23:57,147 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 01:23:57,148 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    60000: bleu:  84.93, loss: 342100.7812, ppl:   1.2367, duration: 1348.1164s
2022-01-21 01:24:16,436 - INFO - joeynmt.training - Epoch   3, Step:    60100, Batch Loss:     9.014831, Tokens per Sec:     3524, Lr: 0.000200
2022-01-21 01:24:35,423 - INFO - joeynmt.training - Epoch   3, Step:    60200, Batch Loss:     3.956788, Tokens per Sec:     3498, Lr: 0.000200
2022-01-21 01:24:54,668 - INFO - joeynmt.training - Epoch   3, Step:    60300, Batch Loss:     7.351171, Tokens per Sec:     3499, Lr: 0.000200
2022-01-21 01:25:13,309 - INFO - joeynmt.training - Epoch   3, Step:    60400, Batch Loss:     3.599677, Tokens per Sec:     3625, Lr: 0.000200
2022-01-21 01:25:32,287 - INFO - joeynmt.training - Epoch   3, Step:    60500, Batch Loss:     7.897568, Tokens per Sec:     3559, Lr: 0.000200
2022-01-21 01:25:51,021 - INFO - joeynmt.training - Epoch   3, Step:    60600, Batch Loss:     6.893692, Tokens per Sec:     3625, Lr: 0.000200
2022-01-21 01:26:10,130 - INFO - joeynmt.training - Epoch   3, Step:    60700, Batch Loss:     6.169505, Tokens per Sec:     3598, Lr: 0.000200
2022-01-21 01:26:28,843 - INFO - joeynmt.training - Epoch   3, Step:    60800, Batch Loss:     4.090619, Tokens per Sec:     3649, Lr: 0.000200
2022-01-21 01:26:47,511 - INFO - joeynmt.training - Epoch   3, Step:    60900, Batch Loss:     3.227118, Tokens per Sec:     3665, Lr: 0.000200
2022-01-21 01:27:06,375 - INFO - joeynmt.training - Epoch   3, Step:    61000, Batch Loss:     4.369514, Tokens per Sec:     3592, Lr: 0.000200
2022-01-21 01:49:15,011 - INFO - joeynmt.training - Example #0
2022-01-21 01:49:15,012 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 01:49:15,013 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 01:49:15,013 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 01:49:15,013 - INFO - joeynmt.training - Example #1
2022-01-21 01:49:15,013 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 01:49:15,013 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 01:49:15,013 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 01:49:15,013 - INFO - joeynmt.training - Example #2
2022-01-21 01:49:15,013 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 01:49:15,013 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 01:49:15,013 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-21 01:49:15,014 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    61000: bleu:  84.90, loss: 333714.4062, ppl:   1.2303, duration: 1328.6386s
2022-01-21 01:49:34,028 - INFO - joeynmt.training - Epoch   3, Step:    61100, Batch Loss:     6.964815, Tokens per Sec:     3498, Lr: 0.000200
2022-01-21 01:49:52,585 - INFO - joeynmt.training - Epoch   3, Step:    61200, Batch Loss:     2.953653, Tokens per Sec:     3695, Lr: 0.000200
2022-01-21 01:50:11,229 - INFO - joeynmt.training - Epoch   3, Step:    61300, Batch Loss:     4.077791, Tokens per Sec:     3575, Lr: 0.000200
2022-01-21 01:50:29,920 - INFO - joeynmt.training - Epoch   3, Step:    61400, Batch Loss:     3.734429, Tokens per Sec:     3692, Lr: 0.000200
2022-01-21 01:50:48,460 - INFO - joeynmt.training - Epoch   3, Step:    61500, Batch Loss:     3.776697, Tokens per Sec:     3558, Lr: 0.000200
2022-01-21 01:51:07,271 - INFO - joeynmt.training - Epoch   3, Step:    61600, Batch Loss:     2.359152, Tokens per Sec:     3577, Lr: 0.000200
2022-01-21 01:51:25,704 - INFO - joeynmt.training - Epoch   3, Step:    61700, Batch Loss:     6.593966, Tokens per Sec:     3557, Lr: 0.000200
2022-01-21 01:51:44,386 - INFO - joeynmt.training - Epoch   3, Step:    61800, Batch Loss:     4.897180, Tokens per Sec:     3660, Lr: 0.000200
2022-01-21 01:52:02,930 - INFO - joeynmt.training - Epoch   3, Step:    61900, Batch Loss:     7.273852, Tokens per Sec:     3664, Lr: 0.000200
2022-01-21 01:52:21,334 - INFO - joeynmt.training - Epoch   3, Step:    62000, Batch Loss:     6.180224, Tokens per Sec:     3580, Lr: 0.000200
2022-01-21 02:14:11,133 - INFO - joeynmt.training - Example #0
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 02:14:11,135 - INFO - joeynmt.training - Example #1
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 02:14:11,135 - INFO - joeynmt.training - Example #2
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 02:14:11,135 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-21 02:14:11,136 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    62000: bleu:  84.89, loss: 337745.5938, ppl:   1.2334, duration: 1309.8019s
2022-01-21 02:14:29,711 - INFO - joeynmt.training - Epoch   3, Step:    62100, Batch Loss:     6.039418, Tokens per Sec:     3602, Lr: 0.000200
2022-01-21 02:14:47,865 - INFO - joeynmt.training - Epoch   3, Step:    62200, Batch Loss:     4.808570, Tokens per Sec:     3727, Lr: 0.000200
2022-01-21 02:15:06,991 - INFO - joeynmt.training - Epoch   3, Step:    62300, Batch Loss:     5.756389, Tokens per Sec:     3479, Lr: 0.000200
2022-01-21 02:15:26,412 - INFO - joeynmt.training - Epoch   3, Step:    62400, Batch Loss:     5.013467, Tokens per Sec:     3482, Lr: 0.000200
2022-01-21 02:15:45,748 - INFO - joeynmt.training - Epoch   3, Step:    62500, Batch Loss:     3.764163, Tokens per Sec:     3408, Lr: 0.000200
2022-01-21 02:16:05,406 - INFO - joeynmt.training - Epoch   3, Step:    62600, Batch Loss:     6.601650, Tokens per Sec:     3448, Lr: 0.000200
2022-01-21 02:16:24,836 - INFO - joeynmt.training - Epoch   3, Step:    62700, Batch Loss:     3.773555, Tokens per Sec:     3552, Lr: 0.000200
2022-01-21 02:16:43,793 - INFO - joeynmt.training - Epoch   3, Step:    62800, Batch Loss:     3.152444, Tokens per Sec:     3491, Lr: 0.000200
2022-01-21 02:17:02,965 - INFO - joeynmt.training - Epoch   3, Step:    62900, Batch Loss:     4.189902, Tokens per Sec:     3495, Lr: 0.000200
2022-01-21 02:17:21,805 - INFO - joeynmt.training - Epoch   3, Step:    63000, Batch Loss:     3.189856, Tokens per Sec:     3535, Lr: 0.000200
2022-01-21 02:39:04,554 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 02:39:37,860 - INFO - joeynmt.helpers - delete models/a_model/60000.ckpt
2022-01-21 02:39:37,944 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/60000.ckpt
2022-01-21 02:39:37,944 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/60000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/60000.ckpt')
2022-01-21 02:39:38,042 - INFO - joeynmt.training - Example #0
2022-01-21 02:39:38,042 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 02:39:38,042 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 02:39:38,042 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-21 02:39:38,042 - INFO - joeynmt.training - Example #1
2022-01-21 02:39:38,042 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 02:39:38,042 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 02:39:38,043 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-21 02:39:38,043 - INFO - joeynmt.training - Example #2
2022-01-21 02:39:38,043 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 02:39:38,043 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 02:39:38,043 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-21 02:39:38,044 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    63000: bleu:  85.07, loss: 335846.7812, ppl:   1.2319, duration: 1336.2380s
2022-01-21 02:39:57,347 - INFO - joeynmt.training - Epoch   3, Step:    63100, Batch Loss:     4.804133, Tokens per Sec:     3515, Lr: 0.000200
2022-01-21 02:40:16,302 - INFO - joeynmt.training - Epoch   3, Step:    63200, Batch Loss:     3.694226, Tokens per Sec:     3634, Lr: 0.000200
2022-01-21 02:40:35,367 - INFO - joeynmt.training - Epoch   3, Step:    63300, Batch Loss:     5.214530, Tokens per Sec:     3609, Lr: 0.000200
2022-01-21 02:40:54,204 - INFO - joeynmt.training - Epoch   3, Step:    63400, Batch Loss:     5.493251, Tokens per Sec:     3674, Lr: 0.000200
2022-01-21 02:41:13,234 - INFO - joeynmt.training - Epoch   3, Step:    63500, Batch Loss:     5.500284, Tokens per Sec:     3631, Lr: 0.000200
2022-01-21 02:41:32,277 - INFO - joeynmt.training - Epoch   3, Step:    63600, Batch Loss:     4.768467, Tokens per Sec:     3647, Lr: 0.000200
2022-01-21 02:41:51,283 - INFO - joeynmt.training - Epoch   3, Step:    63700, Batch Loss:     3.960059, Tokens per Sec:     3477, Lr: 0.000200
2022-01-21 02:42:10,503 - INFO - joeynmt.training - Epoch   3, Step:    63800, Batch Loss:     3.458286, Tokens per Sec:     3527, Lr: 0.000200
2022-01-21 02:42:29,565 - INFO - joeynmt.training - Epoch   3, Step:    63900, Batch Loss:     4.744832, Tokens per Sec:     3571, Lr: 0.000200
2022-01-21 02:42:48,687 - INFO - joeynmt.training - Epoch   3, Step:    64000, Batch Loss:    16.265980, Tokens per Sec:     3475, Lr: 0.000200
2022-01-21 03:04:34,802 - INFO - joeynmt.training - Example #0
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 03:04:34,804 - INFO - joeynmt.training - Example #1
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 23 34 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 03:04:34,804 - INFO - joeynmt.training - Example #2
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 03:04:34,804 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 30 28 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 03:04:34,805 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    64000: bleu:  85.01, loss: 334254.6562, ppl:   1.2307, duration: 1306.1175s
2022-01-21 03:04:53,563 - INFO - joeynmt.training - Epoch   3, Step:    64100, Batch Loss:     2.175773, Tokens per Sec:     3658, Lr: 0.000200
2022-01-21 03:05:11,855 - INFO - joeynmt.training - Epoch   3, Step:    64200, Batch Loss:     5.254712, Tokens per Sec:     3716, Lr: 0.000200
2022-01-21 03:05:30,484 - INFO - joeynmt.training - Epoch   3, Step:    64300, Batch Loss:     7.240028, Tokens per Sec:     3680, Lr: 0.000200
2022-01-21 03:05:49,040 - INFO - joeynmt.training - Epoch   3, Step:    64400, Batch Loss:     2.133224, Tokens per Sec:     3667, Lr: 0.000200
2022-01-21 03:06:07,618 - INFO - joeynmt.training - Epoch   3, Step:    64500, Batch Loss:     6.040110, Tokens per Sec:     3732, Lr: 0.000200
2022-01-21 03:06:25,999 - INFO - joeynmt.training - Epoch   3, Step:    64600, Batch Loss:     2.795391, Tokens per Sec:     3734, Lr: 0.000200
2022-01-21 03:06:44,269 - INFO - joeynmt.training - Epoch   3, Step:    64700, Batch Loss:     3.234664, Tokens per Sec:     3666, Lr: 0.000200
2022-01-21 03:07:02,592 - INFO - joeynmt.training - Epoch   3, Step:    64800, Batch Loss:     3.038522, Tokens per Sec:     3651, Lr: 0.000200
2022-01-21 03:07:20,998 - INFO - joeynmt.training - Epoch   3, Step:    64900, Batch Loss:     2.250073, Tokens per Sec:     3694, Lr: 0.000200
2022-01-21 03:07:39,358 - INFO - joeynmt.training - Epoch   3, Step:    65000, Batch Loss:     3.480843, Tokens per Sec:     3704, Lr: 0.000200
2022-01-21 03:29:25,583 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 03:29:58,342 - INFO - joeynmt.helpers - delete models/a_model/63000.ckpt
2022-01-21 03:29:58,425 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/63000.ckpt
2022-01-21 03:29:58,426 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/63000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/63000.ckpt')
2022-01-21 03:29:58,519 - INFO - joeynmt.training - Example #0
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 03:29:58,519 - INFO - joeynmt.training - Example #1
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 03:29:58,519 - INFO - joeynmt.training - Example #2
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 03:29:58,519 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 03:29:58,520 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    65000: bleu:  85.21, loss: 325107.9375, ppl:   1.2237, duration: 1339.1620s
2022-01-21 03:30:16,938 - INFO - joeynmt.training - Epoch   3, Step:    65100, Batch Loss:     4.281003, Tokens per Sec:     3486, Lr: 0.000200
2022-01-21 03:30:35,273 - INFO - joeynmt.training - Epoch   3, Step:    65200, Batch Loss:     7.109389, Tokens per Sec:     3717, Lr: 0.000200
2022-01-21 03:30:53,663 - INFO - joeynmt.training - Epoch   3, Step:    65300, Batch Loss:     5.887754, Tokens per Sec:     3705, Lr: 0.000200
2022-01-21 03:31:11,452 - INFO - joeynmt.training - Epoch   3, Step:    65400, Batch Loss:     5.027838, Tokens per Sec:     3774, Lr: 0.000200
2022-01-21 03:31:29,952 - INFO - joeynmt.training - Epoch   3, Step:    65500, Batch Loss:     5.360257, Tokens per Sec:     3704, Lr: 0.000200
2022-01-21 03:31:49,499 - INFO - joeynmt.training - Epoch   3, Step:    65600, Batch Loss:     4.544779, Tokens per Sec:     3496, Lr: 0.000200
2022-01-21 03:32:08,960 - INFO - joeynmt.training - Epoch   3, Step:    65700, Batch Loss:     6.828914, Tokens per Sec:     3472, Lr: 0.000200
2022-01-21 03:32:28,224 - INFO - joeynmt.training - Epoch   3, Step:    65800, Batch Loss:    13.838480, Tokens per Sec:     3408, Lr: 0.000200
2022-01-21 03:32:47,646 - INFO - joeynmt.training - Epoch   3, Step:    65900, Batch Loss:     2.952901, Tokens per Sec:     3467, Lr: 0.000200
2022-01-21 03:33:07,345 - INFO - joeynmt.training - Epoch   3, Step:    66000, Batch Loss:    10.832416, Tokens per Sec:     3436, Lr: 0.000200
2022-01-21 03:54:51,995 - INFO - joeynmt.training - Example #0
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 03:54:51,996 - INFO - joeynmt.training - Example #1
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 03:54:51,996 - INFO - joeynmt.training - Example #2
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 03:54:51,996 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 03:54:51,997 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    66000: bleu:  85.13, loss: 331945.6562, ppl:   1.2289, duration: 1304.6513s
2022-01-21 03:55:10,649 - INFO - joeynmt.training - Epoch   3, Step:    66100, Batch Loss:     4.304423, Tokens per Sec:     3604, Lr: 0.000200
2022-01-21 03:55:29,058 - INFO - joeynmt.training - Epoch   3, Step:    66200, Batch Loss:     4.437387, Tokens per Sec:     3627, Lr: 0.000200
2022-01-21 03:55:47,462 - INFO - joeynmt.training - Epoch   3, Step:    66300, Batch Loss:     5.637090, Tokens per Sec:     3613, Lr: 0.000200
2022-01-21 03:56:05,720 - INFO - joeynmt.training - Epoch   3, Step:    66400, Batch Loss:    13.123421, Tokens per Sec:     3774, Lr: 0.000200
2022-01-21 03:56:24,161 - INFO - joeynmt.training - Epoch   3, Step:    66500, Batch Loss:    11.816158, Tokens per Sec:     3627, Lr: 0.000200
2022-01-21 03:56:42,265 - INFO - joeynmt.training - Epoch   3, Step:    66600, Batch Loss:     2.505369, Tokens per Sec:     3573, Lr: 0.000200
2022-01-21 03:57:00,679 - INFO - joeynmt.training - Epoch   3, Step:    66700, Batch Loss:     4.389287, Tokens per Sec:     3776, Lr: 0.000200
2022-01-21 03:57:19,045 - INFO - joeynmt.training - Epoch   3, Step:    66800, Batch Loss:     3.768165, Tokens per Sec:     3646, Lr: 0.000200
2022-01-21 03:57:37,275 - INFO - joeynmt.training - Epoch   3, Step:    66900, Batch Loss:     8.598621, Tokens per Sec:     3688, Lr: 0.000200
2022-01-21 03:57:55,682 - INFO - joeynmt.training - Epoch   3, Step:    67000, Batch Loss:     4.221673, Tokens per Sec:     3715, Lr: 0.000200
2022-01-21 04:21:10,141 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 04:22:05,856 - INFO - joeynmt.helpers - delete models/a_model/65000.ckpt
2022-01-21 04:22:06,205 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/65000.ckpt
2022-01-21 04:22:06,480 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/65000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/65000.ckpt')
2022-01-21 04:22:07,043 - INFO - joeynmt.training - Example #0
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 04:22:07,044 - INFO - joeynmt.training - Example #1
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 04:22:07,044 - INFO - joeynmt.training - Example #2
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 04:22:07,044 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 04:22:07,045 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    67000: bleu:  85.41, loss: 322305.2500, ppl:   1.2216, duration: 1451.3625s
2022-01-21 04:22:29,265 - INFO - joeynmt.training - Epoch   3, Step:    67100, Batch Loss:     2.498069, Tokens per Sec:     2988, Lr: 0.000200
2022-01-21 04:22:48,058 - INFO - joeynmt.training - Epoch   3, Step:    67200, Batch Loss:     2.992209, Tokens per Sec:     3508, Lr: 0.000200
2022-01-21 04:23:06,906 - INFO - joeynmt.training - Epoch   3, Step:    67300, Batch Loss:     6.344343, Tokens per Sec:     3556, Lr: 0.000200
2022-01-21 04:23:25,444 - INFO - joeynmt.training - Epoch   3, Step:    67400, Batch Loss:     4.591124, Tokens per Sec:     3535, Lr: 0.000200
2022-01-21 04:23:47,107 - INFO - joeynmt.training - Epoch   3, Step:    67500, Batch Loss:     6.425180, Tokens per Sec:     3148, Lr: 0.000200
2022-01-21 04:24:20,582 - INFO - joeynmt.training - Epoch   3, Step:    67600, Batch Loss:     5.212491, Tokens per Sec:     1989, Lr: 0.000200
2022-01-21 04:24:39,011 - INFO - joeynmt.training - Epoch   3, Step:    67700, Batch Loss:     9.919209, Tokens per Sec:     3633, Lr: 0.000200
2022-01-21 04:24:57,854 - INFO - joeynmt.training - Epoch   3, Step:    67800, Batch Loss:     3.889731, Tokens per Sec:     3648, Lr: 0.000200
2022-01-21 04:25:16,863 - INFO - joeynmt.training - Epoch   3, Step:    67900, Batch Loss:     5.696227, Tokens per Sec:     3572, Lr: 0.000200
2022-01-21 04:25:42,342 - INFO - joeynmt.training - Epoch   3, Step:    68000, Batch Loss:     5.369016, Tokens per Sec:     2583, Lr: 0.000200
2022-01-21 04:49:36,944 - INFO - joeynmt.training - Example #0
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 04:49:36,945 - INFO - joeynmt.training - Example #1
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 04:49:36,945 - INFO - joeynmt.training - Example #2
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 04:49:36,945 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 04:49:36,946 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    68000: bleu:  85.11, loss: 330929.7188, ppl:   1.2282, duration: 1434.6037s
2022-01-21 04:50:11,780 - INFO - joeynmt.training - Epoch   3, Step:    68100, Batch Loss:     3.402469, Tokens per Sec:     1938, Lr: 0.000200
2022-01-21 04:50:33,527 - INFO - joeynmt.training - Epoch   3, Step:    68200, Batch Loss:     3.290272, Tokens per Sec:     3147, Lr: 0.000200
2022-01-21 04:50:52,033 - INFO - joeynmt.training - Epoch   3, Step:    68300, Batch Loss:     2.052046, Tokens per Sec:     3633, Lr: 0.000200
2022-01-21 04:51:10,662 - INFO - joeynmt.training - Epoch   3, Step:    68400, Batch Loss:     4.713017, Tokens per Sec:     3559, Lr: 0.000200
2022-01-21 04:51:29,550 - INFO - joeynmt.training - Epoch   3, Step:    68500, Batch Loss:     2.552485, Tokens per Sec:     3717, Lr: 0.000200
2022-01-21 04:51:48,758 - INFO - joeynmt.training - Epoch   3, Step:    68600, Batch Loss:    14.906856, Tokens per Sec:     3552, Lr: 0.000200
2022-01-21 04:52:07,959 - INFO - joeynmt.training - Epoch   3, Step:    68700, Batch Loss:     5.353118, Tokens per Sec:     3543, Lr: 0.000200
2022-01-21 04:52:27,020 - INFO - joeynmt.training - Epoch   3, Step:    68800, Batch Loss:     3.724208, Tokens per Sec:     3514, Lr: 0.000200
2022-01-21 04:52:45,666 - INFO - joeynmt.training - Epoch   3, Step:    68900, Batch Loss:     4.097580, Tokens per Sec:     3492, Lr: 0.000200
2022-01-21 04:53:04,470 - INFO - joeynmt.training - Epoch   3, Step:    69000, Batch Loss:     3.836456, Tokens per Sec:     3657, Lr: 0.000200
2022-01-21 05:17:22,982 - INFO - joeynmt.training - Example #0
2022-01-21 05:17:22,983 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 05:17:22,983 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 05:17:22,983 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 05:17:22,983 - INFO - joeynmt.training - Example #1
2022-01-21 05:17:22,983 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 05:17:22,983 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 05:17:22,983 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 05:17:22,983 - INFO - joeynmt.training - Example #2
2022-01-21 05:17:22,983 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 05:17:22,983 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 05:17:22,984 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 05:17:22,984 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    69000: bleu:  84.91, loss: 339620.8438, ppl:   1.2348, duration: 1458.5136s
2022-01-21 05:17:42,302 - INFO - joeynmt.training - Epoch   3, Step:    69100, Batch Loss:     4.932685, Tokens per Sec:     3392, Lr: 0.000200
2022-01-21 05:18:01,139 - INFO - joeynmt.training - Epoch   3, Step:    69200, Batch Loss:     7.182139, Tokens per Sec:     3740, Lr: 0.000200
2022-01-21 05:18:19,996 - INFO - joeynmt.training - Epoch   3, Step:    69300, Batch Loss:     3.723309, Tokens per Sec:     3717, Lr: 0.000200
2022-01-21 05:18:38,599 - INFO - joeynmt.training - Epoch   3, Step:    69400, Batch Loss:     4.179905, Tokens per Sec:     3522, Lr: 0.000200
2022-01-21 05:18:57,479 - INFO - joeynmt.training - Epoch   3, Step:    69500, Batch Loss:     4.397496, Tokens per Sec:     3629, Lr: 0.000200
2022-01-21 05:19:16,515 - INFO - joeynmt.training - Epoch   3, Step:    69600, Batch Loss:     3.678829, Tokens per Sec:     3566, Lr: 0.000200
2022-01-21 05:19:35,151 - INFO - joeynmt.training - Epoch   3, Step:    69700, Batch Loss:     4.314054, Tokens per Sec:     3456, Lr: 0.000200
2022-01-21 05:19:54,157 - INFO - joeynmt.training - Epoch   3, Step:    69800, Batch Loss:     5.033556, Tokens per Sec:     3466, Lr: 0.000200
2022-01-21 05:20:13,283 - INFO - joeynmt.training - Epoch   3, Step:    69900, Batch Loss:     6.780099, Tokens per Sec:     3592, Lr: 0.000200
2022-01-21 05:20:31,758 - INFO - joeynmt.training - Epoch   3, Step:    70000, Batch Loss:     5.576614, Tokens per Sec:     3589, Lr: 0.000200
2022-01-21 05:44:49,366 - INFO - joeynmt.training - Example #0
2022-01-21 05:44:49,367 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 05:44:49,367 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 05:44:49,368 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 05:44:49,368 - INFO - joeynmt.training - Example #1
2022-01-21 05:44:49,368 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 05:44:49,368 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 05:44:49,368 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-21 05:44:49,368 - INFO - joeynmt.training - Example #2
2022-01-21 05:44:49,368 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 05:44:49,368 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 05:44:49,368 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-21 05:44:49,369 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    70000: bleu:  85.27, loss: 324419.0938, ppl:   1.2232, duration: 1457.6106s
2022-01-21 05:45:12,085 - INFO - joeynmt.training - Epoch   3, Step:    70100, Batch Loss:     1.861316, Tokens per Sec:     3053, Lr: 0.000200
2022-01-21 05:45:45,826 - INFO - joeynmt.training - Epoch   3, Step:    70200, Batch Loss:    11.400174, Tokens per Sec:     1944, Lr: 0.000200
2022-01-21 05:46:04,713 - INFO - joeynmt.training - Epoch   3, Step:    70300, Batch Loss:     2.889494, Tokens per Sec:     3484, Lr: 0.000200
2022-01-21 05:46:23,613 - INFO - joeynmt.training - Epoch   3, Step:    70400, Batch Loss:     4.967950, Tokens per Sec:     3584, Lr: 0.000200
2022-01-21 05:46:42,259 - INFO - joeynmt.training - Epoch   3, Step:    70500, Batch Loss:     2.887341, Tokens per Sec:     3674, Lr: 0.000200
2022-01-21 05:47:01,106 - INFO - joeynmt.training - Epoch   3, Step:    70600, Batch Loss:     4.650360, Tokens per Sec:     3532, Lr: 0.000200
2022-01-21 05:47:20,091 - INFO - joeynmt.training - Epoch   3, Step:    70700, Batch Loss:     8.513154, Tokens per Sec:     3554, Lr: 0.000200
2022-01-21 05:47:39,056 - INFO - joeynmt.training - Epoch   3, Step:    70800, Batch Loss:     8.930573, Tokens per Sec:     3550, Lr: 0.000200
2022-01-21 05:47:57,967 - INFO - joeynmt.training - Epoch   3, Step:    70900, Batch Loss:     3.777740, Tokens per Sec:     3577, Lr: 0.000200
2022-01-21 05:48:16,579 - INFO - joeynmt.training - Epoch   3, Step:    71000, Batch Loss:     3.123745, Tokens per Sec:     3550, Lr: 0.000200
2022-01-21 06:12:51,451 - INFO - joeynmt.training - Example #0
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 06:12:51,452 - INFO - joeynmt.training - Example #1
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-21 06:12:51,452 - INFO - joeynmt.training - Example #2
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 06:12:51,452 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-21 06:12:51,453 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    71000: bleu:  84.84, loss: 335747.2188, ppl:   1.2319, duration: 1474.8735s
2022-01-21 06:13:10,657 - INFO - joeynmt.training - Epoch   3, Step:    71100, Batch Loss:     2.843637, Tokens per Sec:     3469, Lr: 0.000200
2022-01-21 06:13:29,637 - INFO - joeynmt.training - Epoch   3, Step:    71200, Batch Loss:     6.271298, Tokens per Sec:     3577, Lr: 0.000200
2022-01-21 06:13:48,294 - INFO - joeynmt.training - Epoch   3, Step:    71300, Batch Loss:     2.954395, Tokens per Sec:     3596, Lr: 0.000200
2022-01-21 06:14:07,157 - INFO - joeynmt.training - Epoch   3, Step:    71400, Batch Loss:     5.737998, Tokens per Sec:     3508, Lr: 0.000200
2022-01-21 06:14:26,223 - INFO - joeynmt.training - Epoch   3, Step:    71500, Batch Loss:     4.009740, Tokens per Sec:     3541, Lr: 0.000200
2022-01-21 06:14:45,077 - INFO - joeynmt.training - Epoch   3, Step:    71600, Batch Loss:     4.304440, Tokens per Sec:     3473, Lr: 0.000200
2022-01-21 06:15:04,080 - INFO - joeynmt.training - Epoch   3, Step:    71700, Batch Loss:     4.476992, Tokens per Sec:     3541, Lr: 0.000200
2022-01-21 06:15:23,043 - INFO - joeynmt.training - Epoch   3, Step:    71800, Batch Loss:     4.185460, Tokens per Sec:     3467, Lr: 0.000200
2022-01-21 06:15:41,934 - INFO - joeynmt.training - Epoch   3, Step:    71900, Batch Loss:     5.312041, Tokens per Sec:     3557, Lr: 0.000200
2022-01-21 06:16:01,096 - INFO - joeynmt.training - Epoch   3, Step:    72000, Batch Loss:     3.673569, Tokens per Sec:     3578, Lr: 0.000200
2022-01-21 06:38:31,738 - INFO - joeynmt.training - Example #0
2022-01-21 06:38:31,739 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 06:38:31,740 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 06:38:31,740 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 33 12 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 06:38:31,740 - INFO - joeynmt.training - Example #1
2022-01-21 06:38:31,740 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 06:38:31,740 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 06:38:31,740 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 06:38:31,740 - INFO - joeynmt.training - Example #2
2022-01-21 06:38:31,740 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 06:38:31,740 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 06:38:31,740 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 06:38:31,741 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    72000: bleu:  84.95, loss: 334957.0312, ppl:   1.2313, duration: 1350.6441s
2022-01-21 06:38:51,236 - INFO - joeynmt.training - Epoch   3, Step:    72100, Batch Loss:     8.941198, Tokens per Sec:     3564, Lr: 0.000200
2022-01-21 06:39:10,698 - INFO - joeynmt.training - Epoch   3, Step:    72200, Batch Loss:     3.230066, Tokens per Sec:     3515, Lr: 0.000200
2022-01-21 06:39:30,026 - INFO - joeynmt.training - Epoch   3, Step:    72300, Batch Loss:     2.326566, Tokens per Sec:     3413, Lr: 0.000200
2022-01-21 06:39:49,468 - INFO - joeynmt.training - Epoch   3, Step:    72400, Batch Loss:     4.639714, Tokens per Sec:     3510, Lr: 0.000200
2022-01-21 06:40:08,948 - INFO - joeynmt.training - Epoch   3, Step:    72500, Batch Loss:     4.791370, Tokens per Sec:     3494, Lr: 0.000200
2022-01-21 06:40:28,424 - INFO - joeynmt.training - Epoch   3, Step:    72600, Batch Loss:     5.177751, Tokens per Sec:     3576, Lr: 0.000200
2022-01-21 06:40:47,828 - INFO - joeynmt.training - Epoch   3, Step:    72700, Batch Loss:     7.921556, Tokens per Sec:     3509, Lr: 0.000200
2022-01-21 06:41:07,522 - INFO - joeynmt.training - Epoch   3, Step:    72800, Batch Loss:     3.762157, Tokens per Sec:     3521, Lr: 0.000200
2022-01-21 06:41:26,270 - INFO - joeynmt.training - Epoch   3, Step:    72900, Batch Loss:     5.662313, Tokens per Sec:     3574, Lr: 0.000200
2022-01-21 06:41:45,045 - INFO - joeynmt.training - Epoch   3, Step:    73000, Batch Loss:     8.291192, Tokens per Sec:     3573, Lr: 0.000200
2022-01-21 07:03:34,147 - INFO - joeynmt.training - Example #0
2022-01-21 07:03:34,148 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 07:03:34,148 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 07:03:34,148 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 07:03:34,148 - INFO - joeynmt.training - Example #1
2022-01-21 07:03:34,148 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 07:03:34,148 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 07:03:34,149 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 07:03:34,149 - INFO - joeynmt.training - Example #2
2022-01-21 07:03:34,149 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 07:03:34,149 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 07:03:34,149 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 07:03:34,149 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    73000: bleu:  85.06, loss: 315148.8750, ppl:   1.2162, duration: 1309.1040s
2022-01-21 07:03:52,936 - INFO - joeynmt.training - Epoch   3, Step:    73100, Batch Loss:     4.750908, Tokens per Sec:     3526, Lr: 0.000200
2022-01-21 07:04:11,318 - INFO - joeynmt.training - Epoch   3, Step:    73200, Batch Loss:     2.947816, Tokens per Sec:     3785, Lr: 0.000200
2022-01-21 07:04:29,675 - INFO - joeynmt.training - Epoch   3, Step:    73300, Batch Loss:     2.520872, Tokens per Sec:     3737, Lr: 0.000200
2022-01-21 07:04:47,921 - INFO - joeynmt.training - Epoch   3, Step:    73400, Batch Loss:     4.194843, Tokens per Sec:     3722, Lr: 0.000200
2022-01-21 07:05:06,066 - INFO - joeynmt.training - Epoch   3, Step:    73500, Batch Loss:     3.460479, Tokens per Sec:     3756, Lr: 0.000200
2022-01-21 07:05:24,403 - INFO - joeynmt.training - Epoch   3, Step:    73600, Batch Loss:     6.377931, Tokens per Sec:     3631, Lr: 0.000200
2022-01-21 07:05:42,985 - INFO - joeynmt.training - Epoch   3, Step:    73700, Batch Loss:     5.243277, Tokens per Sec:     3645, Lr: 0.000200
2022-01-21 07:06:01,804 - INFO - joeynmt.training - Epoch   3, Step:    73800, Batch Loss:     4.678543, Tokens per Sec:     3698, Lr: 0.000200
2022-01-21 07:06:20,539 - INFO - joeynmt.training - Epoch   3, Step:    73900, Batch Loss:     8.590022, Tokens per Sec:     3524, Lr: 0.000200
2022-01-21 07:06:39,366 - INFO - joeynmt.training - Epoch   3, Step:    74000, Batch Loss:     2.732316, Tokens per Sec:     3620, Lr: 0.000200
2022-01-21 07:28:32,133 - INFO - joeynmt.training - Example #0
2022-01-21 07:28:32,134 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 07:28:32,134 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 07:28:32,134 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 07:28:32,134 - INFO - joeynmt.training - Example #1
2022-01-21 07:28:32,135 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 07:28:32,135 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 07:28:32,135 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 07:28:32,135 - INFO - joeynmt.training - Example #2
2022-01-21 07:28:32,135 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 07:28:32,135 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 07:28:32,135 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 07:28:32,136 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    74000: bleu:  85.38, loss: 316744.4688, ppl:   1.2174, duration: 1312.7688s
2022-01-21 07:28:51,015 - INFO - joeynmt.training - Epoch   3, Step:    74100, Batch Loss:     3.975215, Tokens per Sec:     3557, Lr: 0.000200
2022-01-21 07:29:09,826 - INFO - joeynmt.training - Epoch   3, Step:    74200, Batch Loss:     8.471909, Tokens per Sec:     3651, Lr: 0.000200
2022-01-21 07:29:28,322 - INFO - joeynmt.training - Epoch   3, Step:    74300, Batch Loss:     7.380976, Tokens per Sec:     3648, Lr: 0.000200
2022-01-21 07:29:47,006 - INFO - joeynmt.training - Epoch   3, Step:    74400, Batch Loss:     5.710478, Tokens per Sec:     3660, Lr: 0.000200
2022-01-21 07:30:05,892 - INFO - joeynmt.training - Epoch   3, Step:    74500, Batch Loss:     4.501149, Tokens per Sec:     3618, Lr: 0.000200
2022-01-21 07:30:24,632 - INFO - joeynmt.training - Epoch   3, Step:    74600, Batch Loss:     9.451433, Tokens per Sec:     3665, Lr: 0.000200
2022-01-21 07:30:43,377 - INFO - joeynmt.training - Epoch   3, Step:    74700, Batch Loss:     4.131535, Tokens per Sec:     3609, Lr: 0.000200
2022-01-21 07:31:01,845 - INFO - joeynmt.training - Epoch   3, Step:    74800, Batch Loss:     4.753218, Tokens per Sec:     3667, Lr: 0.000200
2022-01-21 07:31:20,442 - INFO - joeynmt.training - Epoch   3, Step:    74900, Batch Loss:     4.205606, Tokens per Sec:     3622, Lr: 0.000200
2022-01-21 07:31:39,193 - INFO - joeynmt.training - Epoch   3, Step:    75000, Batch Loss:     5.640810, Tokens per Sec:     3657, Lr: 0.000200
2022-01-21 07:53:23,820 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 07:53:56,524 - INFO - joeynmt.helpers - delete models/a_model/67000.ckpt
2022-01-21 07:53:56,569 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/67000.ckpt
2022-01-21 07:53:56,570 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/67000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/67000.ckpt')
2022-01-21 07:53:56,668 - INFO - joeynmt.training - Example #0
2022-01-21 07:53:56,668 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 07:53:56,668 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 07:53:56,668 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 07:53:56,668 - INFO - joeynmt.training - Example #1
2022-01-21 07:53:56,668 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 07:53:56,668 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 07:53:56,668 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 07:53:56,668 - INFO - joeynmt.training - Example #2
2022-01-21 07:53:56,669 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 07:53:56,669 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 07:53:56,669 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 07:53:56,670 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    75000: bleu:  85.45, loss: 320008.6875, ppl:   1.2199, duration: 1337.4764s
2022-01-21 07:54:15,757 - INFO - joeynmt.training - Epoch   3, Step:    75100, Batch Loss:     5.986081, Tokens per Sec:     3494, Lr: 0.000200
2022-01-21 07:54:34,561 - INFO - joeynmt.training - Epoch   3, Step:    75200, Batch Loss:     5.272793, Tokens per Sec:     3766, Lr: 0.000200
2022-01-21 07:54:53,304 - INFO - joeynmt.training - Epoch   3, Step:    75300, Batch Loss:     3.575666, Tokens per Sec:     3686, Lr: 0.000200
2022-01-21 07:55:12,044 - INFO - joeynmt.training - Epoch   3, Step:    75400, Batch Loss:     2.885869, Tokens per Sec:     3580, Lr: 0.000200
2022-01-21 07:55:30,950 - INFO - joeynmt.training - Epoch   3, Step:    75500, Batch Loss:     7.036892, Tokens per Sec:     3568, Lr: 0.000200
2022-01-21 07:55:49,445 - INFO - joeynmt.training - Epoch   3, Step:    75600, Batch Loss:     5.903131, Tokens per Sec:     3652, Lr: 0.000200
2022-01-21 07:56:07,914 - INFO - joeynmt.training - Epoch   3, Step:    75700, Batch Loss:     2.739320, Tokens per Sec:     3662, Lr: 0.000200
2022-01-21 07:56:26,586 - INFO - joeynmt.training - Epoch   3, Step:    75800, Batch Loss:     3.926540, Tokens per Sec:     3564, Lr: 0.000200
2022-01-21 07:56:45,199 - INFO - joeynmt.training - Epoch   3, Step:    75900, Batch Loss:     7.087273, Tokens per Sec:     3676, Lr: 0.000200
2022-01-21 07:57:03,950 - INFO - joeynmt.training - Epoch   3, Step:    76000, Batch Loss:     2.295798, Tokens per Sec:     3606, Lr: 0.000200
2022-01-21 08:19:01,735 - INFO - joeynmt.training - Example #0
2022-01-21 08:19:01,736 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 08:19:01,736 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 08:19:01,736 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 08:19:01,737 - INFO - joeynmt.training - Example #1
2022-01-21 08:19:01,737 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 08:19:01,737 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 08:19:01,737 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 08:19:01,737 - INFO - joeynmt.training - Example #2
2022-01-21 08:19:01,737 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 08:19:01,737 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 08:19:01,737 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 08:19:01,738 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    76000: bleu:  85.37, loss: 319563.7188, ppl:   1.2195, duration: 1317.7879s
2022-01-21 08:19:20,385 - INFO - joeynmt.training - Epoch   3, Step:    76100, Batch Loss:     4.586516, Tokens per Sec:     3671, Lr: 0.000200
2022-01-21 08:19:39,099 - INFO - joeynmt.training - Epoch   3, Step:    76200, Batch Loss:     3.920530, Tokens per Sec:     3567, Lr: 0.000200
2022-01-21 08:19:57,973 - INFO - joeynmt.training - Epoch   3, Step:    76300, Batch Loss:     4.188429, Tokens per Sec:     3571, Lr: 0.000200
2022-01-21 08:20:16,665 - INFO - joeynmt.training - Epoch   3, Step:    76400, Batch Loss:     4.174591, Tokens per Sec:     3593, Lr: 0.000200
2022-01-21 08:20:35,208 - INFO - joeynmt.training - Epoch   3, Step:    76500, Batch Loss:     3.206387, Tokens per Sec:     3573, Lr: 0.000200
2022-01-21 08:20:54,096 - INFO - joeynmt.training - Epoch   3, Step:    76600, Batch Loss:     4.207478, Tokens per Sec:     3530, Lr: 0.000200
2022-01-21 08:21:12,485 - INFO - joeynmt.training - Epoch   3, Step:    76700, Batch Loss:     2.148168, Tokens per Sec:     3661, Lr: 0.000200
2022-01-21 08:21:31,172 - INFO - joeynmt.training - Epoch   3, Step:    76800, Batch Loss:     3.356082, Tokens per Sec:     3557, Lr: 0.000200
2022-01-21 08:21:49,805 - INFO - joeynmt.training - Epoch   3, Step:    76900, Batch Loss:     3.798492, Tokens per Sec:     3550, Lr: 0.000200
2022-01-21 08:22:08,742 - INFO - joeynmt.training - Epoch   3, Step:    77000, Batch Loss:     4.436690, Tokens per Sec:     3530, Lr: 0.000200
2022-01-21 08:43:53,221 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 08:44:25,918 - INFO - joeynmt.helpers - delete models/a_model/75000.ckpt
2022-01-21 08:44:26,007 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/75000.ckpt
2022-01-21 08:44:26,008 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/75000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/75000.ckpt')
2022-01-21 08:44:26,041 - INFO - joeynmt.training - Example #0
2022-01-21 08:44:26,041 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 08:44:26,041 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 08:44:26,041 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 08:44:26,041 - INFO - joeynmt.training - Example #1
2022-01-21 08:44:26,042 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 08:44:26,042 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 08:44:26,042 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 08:44:26,042 - INFO - joeynmt.training - Example #2
2022-01-21 08:44:26,042 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 08:44:26,042 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 08:44:26,042 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 08:44:26,043 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    77000: bleu:  85.59, loss: 314586.5938, ppl:   1.2158, duration: 1337.3003s
2022-01-21 08:44:44,915 - INFO - joeynmt.training - Epoch   3, Step:    77100, Batch Loss:     3.543980, Tokens per Sec:     3561, Lr: 0.000200
2022-01-21 08:45:03,598 - INFO - joeynmt.training - Epoch   3, Step:    77200, Batch Loss:     2.040395, Tokens per Sec:     3678, Lr: 0.000200
2022-01-21 08:45:22,212 - INFO - joeynmt.training - Epoch   3, Step:    77300, Batch Loss:     2.394425, Tokens per Sec:     3639, Lr: 0.000200
2022-01-21 08:45:40,838 - INFO - joeynmt.training - Epoch   3, Step:    77400, Batch Loss:    10.004349, Tokens per Sec:     3653, Lr: 0.000200
2022-01-21 08:45:59,600 - INFO - joeynmt.training - Epoch   3, Step:    77500, Batch Loss:     6.380206, Tokens per Sec:     3549, Lr: 0.000200
2022-01-21 08:46:18,308 - INFO - joeynmt.training - Epoch   3, Step:    77600, Batch Loss:     2.260237, Tokens per Sec:     3596, Lr: 0.000200
2022-01-21 08:46:37,181 - INFO - joeynmt.training - Epoch   3, Step:    77700, Batch Loss:     2.930955, Tokens per Sec:     3598, Lr: 0.000200
2022-01-21 08:46:55,662 - INFO - joeynmt.training - Epoch   3, Step:    77800, Batch Loss:     5.459155, Tokens per Sec:     3596, Lr: 0.000200
2022-01-21 08:47:14,332 - INFO - joeynmt.training - Epoch   3, Step:    77900, Batch Loss:     3.088255, Tokens per Sec:     3709, Lr: 0.000200
2022-01-21 08:47:32,713 - INFO - joeynmt.training - Epoch   3, Step:    78000, Batch Loss:     2.559151, Tokens per Sec:     3561, Lr: 0.000200
2022-01-21 09:09:30,390 - INFO - joeynmt.training - Example #0
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 09:09:30,391 - INFO - joeynmt.training - Example #1
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 23 34 | 33 7 | 35 15
2022-01-21 09:09:30,391 - INFO - joeynmt.training - Example #2
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 09:09:30,391 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 09:09:30,392 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    78000: bleu:  85.43, loss: 313497.6875, ppl:   1.2149, duration: 1317.6788s
2022-01-21 09:09:49,653 - INFO - joeynmt.training - Epoch   3, Step:    78100, Batch Loss:     3.504968, Tokens per Sec:     3442, Lr: 0.000200
2022-01-21 09:10:08,365 - INFO - joeynmt.training - Epoch   3, Step:    78200, Batch Loss:     5.813748, Tokens per Sec:     3671, Lr: 0.000200
2022-01-21 09:10:27,018 - INFO - joeynmt.training - Epoch   3, Step:    78300, Batch Loss:    11.208540, Tokens per Sec:     3550, Lr: 0.000200
2022-01-21 09:10:45,474 - INFO - joeynmt.training - Epoch   3, Step:    78400, Batch Loss:     4.852324, Tokens per Sec:     3645, Lr: 0.000200
2022-01-21 09:11:03,803 - INFO - joeynmt.training - Epoch   3, Step:    78500, Batch Loss:     6.992863, Tokens per Sec:     3675, Lr: 0.000200
2022-01-21 09:11:22,709 - INFO - joeynmt.training - Epoch   3, Step:    78600, Batch Loss:     2.940674, Tokens per Sec:     3598, Lr: 0.000200
2022-01-21 09:11:41,593 - INFO - joeynmt.training - Epoch   3, Step:    78700, Batch Loss:     7.152528, Tokens per Sec:     3527, Lr: 0.000200
2022-01-21 09:12:00,347 - INFO - joeynmt.training - Epoch   3, Step:    78800, Batch Loss:     6.054390, Tokens per Sec:     3655, Lr: 0.000200
2022-01-21 09:12:19,368 - INFO - joeynmt.training - Epoch   3, Step:    78900, Batch Loss:     5.199399, Tokens per Sec:     3575, Lr: 0.000200
2022-01-21 09:12:38,303 - INFO - joeynmt.training - Epoch   3, Step:    79000, Batch Loss:     2.983081, Tokens per Sec:     3464, Lr: 0.000200
2022-01-21 09:34:23,695 - INFO - joeynmt.training - Example #0
2022-01-21 09:34:23,696 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 09:34:23,696 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 09:34:23,696 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-21 09:34:23,696 - INFO - joeynmt.training - Example #1
2022-01-21 09:34:23,696 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 09:34:23,696 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 09:34:23,696 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 09:34:23,696 - INFO - joeynmt.training - Example #2
2022-01-21 09:34:23,697 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 09:34:23,697 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 09:34:23,697 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 09:34:23,697 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    79000: bleu:  85.29, loss: 313477.9688, ppl:   1.2149, duration: 1305.3936s
2022-01-21 09:34:42,599 - INFO - joeynmt.training - Epoch   3, Step:    79100, Batch Loss:     4.929575, Tokens per Sec:     3486, Lr: 0.000200
2022-01-21 09:35:01,217 - INFO - joeynmt.training - Epoch   3, Step:    79200, Batch Loss:     4.393772, Tokens per Sec:     3670, Lr: 0.000200
2022-01-21 09:35:20,028 - INFO - joeynmt.training - Epoch   3, Step:    79300, Batch Loss:     2.408204, Tokens per Sec:     3696, Lr: 0.000200
2022-01-21 09:35:38,839 - INFO - joeynmt.training - Epoch   3, Step:    79400, Batch Loss:     6.210702, Tokens per Sec:     3612, Lr: 0.000200
2022-01-21 09:35:57,643 - INFO - joeynmt.training - Epoch   3, Step:    79500, Batch Loss:     4.615036, Tokens per Sec:     3621, Lr: 0.000200
2022-01-21 09:36:16,497 - INFO - joeynmt.training - Epoch   3, Step:    79600, Batch Loss:     3.836316, Tokens per Sec:     3668, Lr: 0.000200
2022-01-21 09:36:35,360 - INFO - joeynmt.training - Epoch   3, Step:    79700, Batch Loss:     6.843217, Tokens per Sec:     3602, Lr: 0.000200
2022-01-21 09:36:37,114 - INFO - joeynmt.training - Epoch   3: total training loss 137772.35
2022-01-21 09:36:37,115 - INFO - joeynmt.training - EPOCH 4
2022-01-21 09:36:53,867 - INFO - joeynmt.training - Epoch   4, Step:    79800, Batch Loss:     3.332729, Tokens per Sec:     3548, Lr: 0.000200
2022-01-21 09:37:12,170 - INFO - joeynmt.training - Epoch   4, Step:    79900, Batch Loss:     3.891083, Tokens per Sec:     3645, Lr: 0.000200
2022-01-21 09:37:30,395 - INFO - joeynmt.training - Epoch   4, Step:    80000, Batch Loss:     1.971572, Tokens per Sec:     3624, Lr: 0.000200
2022-01-21 09:59:15,287 - INFO - joeynmt.training - Example #0
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 09:59:15,288 - INFO - joeynmt.training - Example #1
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 09:59:15,288 - INFO - joeynmt.training - Example #2
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 09:59:15,288 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 09:59:15,289 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    80000: bleu:  85.44, loss: 329729.1250, ppl:   1.2273, duration: 1304.8934s
2022-01-21 09:59:34,091 - INFO - joeynmt.training - Epoch   4, Step:    80100, Batch Loss:     2.540431, Tokens per Sec:     3620, Lr: 0.000200
2022-01-21 09:59:52,464 - INFO - joeynmt.training - Epoch   4, Step:    80200, Batch Loss:     4.054222, Tokens per Sec:     3606, Lr: 0.000200
2022-01-21 10:00:10,733 - INFO - joeynmt.training - Epoch   4, Step:    80300, Batch Loss:     3.670503, Tokens per Sec:     3660, Lr: 0.000200
2022-01-21 10:00:29,147 - INFO - joeynmt.training - Epoch   4, Step:    80400, Batch Loss:     6.585955, Tokens per Sec:     3720, Lr: 0.000200
2022-01-21 10:00:47,631 - INFO - joeynmt.training - Epoch   4, Step:    80500, Batch Loss:     4.816588, Tokens per Sec:     3734, Lr: 0.000200
2022-01-21 10:01:05,924 - INFO - joeynmt.training - Epoch   4, Step:    80600, Batch Loss:     4.518610, Tokens per Sec:     3695, Lr: 0.000200
2022-01-21 10:01:24,280 - INFO - joeynmt.training - Epoch   4, Step:    80700, Batch Loss:     4.267707, Tokens per Sec:     3677, Lr: 0.000200
2022-01-21 10:01:42,517 - INFO - joeynmt.training - Epoch   4, Step:    80800, Batch Loss:     3.389808, Tokens per Sec:     3721, Lr: 0.000200
2022-01-21 10:02:00,704 - INFO - joeynmt.training - Epoch   4, Step:    80900, Batch Loss:     3.343434, Tokens per Sec:     3656, Lr: 0.000200
2022-01-21 10:02:19,121 - INFO - joeynmt.training - Epoch   4, Step:    81000, Batch Loss:     3.850019, Tokens per Sec:     3633, Lr: 0.000200
2022-01-21 10:24:17,216 - INFO - joeynmt.training - Example #0
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 10:24:17,217 - INFO - joeynmt.training - Example #1
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 10:24:17,217 - INFO - joeynmt.training - Example #2
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 10:24:17,217 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 10:24:17,218 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    81000: bleu:  85.53, loss: 309456.5312, ppl:   1.2119, duration: 1318.0972s
2022-01-21 10:24:36,472 - INFO - joeynmt.training - Epoch   4, Step:    81100, Batch Loss:     3.038236, Tokens per Sec:     3528, Lr: 0.000200
2022-01-21 10:24:55,404 - INFO - joeynmt.training - Epoch   4, Step:    81200, Batch Loss:     5.002986, Tokens per Sec:     3566, Lr: 0.000200
2022-01-21 10:25:14,420 - INFO - joeynmt.training - Epoch   4, Step:    81300, Batch Loss:     2.480445, Tokens per Sec:     3585, Lr: 0.000200
2022-01-21 10:25:33,209 - INFO - joeynmt.training - Epoch   4, Step:    81400, Batch Loss:     3.064956, Tokens per Sec:     3564, Lr: 0.000200
2022-01-21 10:25:52,002 - INFO - joeynmt.training - Epoch   4, Step:    81500, Batch Loss:     5.060853, Tokens per Sec:     3650, Lr: 0.000200
2022-01-21 10:26:11,063 - INFO - joeynmt.training - Epoch   4, Step:    81600, Batch Loss:     4.329310, Tokens per Sec:     3507, Lr: 0.000200
2022-01-21 10:26:30,102 - INFO - joeynmt.training - Epoch   4, Step:    81700, Batch Loss:     3.591032, Tokens per Sec:     3400, Lr: 0.000200
2022-01-21 10:26:48,951 - INFO - joeynmt.training - Epoch   4, Step:    81800, Batch Loss:     4.106421, Tokens per Sec:     3562, Lr: 0.000200
2022-01-21 10:27:08,075 - INFO - joeynmt.training - Epoch   4, Step:    81900, Batch Loss:     2.900892, Tokens per Sec:     3509, Lr: 0.000200
2022-01-21 10:27:26,935 - INFO - joeynmt.training - Epoch   4, Step:    82000, Batch Loss:     3.810315, Tokens per Sec:     3578, Lr: 0.000200
2022-01-21 10:49:15,777 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 10:49:48,480 - INFO - joeynmt.helpers - delete models/a_model/77000.ckpt
2022-01-21 10:49:48,569 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/77000.ckpt
2022-01-21 10:49:48,569 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/77000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/77000.ckpt')
2022-01-21 10:49:48,717 - INFO - joeynmt.training - Example #0
2022-01-21 10:49:48,717 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 10:49:48,717 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 10:49:48,717 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 10:49:48,717 - INFO - joeynmt.training - Example #1
2022-01-21 10:49:48,717 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 10:49:48,718 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 10:49:48,718 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 10:49:48,718 - INFO - joeynmt.training - Example #2
2022-01-21 10:49:48,718 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 10:49:48,718 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 10:49:48,718 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 10:49:48,719 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    82000: bleu:  85.69, loss: 308855.3750, ppl:   1.2115, duration: 1341.7835s
2022-01-21 10:50:07,471 - INFO - joeynmt.training - Epoch   4, Step:    82100, Batch Loss:     3.155495, Tokens per Sec:     3588, Lr: 0.000200
2022-01-21 10:50:25,623 - INFO - joeynmt.training - Epoch   4, Step:    82200, Batch Loss:     2.665488, Tokens per Sec:     3639, Lr: 0.000200
2022-01-21 10:50:43,871 - INFO - joeynmt.training - Epoch   4, Step:    82300, Batch Loss:     2.923531, Tokens per Sec:     3633, Lr: 0.000200
2022-01-21 10:51:02,133 - INFO - joeynmt.training - Epoch   4, Step:    82400, Batch Loss:     8.262030, Tokens per Sec:     3662, Lr: 0.000200
2022-01-21 10:51:20,504 - INFO - joeynmt.training - Epoch   4, Step:    82500, Batch Loss:    10.435621, Tokens per Sec:     3654, Lr: 0.000200
2022-01-21 10:51:39,084 - INFO - joeynmt.training - Epoch   4, Step:    82600, Batch Loss:     3.824927, Tokens per Sec:     3489, Lr: 0.000200
2022-01-21 10:51:57,570 - INFO - joeynmt.training - Epoch   4, Step:    82700, Batch Loss:     5.700395, Tokens per Sec:     3664, Lr: 0.000200
2022-01-21 10:52:15,816 - INFO - joeynmt.training - Epoch   4, Step:    82800, Batch Loss:     4.346504, Tokens per Sec:     3702, Lr: 0.000200
2022-01-21 10:52:34,164 - INFO - joeynmt.training - Epoch   4, Step:    82900, Batch Loss:     5.321580, Tokens per Sec:     3602, Lr: 0.000200
2022-01-21 10:52:52,082 - INFO - joeynmt.training - Epoch   4, Step:    83000, Batch Loss:     3.598629, Tokens per Sec:     3704, Lr: 0.000200
2022-01-21 11:14:41,177 - INFO - joeynmt.training - Example #0
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 11:14:41,178 - INFO - joeynmt.training - Example #1
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 11:14:41,178 - INFO - joeynmt.training - Example #2
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 11:14:41,178 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 11:14:41,179 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    83000: bleu:  85.59, loss: 306482.0938, ppl:   1.2097, duration: 1309.0966s
2022-01-21 11:14:59,845 - INFO - joeynmt.training - Epoch   4, Step:    83100, Batch Loss:     1.783221, Tokens per Sec:     3617, Lr: 0.000200
2022-01-21 11:15:18,442 - INFO - joeynmt.training - Epoch   4, Step:    83200, Batch Loss:     2.550471, Tokens per Sec:     3700, Lr: 0.000200
2022-01-21 11:15:36,699 - INFO - joeynmt.training - Epoch   4, Step:    83300, Batch Loss:     3.385595, Tokens per Sec:     3559, Lr: 0.000200
2022-01-21 11:15:55,183 - INFO - joeynmt.training - Epoch   4, Step:    83400, Batch Loss:     5.623052, Tokens per Sec:     3687, Lr: 0.000200
2022-01-21 11:16:13,647 - INFO - joeynmt.training - Epoch   4, Step:    83500, Batch Loss:     4.018810, Tokens per Sec:     3637, Lr: 0.000200
2022-01-21 11:16:31,898 - INFO - joeynmt.training - Epoch   4, Step:    83600, Batch Loss:     2.383062, Tokens per Sec:     3763, Lr: 0.000200
2022-01-21 11:16:49,812 - INFO - joeynmt.training - Epoch   4, Step:    83700, Batch Loss:     7.100998, Tokens per Sec:     3648, Lr: 0.000200
2022-01-21 11:17:07,549 - INFO - joeynmt.training - Epoch   4, Step:    83800, Batch Loss:     8.474070, Tokens per Sec:     3744, Lr: 0.000200
2022-01-21 11:17:24,912 - INFO - joeynmt.training - Epoch   4, Step:    83900, Batch Loss:     6.837237, Tokens per Sec:     3774, Lr: 0.000200
2022-01-21 11:17:42,443 - INFO - joeynmt.training - Epoch   4, Step:    84000, Batch Loss:     5.309264, Tokens per Sec:     3742, Lr: 0.000200
2022-01-21 11:39:28,056 - INFO - joeynmt.training - Example #0
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 11:39:28,057 - INFO - joeynmt.training - Example #1
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 11:39:28,057 - INFO - joeynmt.training - Example #2
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 11:39:28,057 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 11:39:28,058 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    84000: bleu:  85.58, loss: 316907.4375, ppl:   1.2175, duration: 1305.6146s
2022-01-21 11:39:47,739 - INFO - joeynmt.training - Epoch   4, Step:    84100, Batch Loss:     3.529350, Tokens per Sec:     3435, Lr: 0.000200
2022-01-21 11:40:06,751 - INFO - joeynmt.training - Epoch   4, Step:    84200, Batch Loss:    10.079638, Tokens per Sec:     3536, Lr: 0.000200
2022-01-21 11:40:25,639 - INFO - joeynmt.training - Epoch   4, Step:    84300, Batch Loss:     3.322925, Tokens per Sec:     3613, Lr: 0.000200
2022-01-21 11:40:44,755 - INFO - joeynmt.training - Epoch   4, Step:    84400, Batch Loss:     3.761890, Tokens per Sec:     3570, Lr: 0.000200
2022-01-21 11:41:03,743 - INFO - joeynmt.training - Epoch   4, Step:    84500, Batch Loss:     3.368037, Tokens per Sec:     3456, Lr: 0.000200
2022-01-21 11:41:23,186 - INFO - joeynmt.training - Epoch   4, Step:    84600, Batch Loss:     2.378358, Tokens per Sec:     3516, Lr: 0.000200
2022-01-21 11:41:42,036 - INFO - joeynmt.training - Epoch   4, Step:    84700, Batch Loss:     3.617871, Tokens per Sec:     3474, Lr: 0.000200
2022-01-21 11:42:01,106 - INFO - joeynmt.training - Epoch   4, Step:    84800, Batch Loss:     2.364893, Tokens per Sec:     3512, Lr: 0.000200
2022-01-21 11:42:19,866 - INFO - joeynmt.training - Epoch   4, Step:    84900, Batch Loss:     4.975635, Tokens per Sec:     3519, Lr: 0.000200
2022-01-21 11:42:38,768 - INFO - joeynmt.training - Epoch   4, Step:    85000, Batch Loss:     2.206760, Tokens per Sec:     3581, Lr: 0.000200
2022-01-21 12:04:50,862 - INFO - joeynmt.training - Example #0
2022-01-21 12:04:50,863 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 12:04:50,863 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 12:04:50,863 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 12:04:50,863 - INFO - joeynmt.training - Example #1
2022-01-21 12:04:50,863 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 12:04:50,863 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 12:04:50,863 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 12:04:50,863 - INFO - joeynmt.training - Example #2
2022-01-21 12:04:50,863 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 12:04:50,864 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 12:04:50,864 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-21 12:04:50,865 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    85000: bleu:  85.42, loss: 327595.9375, ppl:   1.2256, duration: 1332.0957s
2022-01-21 12:05:09,725 - INFO - joeynmt.training - Epoch   4, Step:    85100, Batch Loss:     1.925868, Tokens per Sec:     3436, Lr: 0.000200
2022-01-21 12:05:28,436 - INFO - joeynmt.training - Epoch   4, Step:    85200, Batch Loss:     2.971621, Tokens per Sec:     3579, Lr: 0.000200
2022-01-21 12:05:47,632 - INFO - joeynmt.training - Epoch   4, Step:    85300, Batch Loss:     4.497037, Tokens per Sec:     3567, Lr: 0.000200
2022-01-21 12:06:06,679 - INFO - joeynmt.training - Epoch   4, Step:    85400, Batch Loss:     9.063213, Tokens per Sec:     3569, Lr: 0.000200
2022-01-21 12:06:25,573 - INFO - joeynmt.training - Epoch   4, Step:    85500, Batch Loss:     7.282852, Tokens per Sec:     3661, Lr: 0.000200
2022-01-21 12:06:44,225 - INFO - joeynmt.training - Epoch   4, Step:    85600, Batch Loss:     4.487636, Tokens per Sec:     3502, Lr: 0.000200
2022-01-21 12:07:03,346 - INFO - joeynmt.training - Epoch   4, Step:    85700, Batch Loss:     4.293802, Tokens per Sec:     3472, Lr: 0.000200
2022-01-21 12:07:22,488 - INFO - joeynmt.training - Epoch   4, Step:    85800, Batch Loss:     3.279621, Tokens per Sec:     3614, Lr: 0.000200
2022-01-21 12:07:41,389 - INFO - joeynmt.training - Epoch   4, Step:    85900, Batch Loss:     4.415886, Tokens per Sec:     3522, Lr: 0.000200
2022-01-21 12:07:59,847 - INFO - joeynmt.training - Epoch   4, Step:    86000, Batch Loss:     5.516784, Tokens per Sec:     3582, Lr: 0.000200
2022-01-21 12:29:49,531 - INFO - joeynmt.training - Example #0
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 12:29:49,532 - INFO - joeynmt.training - Example #1
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 12:29:49,532 - INFO - joeynmt.training - Example #2
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 12:29:49,532 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 12:29:49,533 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    86000: bleu:  85.33, loss: 311633.4062, ppl:   1.2135, duration: 1309.6856s
2022-01-21 12:30:08,553 - INFO - joeynmt.training - Epoch   4, Step:    86100, Batch Loss:     4.478772, Tokens per Sec:     3528, Lr: 0.000200
2022-01-21 12:30:27,184 - INFO - joeynmt.training - Epoch   4, Step:    86200, Batch Loss:     7.927494, Tokens per Sec:     3709, Lr: 0.000200
2022-01-21 12:30:46,166 - INFO - joeynmt.training - Epoch   4, Step:    86300, Batch Loss:     1.264125, Tokens per Sec:     3517, Lr: 0.000200
2022-01-21 12:31:05,308 - INFO - joeynmt.training - Epoch   4, Step:    86400, Batch Loss:     4.056337, Tokens per Sec:     3544, Lr: 0.000200
2022-01-21 12:31:24,382 - INFO - joeynmt.training - Epoch   4, Step:    86500, Batch Loss:     3.761491, Tokens per Sec:     3490, Lr: 0.000200
2022-01-21 12:31:43,424 - INFO - joeynmt.training - Epoch   4, Step:    86600, Batch Loss:     3.156859, Tokens per Sec:     3499, Lr: 0.000200
2022-01-21 12:32:02,621 - INFO - joeynmt.training - Epoch   4, Step:    86700, Batch Loss:     3.688317, Tokens per Sec:     3509, Lr: 0.000200
2022-01-21 12:32:21,621 - INFO - joeynmt.training - Epoch   4, Step:    86800, Batch Loss:     3.260282, Tokens per Sec:     3570, Lr: 0.000200
2022-01-21 12:32:40,658 - INFO - joeynmt.training - Epoch   4, Step:    86900, Batch Loss:     4.479408, Tokens per Sec:     3535, Lr: 0.000200
2022-01-21 12:32:59,444 - INFO - joeynmt.training - Epoch   4, Step:    87000, Batch Loss:     3.685237, Tokens per Sec:     3450, Lr: 0.000200
2022-01-21 12:54:48,058 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 12:55:20,866 - INFO - joeynmt.helpers - delete models/a_model/82000.ckpt
2022-01-21 12:55:20,958 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/82000.ckpt
2022-01-21 12:55:20,959 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/82000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/82000.ckpt')
2022-01-21 12:55:21,125 - INFO - joeynmt.training - Example #0
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 12:55:21,126 - INFO - joeynmt.training - Example #1
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 12:55:21,126 - INFO - joeynmt.training - Example #2
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 12:55:21,126 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 12:55:21,127 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    87000: bleu:  85.72, loss: 297889.5938, ppl:   1.2032, duration: 1341.6825s
2022-01-21 12:55:40,116 - INFO - joeynmt.training - Epoch   4, Step:    87100, Batch Loss:     4.352342, Tokens per Sec:     3566, Lr: 0.000200
2022-01-21 12:55:59,129 - INFO - joeynmt.training - Epoch   4, Step:    87200, Batch Loss:     3.636031, Tokens per Sec:     3483, Lr: 0.000200
2022-01-21 12:56:17,923 - INFO - joeynmt.training - Epoch   4, Step:    87300, Batch Loss:     2.395452, Tokens per Sec:     3524, Lr: 0.000200
2022-01-21 12:56:36,878 - INFO - joeynmt.training - Epoch   4, Step:    87400, Batch Loss:     5.086884, Tokens per Sec:     3593, Lr: 0.000200
2022-01-21 12:56:55,811 - INFO - joeynmt.training - Epoch   4, Step:    87500, Batch Loss:     5.173908, Tokens per Sec:     3588, Lr: 0.000200
2022-01-21 12:57:14,570 - INFO - joeynmt.training - Epoch   4, Step:    87600, Batch Loss:     2.712286, Tokens per Sec:     3627, Lr: 0.000200
2022-01-21 12:57:33,785 - INFO - joeynmt.training - Epoch   4, Step:    87700, Batch Loss:     5.275908, Tokens per Sec:     3583, Lr: 0.000200
2022-01-21 12:57:52,793 - INFO - joeynmt.training - Epoch   4, Step:    87800, Batch Loss:     2.868530, Tokens per Sec:     3496, Lr: 0.000200
2022-01-21 12:58:11,785 - INFO - joeynmt.training - Epoch   4, Step:    87900, Batch Loss:     2.227247, Tokens per Sec:     3442, Lr: 0.000200
2022-01-21 12:58:30,703 - INFO - joeynmt.training - Epoch   4, Step:    88000, Batch Loss:     4.106595, Tokens per Sec:     3666, Lr: 0.000200
2022-01-21 13:20:15,027 - INFO - joeynmt.training - Example #0
2022-01-21 13:20:15,028 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 13:20:15,028 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 13:20:15,029 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-21 13:20:15,029 - INFO - joeynmt.training - Example #1
2022-01-21 13:20:15,029 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 13:20:15,029 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 13:20:15,029 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 13:20:15,029 - INFO - joeynmt.training - Example #2
2022-01-21 13:20:15,029 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 13:20:15,029 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 13:20:15,029 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 13:20:15,030 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    88000: bleu:  85.69, loss: 302260.0312, ppl:   1.2065, duration: 1304.3263s
2022-01-21 13:20:34,162 - INFO - joeynmt.training - Epoch   4, Step:    88100, Batch Loss:     6.870118, Tokens per Sec:     3536, Lr: 0.000200
2022-01-21 13:20:52,826 - INFO - joeynmt.training - Epoch   4, Step:    88200, Batch Loss:     5.674254, Tokens per Sec:     3748, Lr: 0.000200
2022-01-21 13:21:11,760 - INFO - joeynmt.training - Epoch   4, Step:    88300, Batch Loss:     4.732646, Tokens per Sec:     3643, Lr: 0.000200
2022-01-21 13:21:30,914 - INFO - joeynmt.training - Epoch   4, Step:    88400, Batch Loss:     3.296763, Tokens per Sec:     3570, Lr: 0.000200
2022-01-21 13:21:49,849 - INFO - joeynmt.training - Epoch   4, Step:    88500, Batch Loss:     1.500384, Tokens per Sec:     3564, Lr: 0.000200
2022-01-21 13:22:08,748 - INFO - joeynmt.training - Epoch   4, Step:    88600, Batch Loss:     3.246172, Tokens per Sec:     3585, Lr: 0.000200
2022-01-21 13:22:27,749 - INFO - joeynmt.training - Epoch   4, Step:    88700, Batch Loss:     2.747155, Tokens per Sec:     3658, Lr: 0.000200
2022-01-21 13:22:46,793 - INFO - joeynmt.training - Epoch   4, Step:    88800, Batch Loss:     8.017607, Tokens per Sec:     3469, Lr: 0.000200
2022-01-21 13:23:05,932 - INFO - joeynmt.training - Epoch   4, Step:    88900, Batch Loss:     2.618369, Tokens per Sec:     3584, Lr: 0.000200
2022-01-21 13:23:25,107 - INFO - joeynmt.training - Epoch   4, Step:    89000, Batch Loss:     3.676921, Tokens per Sec:     3640, Lr: 0.000200
2022-01-21 13:45:13,309 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 13:45:46,179 - INFO - joeynmt.helpers - delete models/a_model/87000.ckpt
2022-01-21 13:45:46,231 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/87000.ckpt
2022-01-21 13:45:46,232 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/87000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/87000.ckpt')
2022-01-21 13:45:46,332 - INFO - joeynmt.training - Example #0
2022-01-21 13:45:46,332 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 13:45:46,332 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 13:45:46,332 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-21 13:45:46,332 - INFO - joeynmt.training - Example #1
2022-01-21 13:45:46,332 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 13:45:46,332 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 13:45:46,332 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 13:45:46,332 - INFO - joeynmt.training - Example #2
2022-01-21 13:45:46,332 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 13:45:46,332 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 13:45:46,333 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 13:45:46,334 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    89000: bleu:  85.73, loss: 300722.4062, ppl:   1.2053, duration: 1341.2260s
2022-01-21 13:46:05,712 - INFO - joeynmt.training - Epoch   4, Step:    89100, Batch Loss:     4.641013, Tokens per Sec:     3469, Lr: 0.000200
2022-01-21 13:46:24,581 - INFO - joeynmt.training - Epoch   4, Step:    89200, Batch Loss:     7.181321, Tokens per Sec:     3608, Lr: 0.000200
2022-01-21 13:46:43,572 - INFO - joeynmt.training - Epoch   4, Step:    89300, Batch Loss:     3.477554, Tokens per Sec:     3597, Lr: 0.000200
2022-01-21 13:47:02,508 - INFO - joeynmt.training - Epoch   4, Step:    89400, Batch Loss:     5.555667, Tokens per Sec:     3673, Lr: 0.000200
2022-01-21 13:47:21,457 - INFO - joeynmt.training - Epoch   4, Step:    89500, Batch Loss:     3.216512, Tokens per Sec:     3531, Lr: 0.000200
2022-01-21 13:47:40,319 - INFO - joeynmt.training - Epoch   4, Step:    89600, Batch Loss:     3.853126, Tokens per Sec:     3581, Lr: 0.000200
2022-01-21 13:47:59,275 - INFO - joeynmt.training - Epoch   4, Step:    89700, Batch Loss:     3.794628, Tokens per Sec:     3667, Lr: 0.000200
2022-01-21 13:48:18,006 - INFO - joeynmt.training - Epoch   4, Step:    89800, Batch Loss:     3.828078, Tokens per Sec:     3647, Lr: 0.000200
2022-01-21 13:48:37,014 - INFO - joeynmt.training - Epoch   4, Step:    89900, Batch Loss:     5.322983, Tokens per Sec:     3706, Lr: 0.000200
2022-01-21 13:48:55,593 - INFO - joeynmt.training - Epoch   4, Step:    90000, Batch Loss:     4.572519, Tokens per Sec:     3505, Lr: 0.000200
2022-01-21 14:10:38,157 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 14:11:11,147 - INFO - joeynmt.helpers - delete models/a_model/89000.ckpt
2022-01-21 14:11:11,234 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/89000.ckpt
2022-01-21 14:11:11,239 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/89000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/89000.ckpt')
2022-01-21 14:11:11,393 - INFO - joeynmt.training - Example #0
2022-01-21 14:11:11,393 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 14:11:11,393 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 14:11:11,393 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 14:11:11,393 - INFO - joeynmt.training - Example #1
2022-01-21 14:11:11,393 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 14:11:11,393 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 14:11:11,393 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 14:11:11,393 - INFO - joeynmt.training - Example #2
2022-01-21 14:11:11,394 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 14:11:11,394 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 14:11:11,394 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 14:11:11,395 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    90000: bleu:  85.73, loss: 301053.8125, ppl:   1.2056, duration: 1335.8011s
2022-01-21 14:12:09,948 - INFO - joeynmt.training - Epoch   4, Step:    90100, Batch Loss:     2.686182, Tokens per Sec:     1141, Lr: 0.000200
2022-01-21 14:12:53,790 - INFO - joeynmt.training - Epoch   4, Step:    90200, Batch Loss:     3.100242, Tokens per Sec:     1583, Lr: 0.000200
2022-01-21 14:13:12,666 - INFO - joeynmt.training - Epoch   4, Step:    90300, Batch Loss:     4.917559, Tokens per Sec:     3452, Lr: 0.000200
2022-01-21 14:13:31,595 - INFO - joeynmt.training - Epoch   4, Step:    90400, Batch Loss:     2.810081, Tokens per Sec:     3571, Lr: 0.000200
2022-01-21 14:13:50,588 - INFO - joeynmt.training - Epoch   4, Step:    90500, Batch Loss:     2.778542, Tokens per Sec:     3559, Lr: 0.000200
2022-01-21 14:14:09,571 - INFO - joeynmt.training - Epoch   4, Step:    90600, Batch Loss:     2.249974, Tokens per Sec:     3564, Lr: 0.000200
2022-01-21 14:14:28,462 - INFO - joeynmt.training - Epoch   4, Step:    90700, Batch Loss:     3.924196, Tokens per Sec:     3449, Lr: 0.000200
2022-01-21 14:14:47,334 - INFO - joeynmt.training - Epoch   4, Step:    90800, Batch Loss:     4.085449, Tokens per Sec:     3543, Lr: 0.000200
2022-01-21 14:15:06,113 - INFO - joeynmt.training - Epoch   4, Step:    90900, Batch Loss:     3.899324, Tokens per Sec:     3585, Lr: 0.000200
2022-01-21 14:15:25,011 - INFO - joeynmt.training - Epoch   4, Step:    91000, Batch Loss:     6.404106, Tokens per Sec:     3684, Lr: 0.000200
2022-01-21 14:37:11,877 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 14:37:44,786 - INFO - joeynmt.helpers - delete models/a_model/90000.ckpt
2022-01-21 14:37:44,818 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/90000.ckpt
2022-01-21 14:37:44,819 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/90000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/90000.ckpt')
2022-01-21 14:37:44,924 - INFO - joeynmt.training - Example #0
2022-01-21 14:37:44,924 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 14:37:44,924 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 14:37:44,924 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 14:37:44,924 - INFO - joeynmt.training - Example #1
2022-01-21 14:37:44,925 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 14:37:44,925 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 14:37:44,925 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 14:37:44,925 - INFO - joeynmt.training - Example #2
2022-01-21 14:37:44,925 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 14:37:44,925 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 14:37:44,925 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 14:37:44,926 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    91000: bleu:  85.95, loss: 293655.4062, ppl:   1.2001, duration: 1339.9143s
2022-01-21 14:38:04,254 - INFO - joeynmt.training - Epoch   4, Step:    91100, Batch Loss:     3.726427, Tokens per Sec:     3628, Lr: 0.000200
2022-01-21 14:38:23,240 - INFO - joeynmt.training - Epoch   4, Step:    91200, Batch Loss:     4.141225, Tokens per Sec:     3626, Lr: 0.000200
2022-01-21 14:38:42,268 - INFO - joeynmt.training - Epoch   4, Step:    91300, Batch Loss:     6.112705, Tokens per Sec:     3674, Lr: 0.000200
2022-01-21 14:39:01,222 - INFO - joeynmt.training - Epoch   4, Step:    91400, Batch Loss:     3.689512, Tokens per Sec:     3519, Lr: 0.000200
2022-01-21 14:39:19,971 - INFO - joeynmt.training - Epoch   4, Step:    91500, Batch Loss:     2.541409, Tokens per Sec:     3592, Lr: 0.000200
2022-01-21 14:39:38,816 - INFO - joeynmt.training - Epoch   4, Step:    91600, Batch Loss:     3.532173, Tokens per Sec:     3502, Lr: 0.000200
2022-01-21 14:39:57,738 - INFO - joeynmt.training - Epoch   4, Step:    91700, Batch Loss:     4.253079, Tokens per Sec:     3500, Lr: 0.000200
2022-01-21 14:40:16,195 - INFO - joeynmt.training - Epoch   4, Step:    91800, Batch Loss:     4.701159, Tokens per Sec:     3709, Lr: 0.000200
2022-01-21 14:40:35,118 - INFO - joeynmt.training - Epoch   4, Step:    91900, Batch Loss:     3.739794, Tokens per Sec:     3616, Lr: 0.000200
2022-01-21 14:40:53,894 - INFO - joeynmt.training - Epoch   4, Step:    92000, Batch Loss:     2.960144, Tokens per Sec:     3488, Lr: 0.000200
2022-01-21 15:02:39,983 - INFO - joeynmt.training - Example #0
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 15:02:39,984 - INFO - joeynmt.training - Example #1
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 15:02:39,984 - INFO - joeynmt.training - Example #2
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 15:02:39,984 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 15:02:39,985 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    92000: bleu:  85.58, loss: 302673.7188, ppl:   1.2068, duration: 1306.0914s
2022-01-21 15:02:59,064 - INFO - joeynmt.training - Epoch   4, Step:    92100, Batch Loss:     2.611506, Tokens per Sec:     3559, Lr: 0.000200
2022-01-21 15:03:18,001 - INFO - joeynmt.training - Epoch   4, Step:    92200, Batch Loss:     3.472151, Tokens per Sec:     3602, Lr: 0.000200
2022-01-21 15:03:36,919 - INFO - joeynmt.training - Epoch   4, Step:    92300, Batch Loss:     4.828021, Tokens per Sec:     3547, Lr: 0.000200
2022-01-21 15:03:56,194 - INFO - joeynmt.training - Epoch   4, Step:    92400, Batch Loss:     4.301600, Tokens per Sec:     3570, Lr: 0.000200
2022-01-21 15:04:14,851 - INFO - joeynmt.training - Epoch   4, Step:    92500, Batch Loss:     7.614724, Tokens per Sec:     3510, Lr: 0.000200
2022-01-21 15:04:33,780 - INFO - joeynmt.training - Epoch   4, Step:    92600, Batch Loss:     6.734564, Tokens per Sec:     3614, Lr: 0.000200
2022-01-21 15:04:52,250 - INFO - joeynmt.training - Epoch   4, Step:    92700, Batch Loss:     1.959420, Tokens per Sec:     3479, Lr: 0.000200
2022-01-21 15:05:11,215 - INFO - joeynmt.training - Epoch   4, Step:    92800, Batch Loss:     5.833076, Tokens per Sec:     3676, Lr: 0.000200
2022-01-21 15:05:30,115 - INFO - joeynmt.training - Epoch   4, Step:    92900, Batch Loss:    10.315945, Tokens per Sec:     3708, Lr: 0.000200
2022-01-21 15:05:48,929 - INFO - joeynmt.training - Epoch   4, Step:    93000, Batch Loss:     5.606644, Tokens per Sec:     3464, Lr: 0.000200
2022-01-21 15:27:33,594 - INFO - joeynmt.training - Example #0
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 33 12 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 15:27:33,595 - INFO - joeynmt.training - Example #1
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 15:27:33,595 - INFO - joeynmt.training - Example #2
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 15:27:33,595 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 30 28 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 15:27:33,596 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    93000: bleu:  85.75, loss: 301140.5625, ppl:   1.2057, duration: 1304.6669s
2022-01-21 15:27:53,076 - INFO - joeynmt.training - Epoch   4, Step:    93100, Batch Loss:     1.668834, Tokens per Sec:     3432, Lr: 0.000200
2022-01-21 15:28:11,812 - INFO - joeynmt.training - Epoch   4, Step:    93200, Batch Loss:     3.821090, Tokens per Sec:     3629, Lr: 0.000200
2022-01-21 15:28:30,633 - INFO - joeynmt.training - Epoch   4, Step:    93300, Batch Loss:     3.811445, Tokens per Sec:     3661, Lr: 0.000200
2022-01-21 15:28:49,293 - INFO - joeynmt.training - Epoch   4, Step:    93400, Batch Loss:     4.495326, Tokens per Sec:     3503, Lr: 0.000200
2022-01-21 15:29:07,951 - INFO - joeynmt.training - Epoch   4, Step:    93500, Batch Loss:     7.331312, Tokens per Sec:     3636, Lr: 0.000200
2022-01-21 15:29:27,025 - INFO - joeynmt.training - Epoch   4, Step:    93600, Batch Loss:     2.969775, Tokens per Sec:     3446, Lr: 0.000200
2022-01-21 15:29:46,011 - INFO - joeynmt.training - Epoch   4, Step:    93700, Batch Loss:     2.311533, Tokens per Sec:     3438, Lr: 0.000200
2022-01-21 15:30:05,152 - INFO - joeynmt.training - Epoch   4, Step:    93800, Batch Loss:     5.054938, Tokens per Sec:     3517, Lr: 0.000200
2022-01-21 15:30:24,024 - INFO - joeynmt.training - Epoch   4, Step:    93900, Batch Loss:     3.677803, Tokens per Sec:     3564, Lr: 0.000200
2022-01-21 15:30:43,054 - INFO - joeynmt.training - Epoch   4, Step:    94000, Batch Loss:     3.903358, Tokens per Sec:     3566, Lr: 0.000200
2022-01-21 15:52:27,113 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 15:52:59,932 - INFO - joeynmt.helpers - delete models/a_model/91000.ckpt
2022-01-21 15:52:59,972 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/91000.ckpt
2022-01-21 15:52:59,973 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/91000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/91000.ckpt')
2022-01-21 15:53:00,127 - INFO - joeynmt.training - Example #0
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 15:53:00,128 - INFO - joeynmt.training - Example #1
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 15:53:00,128 - INFO - joeynmt.training - Example #2
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 15:53:00,128 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-21 15:53:00,129 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    94000: bleu:  85.99, loss: 294992.9375, ppl:   1.2011, duration: 1337.0743s
2022-01-21 15:53:18,859 - INFO - joeynmt.training - Epoch   4, Step:    94100, Batch Loss:     5.477447, Tokens per Sec:     3561, Lr: 0.000200
2022-01-21 15:53:37,795 - INFO - joeynmt.training - Epoch   4, Step:    94200, Batch Loss:     4.366771, Tokens per Sec:     3661, Lr: 0.000200
2022-01-21 15:53:56,677 - INFO - joeynmt.training - Epoch   4, Step:    94300, Batch Loss:     1.844475, Tokens per Sec:     3620, Lr: 0.000200
2022-01-21 15:54:15,647 - INFO - joeynmt.training - Epoch   4, Step:    94400, Batch Loss:     2.759232, Tokens per Sec:     3650, Lr: 0.000200
2022-01-21 15:54:34,503 - INFO - joeynmt.training - Epoch   4, Step:    94500, Batch Loss:     3.739374, Tokens per Sec:     3513, Lr: 0.000200
2022-01-21 15:54:53,488 - INFO - joeynmt.training - Epoch   4, Step:    94600, Batch Loss:     3.980650, Tokens per Sec:     3495, Lr: 0.000200
2022-01-21 15:55:12,558 - INFO - joeynmt.training - Epoch   4, Step:    94700, Batch Loss:     5.982330, Tokens per Sec:     3543, Lr: 0.000200
2022-01-21 15:55:31,477 - INFO - joeynmt.training - Epoch   4, Step:    94800, Batch Loss:     1.744461, Tokens per Sec:     3523, Lr: 0.000200
2022-01-21 15:55:50,363 - INFO - joeynmt.training - Epoch   4, Step:    94900, Batch Loss:     1.722246, Tokens per Sec:     3635, Lr: 0.000200
2022-01-21 15:56:09,132 - INFO - joeynmt.training - Epoch   4, Step:    95000, Batch Loss:     3.280165, Tokens per Sec:     3616, Lr: 0.000200
2022-01-21 16:17:53,053 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 16:18:25,784 - INFO - joeynmt.helpers - delete models/a_model/94000.ckpt
2022-01-21 16:18:25,821 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/94000.ckpt
2022-01-21 16:18:25,822 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/94000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/94000.ckpt')
2022-01-21 16:18:25,956 - INFO - joeynmt.training - Example #0
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 16:18:25,957 - INFO - joeynmt.training - Example #1
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 16:18:25,957 - INFO - joeynmt.training - Example #2
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 16:18:25,957 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 16:18:25,958 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    95000: bleu:  86.04, loss: 297490.4062, ppl:   1.2029, duration: 1336.8261s
2022-01-21 16:18:45,163 - INFO - joeynmt.training - Epoch   4, Step:    95100, Batch Loss:     3.538567, Tokens per Sec:     3610, Lr: 0.000200
2022-01-21 16:19:03,727 - INFO - joeynmt.training - Epoch   4, Step:    95200, Batch Loss:     2.094219, Tokens per Sec:     3615, Lr: 0.000200
2022-01-21 16:19:22,798 - INFO - joeynmt.training - Epoch   4, Step:    95300, Batch Loss:     3.601950, Tokens per Sec:     3439, Lr: 0.000200
2022-01-21 16:19:41,741 - INFO - joeynmt.training - Epoch   4, Step:    95400, Batch Loss:     5.099227, Tokens per Sec:     3575, Lr: 0.000200
2022-01-21 16:20:00,566 - INFO - joeynmt.training - Epoch   4, Step:    95500, Batch Loss:     2.977558, Tokens per Sec:     3654, Lr: 0.000200
2022-01-21 16:20:19,106 - INFO - joeynmt.training - Epoch   4, Step:    95600, Batch Loss:     5.316544, Tokens per Sec:     3547, Lr: 0.000200
2022-01-21 16:20:37,791 - INFO - joeynmt.training - Epoch   4, Step:    95700, Batch Loss:     2.960290, Tokens per Sec:     3492, Lr: 0.000200
2022-01-21 16:20:56,887 - INFO - joeynmt.training - Epoch   4, Step:    95800, Batch Loss:     8.811171, Tokens per Sec:     3590, Lr: 0.000200
2022-01-21 16:21:15,720 - INFO - joeynmt.training - Epoch   4, Step:    95900, Batch Loss:     4.904750, Tokens per Sec:     3552, Lr: 0.000200
2022-01-21 16:21:34,609 - INFO - joeynmt.training - Epoch   4, Step:    96000, Batch Loss:     2.308341, Tokens per Sec:     3603, Lr: 0.000200
2022-01-21 16:43:41,038 - INFO - joeynmt.training - Example #0
2022-01-21 16:43:41,039 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 16:43:41,039 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 16:43:41,039 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 16:43:41,039 - INFO - joeynmt.training - Example #1
2022-01-21 16:43:41,039 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 16:43:41,039 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 16:43:41,039 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 16:43:41,039 - INFO - joeynmt.training - Example #2
2022-01-21 16:43:41,040 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 16:43:41,040 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 16:43:41,040 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 16:43:41,041 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    96000: bleu:  86.00, loss: 287696.5000, ppl:   1.1956, duration: 1326.4308s
2022-01-21 16:43:59,806 - INFO - joeynmt.training - Epoch   4, Step:    96100, Batch Loss:     2.844359, Tokens per Sec:     3605, Lr: 0.000200
2022-01-21 16:44:18,621 - INFO - joeynmt.training - Epoch   4, Step:    96200, Batch Loss:     3.124343, Tokens per Sec:     3669, Lr: 0.000200
2022-01-21 16:44:37,505 - INFO - joeynmt.training - Epoch   4, Step:    96300, Batch Loss:     4.457055, Tokens per Sec:     3613, Lr: 0.000200
2022-01-21 16:44:56,497 - INFO - joeynmt.training - Epoch   4, Step:    96400, Batch Loss:     4.166366, Tokens per Sec:     3639, Lr: 0.000200
2022-01-21 16:45:15,362 - INFO - joeynmt.training - Epoch   4, Step:    96500, Batch Loss:     2.237580, Tokens per Sec:     3680, Lr: 0.000200
2022-01-21 16:45:34,327 - INFO - joeynmt.training - Epoch   4, Step:    96600, Batch Loss:     1.827191, Tokens per Sec:     3588, Lr: 0.000200
2022-01-21 16:45:53,225 - INFO - joeynmt.training - Epoch   4, Step:    96700, Batch Loss:     3.624160, Tokens per Sec:     3546, Lr: 0.000200
2022-01-21 16:46:12,093 - INFO - joeynmt.training - Epoch   4, Step:    96800, Batch Loss:    23.031179, Tokens per Sec:     3470, Lr: 0.000200
2022-01-21 16:46:31,278 - INFO - joeynmt.training - Epoch   4, Step:    96900, Batch Loss:     6.278359, Tokens per Sec:     3437, Lr: 0.000200
2022-01-21 16:46:50,696 - INFO - joeynmt.training - Epoch   4, Step:    97000, Batch Loss:     4.948676, Tokens per Sec:     3623, Lr: 0.000200
2022-01-21 17:08:35,568 - INFO - joeynmt.training - Example #0
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 17:08:35,569 - INFO - joeynmt.training - Example #1
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 17:08:35,569 - INFO - joeynmt.training - Example #2
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 17:08:35,569 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 17:08:35,570 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    97000: bleu:  86.02, loss: 291875.0625, ppl:   1.1987, duration: 1304.8736s
2022-01-21 17:08:54,863 - INFO - joeynmt.training - Epoch   4, Step:    97100, Batch Loss:     2.040966, Tokens per Sec:     3467, Lr: 0.000200
2022-01-21 17:09:13,838 - INFO - joeynmt.training - Epoch   4, Step:    97200, Batch Loss:     2.397947, Tokens per Sec:     3671, Lr: 0.000200
2022-01-21 17:09:32,661 - INFO - joeynmt.training - Epoch   4, Step:    97300, Batch Loss:     2.873183, Tokens per Sec:     3671, Lr: 0.000200
2022-01-21 17:09:51,530 - INFO - joeynmt.training - Epoch   4, Step:    97400, Batch Loss:     3.175036, Tokens per Sec:     3498, Lr: 0.000200
2022-01-21 17:10:10,537 - INFO - joeynmt.training - Epoch   4, Step:    97500, Batch Loss:     2.716157, Tokens per Sec:     3631, Lr: 0.000200
2022-01-21 17:10:29,724 - INFO - joeynmt.training - Epoch   4, Step:    97600, Batch Loss:     7.195591, Tokens per Sec:     3523, Lr: 0.000200
2022-01-21 17:10:48,750 - INFO - joeynmt.training - Epoch   4, Step:    97700, Batch Loss:     6.118395, Tokens per Sec:     3656, Lr: 0.000200
2022-01-21 17:11:07,971 - INFO - joeynmt.training - Epoch   4, Step:    97800, Batch Loss:     3.873736, Tokens per Sec:     3496, Lr: 0.000200
2022-01-21 17:11:26,809 - INFO - joeynmt.training - Epoch   4, Step:    97900, Batch Loss:     4.982991, Tokens per Sec:     3563, Lr: 0.000200
2022-01-21 17:11:45,602 - INFO - joeynmt.training - Epoch   4, Step:    98000, Batch Loss:     6.234629, Tokens per Sec:     3540, Lr: 0.000200
2022-01-21 17:33:27,791 - INFO - joeynmt.training - Example #0
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-21 17:33:27,793 - INFO - joeynmt.training - Example #1
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 17:33:27,793 - INFO - joeynmt.training - Example #2
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 17:33:27,793 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 17:33:27,794 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    98000: bleu:  85.74, loss: 295107.6250, ppl:   1.2012, duration: 1302.1922s
2022-01-21 17:33:47,042 - INFO - joeynmt.training - Epoch   4, Step:    98100, Batch Loss:     2.407735, Tokens per Sec:     3522, Lr: 0.000200
2022-01-21 17:34:06,050 - INFO - joeynmt.training - Epoch   4, Step:    98200, Batch Loss:     4.152733, Tokens per Sec:     3480, Lr: 0.000200
2022-01-21 17:34:25,228 - INFO - joeynmt.training - Epoch   4, Step:    98300, Batch Loss:     8.499740, Tokens per Sec:     3496, Lr: 0.000200
2022-01-21 17:34:44,285 - INFO - joeynmt.training - Epoch   4, Step:    98400, Batch Loss:     6.260395, Tokens per Sec:     3641, Lr: 0.000200
2022-01-21 17:35:03,072 - INFO - joeynmt.training - Epoch   4, Step:    98500, Batch Loss:    14.211539, Tokens per Sec:     3475, Lr: 0.000200
2022-01-21 17:35:22,129 - INFO - joeynmt.training - Epoch   4, Step:    98600, Batch Loss:     3.504525, Tokens per Sec:     3531, Lr: 0.000200
2022-01-21 17:35:41,015 - INFO - joeynmt.training - Epoch   4, Step:    98700, Batch Loss:     3.483981, Tokens per Sec:     3655, Lr: 0.000200
2022-01-21 17:35:59,689 - INFO - joeynmt.training - Epoch   4, Step:    98800, Batch Loss:     4.583508, Tokens per Sec:     3586, Lr: 0.000200
2022-01-21 17:36:18,825 - INFO - joeynmt.training - Epoch   4, Step:    98900, Batch Loss:     3.474072, Tokens per Sec:     3655, Lr: 0.000200
2022-01-21 17:36:38,034 - INFO - joeynmt.training - Epoch   4, Step:    99000, Batch Loss:     5.059980, Tokens per Sec:     3603, Lr: 0.000200
2022-01-21 17:58:20,018 - INFO - joeynmt.training - Example #0
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 17:58:20,019 - INFO - joeynmt.training - Example #1
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 17:58:20,019 - INFO - joeynmt.training - Example #2
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 17:58:20,019 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 17:58:20,020 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    99000: bleu:  85.80, loss: 299050.4375, ppl:   1.2041, duration: 1301.9854s
2022-01-21 17:58:38,762 - INFO - joeynmt.training - Epoch   4, Step:    99100, Batch Loss:     3.562188, Tokens per Sec:     3445, Lr: 0.000200
2022-01-21 17:58:57,731 - INFO - joeynmt.training - Epoch   4, Step:    99200, Batch Loss:     2.841757, Tokens per Sec:     3577, Lr: 0.000200
2022-01-21 17:59:16,540 - INFO - joeynmt.training - Epoch   4, Step:    99300, Batch Loss:     2.157920, Tokens per Sec:     3567, Lr: 0.000200
2022-01-21 17:59:35,569 - INFO - joeynmt.training - Epoch   4, Step:    99400, Batch Loss:     2.812442, Tokens per Sec:     3575, Lr: 0.000200
2022-01-21 17:59:54,135 - INFO - joeynmt.training - Epoch   4, Step:    99500, Batch Loss:     4.741399, Tokens per Sec:     3571, Lr: 0.000200
2022-01-21 18:00:13,124 - INFO - joeynmt.training - Epoch   4, Step:    99600, Batch Loss:     3.181034, Tokens per Sec:     3570, Lr: 0.000200
2022-01-21 18:00:31,968 - INFO - joeynmt.training - Epoch   4, Step:    99700, Batch Loss:     3.549840, Tokens per Sec:     3667, Lr: 0.000200
2022-01-21 18:00:51,031 - INFO - joeynmt.training - Epoch   4, Step:    99800, Batch Loss:     3.994474, Tokens per Sec:     3648, Lr: 0.000200
2022-01-21 18:01:09,845 - INFO - joeynmt.training - Epoch   4, Step:    99900, Batch Loss:     3.739882, Tokens per Sec:     3603, Lr: 0.000200
2022-01-21 18:01:28,735 - INFO - joeynmt.training - Epoch   4, Step:   100000, Batch Loss:     3.411373, Tokens per Sec:     3691, Lr: 0.000200
2022-01-21 18:23:17,657 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 18:23:51,414 - INFO - joeynmt.helpers - delete models/a_model/95000.ckpt
2022-01-21 18:23:51,453 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/95000.ckpt
2022-01-21 18:23:51,454 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/95000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/95000.ckpt')
2022-01-21 18:23:51,568 - INFO - joeynmt.training - Example #0
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 18:23:51,568 - INFO - joeynmt.training - Example #1
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 18:23:51,568 - INFO - joeynmt.training - Example #2
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 18:23:51,568 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 18:23:51,579 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step   100000: bleu:  86.11, loss: 288236.7188, ppl:   1.1960, duration: 1342.8434s
2022-01-21 18:24:10,770 - INFO - joeynmt.training - Epoch   4, Step:   100100, Batch Loss:     2.728801, Tokens per Sec:     3532, Lr: 0.000200
2022-01-21 18:24:29,495 - INFO - joeynmt.training - Epoch   4, Step:   100200, Batch Loss:     2.887157, Tokens per Sec:     3641, Lr: 0.000200
2022-01-21 18:24:48,258 - INFO - joeynmt.training - Epoch   4, Step:   100300, Batch Loss:     5.208814, Tokens per Sec:     3575, Lr: 0.000200
2022-01-21 18:25:06,944 - INFO - joeynmt.training - Epoch   4, Step:   100400, Batch Loss:     2.964742, Tokens per Sec:     3622, Lr: 0.000200
2022-01-21 18:25:25,952 - INFO - joeynmt.training - Epoch   4, Step:   100500, Batch Loss:     3.476841, Tokens per Sec:     3680, Lr: 0.000200
2022-01-21 18:25:45,013 - INFO - joeynmt.training - Epoch   4, Step:   100600, Batch Loss:     3.333688, Tokens per Sec:     3561, Lr: 0.000200
2022-01-21 18:26:04,061 - INFO - joeynmt.training - Epoch   4, Step:   100700, Batch Loss:     3.914701, Tokens per Sec:     3607, Lr: 0.000200
2022-01-21 18:26:22,986 - INFO - joeynmt.training - Epoch   4, Step:   100800, Batch Loss:     6.010674, Tokens per Sec:     3637, Lr: 0.000200
2022-01-21 18:26:41,518 - INFO - joeynmt.training - Epoch   4, Step:   100900, Batch Loss:     6.307572, Tokens per Sec:     3728, Lr: 0.000200
2022-01-21 18:27:00,345 - INFO - joeynmt.training - Epoch   4, Step:   101000, Batch Loss:     4.161243, Tokens per Sec:     3523, Lr: 0.000200
2022-01-21 18:48:47,121 - INFO - joeynmt.training - Example #0
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 18:48:47,122 - INFO - joeynmt.training - Example #1
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 18:48:47,122 - INFO - joeynmt.training - Example #2
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 18:48:47,122 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 18:48:47,123 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step   101000: bleu:  85.96, loss: 286278.0312, ppl:   1.1946, duration: 1306.7772s
2022-01-21 18:49:05,876 - INFO - joeynmt.training - Epoch   4, Step:   101100, Batch Loss:     3.012794, Tokens per Sec:     3504, Lr: 0.000200
2022-01-21 18:49:24,600 - INFO - joeynmt.training - Epoch   4, Step:   101200, Batch Loss:     6.216017, Tokens per Sec:     3689, Lr: 0.000200
2022-01-21 18:49:43,731 - INFO - joeynmt.training - Epoch   4, Step:   101300, Batch Loss:     2.524274, Tokens per Sec:     3548, Lr: 0.000200
2022-01-21 18:50:02,397 - INFO - joeynmt.training - Epoch   4, Step:   101400, Batch Loss:     2.691665, Tokens per Sec:     3618, Lr: 0.000200
2022-01-21 18:50:21,230 - INFO - joeynmt.training - Epoch   4, Step:   101500, Batch Loss:     8.904844, Tokens per Sec:     3470, Lr: 0.000200
2022-01-21 18:50:40,210 - INFO - joeynmt.training - Epoch   4, Step:   101600, Batch Loss:     1.819730, Tokens per Sec:     3521, Lr: 0.000200
2022-01-21 18:50:59,161 - INFO - joeynmt.training - Epoch   4, Step:   101700, Batch Loss:     2.297826, Tokens per Sec:     3606, Lr: 0.000200
2022-01-21 18:51:18,395 - INFO - joeynmt.training - Epoch   4, Step:   101800, Batch Loss:     2.832819, Tokens per Sec:     3535, Lr: 0.000200
2022-01-21 18:51:37,340 - INFO - joeynmt.training - Epoch   4, Step:   101900, Batch Loss:    15.837192, Tokens per Sec:     3702, Lr: 0.000200
2022-01-21 18:51:56,186 - INFO - joeynmt.training - Epoch   4, Step:   102000, Batch Loss:     4.438695, Tokens per Sec:     3650, Lr: 0.000200
2022-01-21 19:13:42,201 - INFO - joeynmt.training - Example #0
2022-01-21 19:13:42,202 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 19:13:42,202 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 19:13:42,202 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 19:13:42,202 - INFO - joeynmt.training - Example #1
2022-01-21 19:13:42,202 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 19:13:42,202 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 19:13:42,202 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 19:13:42,202 - INFO - joeynmt.training - Example #2
2022-01-21 19:13:42,202 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 19:13:42,203 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 19:13:42,203 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 19:13:42,203 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step   102000: bleu:  86.03, loss: 294134.1875, ppl:   1.2004, duration: 1306.0169s
2022-01-21 19:14:01,250 - INFO - joeynmt.training - Epoch   4, Step:   102100, Batch Loss:     2.009628, Tokens per Sec:     3462, Lr: 0.000200
2022-01-21 19:14:20,234 - INFO - joeynmt.training - Epoch   4, Step:   102200, Batch Loss:     4.123208, Tokens per Sec:     3559, Lr: 0.000200
2022-01-21 19:14:38,878 - INFO - joeynmt.training - Epoch   4, Step:   102300, Batch Loss:     3.271610, Tokens per Sec:     3621, Lr: 0.000200
2022-01-21 19:14:57,573 - INFO - joeynmt.training - Epoch   4, Step:   102400, Batch Loss:     4.015319, Tokens per Sec:     3545, Lr: 0.000200
2022-01-21 19:15:16,461 - INFO - joeynmt.training - Epoch   4, Step:   102500, Batch Loss:     4.461385, Tokens per Sec:     3685, Lr: 0.000200
2022-01-21 19:15:35,184 - INFO - joeynmt.training - Epoch   4, Step:   102600, Batch Loss:     1.740007, Tokens per Sec:     3703, Lr: 0.000200
2022-01-21 19:15:53,843 - INFO - joeynmt.training - Epoch   4, Step:   102700, Batch Loss:     4.506989, Tokens per Sec:     3638, Lr: 0.000200
2022-01-21 19:16:12,474 - INFO - joeynmt.training - Epoch   4, Step:   102800, Batch Loss:     3.692805, Tokens per Sec:     3575, Lr: 0.000200
2022-01-21 19:16:31,171 - INFO - joeynmt.training - Epoch   4, Step:   102900, Batch Loss:     3.857615, Tokens per Sec:     3692, Lr: 0.000200
2022-01-21 19:16:49,993 - INFO - joeynmt.training - Epoch   4, Step:   103000, Batch Loss:     2.528832, Tokens per Sec:     3569, Lr: 0.000200
2022-01-21 19:38:42,957 - INFO - joeynmt.training - Example #0
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 19:38:42,958 - INFO - joeynmt.training - Example #1
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 19:38:42,958 - INFO - joeynmt.training - Example #2
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 19:38:42,958 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 19:38:42,959 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step   103000: bleu:  85.72, loss: 300840.6562, ppl:   1.2054, duration: 1312.9660s
2022-01-21 19:39:02,490 - INFO - joeynmt.training - Epoch   4, Step:   103100, Batch Loss:     4.063874, Tokens per Sec:     3475, Lr: 0.000200
2022-01-21 19:39:21,473 - INFO - joeynmt.training - Epoch   4, Step:   103200, Batch Loss:     4.490360, Tokens per Sec:     3607, Lr: 0.000200
2022-01-21 19:39:40,375 - INFO - joeynmt.training - Epoch   4, Step:   103300, Batch Loss:     3.725639, Tokens per Sec:     3482, Lr: 0.000200
2022-01-21 19:39:59,202 - INFO - joeynmt.training - Epoch   4, Step:   103400, Batch Loss:     3.945227, Tokens per Sec:     3495, Lr: 0.000200
2022-01-21 19:40:18,050 - INFO - joeynmt.training - Epoch   4, Step:   103500, Batch Loss:     8.556198, Tokens per Sec:     3669, Lr: 0.000200
2022-01-21 19:40:37,002 - INFO - joeynmt.training - Epoch   4, Step:   103600, Batch Loss:     2.797881, Tokens per Sec:     3633, Lr: 0.000200
2022-01-21 19:40:55,674 - INFO - joeynmt.training - Epoch   4, Step:   103700, Batch Loss:     3.539620, Tokens per Sec:     3647, Lr: 0.000200
2022-01-21 19:41:14,581 - INFO - joeynmt.training - Epoch   4, Step:   103800, Batch Loss:     3.501554, Tokens per Sec:     3554, Lr: 0.000200
2022-01-21 19:41:33,390 - INFO - joeynmt.training - Epoch   4, Step:   103900, Batch Loss:     3.942361, Tokens per Sec:     3635, Lr: 0.000200
2022-01-21 19:41:52,323 - INFO - joeynmt.training - Epoch   4, Step:   104000, Batch Loss:     5.839320, Tokens per Sec:     3521, Lr: 0.000200
2022-01-21 20:03:36,570 - INFO - joeynmt.training - Example #0
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 20:03:36,571 - INFO - joeynmt.training - Example #1
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 20:03:36,571 - INFO - joeynmt.training - Example #2
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 20:03:36,571 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 20:03:36,572 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step   104000: bleu:  86.10, loss: 288164.2500, ppl:   1.1960, duration: 1304.2491s
2022-01-21 20:03:55,683 - INFO - joeynmt.training - Epoch   4, Step:   104100, Batch Loss:     3.495193, Tokens per Sec:     3513, Lr: 0.000200
2022-01-21 20:04:14,438 - INFO - joeynmt.training - Epoch   4, Step:   104200, Batch Loss:     3.279774, Tokens per Sec:     3632, Lr: 0.000200
2022-01-21 20:04:33,405 - INFO - joeynmt.training - Epoch   4, Step:   104300, Batch Loss:     8.890553, Tokens per Sec:     3588, Lr: 0.000200
2022-01-21 20:04:52,252 - INFO - joeynmt.training - Epoch   4, Step:   104400, Batch Loss:     4.963993, Tokens per Sec:     3502, Lr: 0.000200
2022-01-21 20:05:11,232 - INFO - joeynmt.training - Epoch   4, Step:   104500, Batch Loss:     4.233975, Tokens per Sec:     3572, Lr: 0.000200
2022-01-21 20:05:30,138 - INFO - joeynmt.training - Epoch   4, Step:   104600, Batch Loss:     8.874788, Tokens per Sec:     3626, Lr: 0.000200
2022-01-21 20:05:49,074 - INFO - joeynmt.training - Epoch   4, Step:   104700, Batch Loss:     3.191936, Tokens per Sec:     3676, Lr: 0.000200
2022-01-21 20:06:08,134 - INFO - joeynmt.training - Epoch   4, Step:   104800, Batch Loss:     2.574418, Tokens per Sec:     3582, Lr: 0.000200
2022-01-21 20:06:26,958 - INFO - joeynmt.training - Epoch   4, Step:   104900, Batch Loss:     2.335796, Tokens per Sec:     3571, Lr: 0.000200
2022-01-21 20:06:45,815 - INFO - joeynmt.training - Epoch   4, Step:   105000, Batch Loss:     3.375399, Tokens per Sec:     3490, Lr: 0.000200
2022-01-21 20:28:33,501 - INFO - joeynmt.training - Example #0
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 20:28:33,503 - INFO - joeynmt.training - Example #1
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 20:28:33,503 - INFO - joeynmt.training - Example #2
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 20:28:33,503 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 20:28:33,504 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step   105000: bleu:  85.92, loss: 290902.0938, ppl:   1.1980, duration: 1307.6882s
2022-01-21 20:28:52,822 - INFO - joeynmt.training - Epoch   4, Step:   105100, Batch Loss:     2.417959, Tokens per Sec:     3532, Lr: 0.000200
2022-01-21 20:29:11,686 - INFO - joeynmt.training - Epoch   4, Step:   105200, Batch Loss:     1.685683, Tokens per Sec:     3584, Lr: 0.000200
2022-01-21 20:29:30,439 - INFO - joeynmt.training - Epoch   4, Step:   105300, Batch Loss:     2.115421, Tokens per Sec:     3611, Lr: 0.000200
2022-01-21 20:29:49,507 - INFO - joeynmt.training - Epoch   4, Step:   105400, Batch Loss:     3.865464, Tokens per Sec:     3565, Lr: 0.000200
2022-01-21 20:30:08,412 - INFO - joeynmt.training - Epoch   4, Step:   105500, Batch Loss:     3.388677, Tokens per Sec:     3570, Lr: 0.000200
2022-01-21 20:30:27,180 - INFO - joeynmt.training - Epoch   4, Step:   105600, Batch Loss:     3.480743, Tokens per Sec:     3574, Lr: 0.000200
2022-01-21 20:30:45,819 - INFO - joeynmt.training - Epoch   4, Step:   105700, Batch Loss:     4.090034, Tokens per Sec:     3714, Lr: 0.000200
2022-01-21 20:31:04,830 - INFO - joeynmt.training - Epoch   4, Step:   105800, Batch Loss:     3.674631, Tokens per Sec:     3583, Lr: 0.000200
2022-01-21 20:31:23,538 - INFO - joeynmt.training - Epoch   4, Step:   105900, Batch Loss:     2.739303, Tokens per Sec:     3594, Lr: 0.000200
2022-01-21 20:31:42,353 - INFO - joeynmt.training - Epoch   4, Step:   106000, Batch Loss:     2.811197, Tokens per Sec:     3550, Lr: 0.000200
2022-01-21 20:53:29,596 - INFO - joeynmt.training - Example #0
2022-01-21 20:53:29,597 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 20:53:29,597 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 20:53:29,597 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 20:53:29,597 - INFO - joeynmt.training - Example #1
2022-01-21 20:53:29,597 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 20:53:29,597 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 20:53:29,598 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 20:53:29,598 - INFO - joeynmt.training - Example #2
2022-01-21 20:53:29,598 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 20:53:29,598 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 20:53:29,598 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 20:53:29,598 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step   106000: bleu:  85.98, loss: 286954.3750, ppl:   1.1951, duration: 1307.2449s
2022-01-21 20:53:48,464 - INFO - joeynmt.training - Epoch   4, Step:   106100, Batch Loss:     3.202483, Tokens per Sec:     3735, Lr: 0.000200
2022-01-21 20:54:07,083 - INFO - joeynmt.training - Epoch   4, Step:   106200, Batch Loss:     4.311380, Tokens per Sec:     3673, Lr: 0.000200
2022-01-21 20:54:17,655 - INFO - joeynmt.training - Epoch   4: total training loss 117166.33
2022-01-21 20:54:17,655 - INFO - joeynmt.training - EPOCH 5
2022-01-21 20:54:25,721 - INFO - joeynmt.training - Epoch   5, Step:   106300, Batch Loss:     4.479826, Tokens per Sec:     3458, Lr: 0.000200
2022-01-21 20:54:43,622 - INFO - joeynmt.training - Epoch   5, Step:   106400, Batch Loss:     2.627733, Tokens per Sec:     3804, Lr: 0.000200
2022-01-21 20:55:01,612 - INFO - joeynmt.training - Epoch   5, Step:   106500, Batch Loss:     6.751887, Tokens per Sec:     3700, Lr: 0.000200
2022-01-21 20:55:19,518 - INFO - joeynmt.training - Epoch   5, Step:   106600, Batch Loss:     2.354561, Tokens per Sec:     3806, Lr: 0.000200
2022-01-21 20:55:37,425 - INFO - joeynmt.training - Epoch   5, Step:   106700, Batch Loss:     2.675777, Tokens per Sec:     3690, Lr: 0.000200
2022-01-21 20:55:55,381 - INFO - joeynmt.training - Epoch   5, Step:   106800, Batch Loss:     3.281213, Tokens per Sec:     3884, Lr: 0.000200
2022-01-21 20:56:13,394 - INFO - joeynmt.training - Epoch   5, Step:   106900, Batch Loss:     2.500072, Tokens per Sec:     3801, Lr: 0.000200
2022-01-21 20:56:31,500 - INFO - joeynmt.training - Epoch   5, Step:   107000, Batch Loss:     3.000163, Tokens per Sec:     3751, Lr: 0.000200
2022-01-21 21:18:16,436 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 21:18:49,235 - INFO - joeynmt.helpers - delete models/a_model/100000.ckpt
2022-01-21 21:18:49,275 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/100000.ckpt
2022-01-21 21:18:49,276 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/100000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/100000.ckpt')
2022-01-21 21:18:49,371 - INFO - joeynmt.training - Example #0
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 21:18:49,372 - INFO - joeynmt.training - Example #1
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 21:18:49,372 - INFO - joeynmt.training - Example #2
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 21:18:49,372 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 21:18:49,373 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   107000: bleu:  86.17, loss: 291929.1875, ppl:   1.1988, duration: 1337.8726s
2022-01-21 21:19:08,023 - INFO - joeynmt.training - Epoch   5, Step:   107100, Batch Loss:     2.086196, Tokens per Sec:     3612, Lr: 0.000200
2022-01-21 21:19:26,328 - INFO - joeynmt.training - Epoch   5, Step:   107200, Batch Loss:     4.794923, Tokens per Sec:     3556, Lr: 0.000200
2022-01-21 21:19:44,786 - INFO - joeynmt.training - Epoch   5, Step:   107300, Batch Loss:     3.399889, Tokens per Sec:     3762, Lr: 0.000200
2022-01-21 21:20:03,151 - INFO - joeynmt.training - Epoch   5, Step:   107400, Batch Loss:     5.172752, Tokens per Sec:     3520, Lr: 0.000200
2022-01-21 21:20:21,851 - INFO - joeynmt.training - Epoch   5, Step:   107500, Batch Loss:     4.732436, Tokens per Sec:     3469, Lr: 0.000200
2022-01-21 21:20:40,120 - INFO - joeynmt.training - Epoch   5, Step:   107600, Batch Loss:     3.941620, Tokens per Sec:     3623, Lr: 0.000200
2022-01-21 21:20:58,657 - INFO - joeynmt.training - Epoch   5, Step:   107700, Batch Loss:     4.365875, Tokens per Sec:     3601, Lr: 0.000200
2022-01-21 21:21:17,347 - INFO - joeynmt.training - Epoch   5, Step:   107800, Batch Loss:     3.440905, Tokens per Sec:     3558, Lr: 0.000200
2022-01-21 21:21:36,796 - INFO - joeynmt.training - Epoch   5, Step:   107900, Batch Loss:     2.023525, Tokens per Sec:     3453, Lr: 0.000200
2022-01-21 21:21:56,163 - INFO - joeynmt.training - Epoch   5, Step:   108000, Batch Loss:     4.238628, Tokens per Sec:     3430, Lr: 0.000200
2022-01-21 21:44:03,398 - INFO - joeynmt.training - Example #0
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-21 21:44:03,399 - INFO - joeynmt.training - Example #1
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 21:44:03,399 - INFO - joeynmt.training - Example #2
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 21:44:03,399 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 21:44:03,400 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   108000: bleu:  86.08, loss: 288356.7500, ppl:   1.1961, duration: 1327.2368s
2022-01-21 21:44:22,450 - INFO - joeynmt.training - Epoch   5, Step:   108100, Batch Loss:     2.902709, Tokens per Sec:     3528, Lr: 0.000200
2022-01-21 21:44:41,173 - INFO - joeynmt.training - Epoch   5, Step:   108200, Batch Loss:     2.988528, Tokens per Sec:     3547, Lr: 0.000200
2022-01-21 21:45:00,160 - INFO - joeynmt.training - Epoch   5, Step:   108300, Batch Loss:     3.261377, Tokens per Sec:     3641, Lr: 0.000200
2022-01-21 21:45:18,916 - INFO - joeynmt.training - Epoch   5, Step:   108400, Batch Loss:     3.918355, Tokens per Sec:     3586, Lr: 0.000200
2022-01-21 21:45:37,750 - INFO - joeynmt.training - Epoch   5, Step:   108500, Batch Loss:     5.624886, Tokens per Sec:     3786, Lr: 0.000200
2022-01-21 21:45:56,350 - INFO - joeynmt.training - Epoch   5, Step:   108600, Batch Loss:     2.651292, Tokens per Sec:     3471, Lr: 0.000200
2022-01-21 21:46:15,132 - INFO - joeynmt.training - Epoch   5, Step:   108700, Batch Loss:     5.829778, Tokens per Sec:     3513, Lr: 0.000200
2022-01-21 21:46:33,747 - INFO - joeynmt.training - Epoch   5, Step:   108800, Batch Loss:     3.136702, Tokens per Sec:     3745, Lr: 0.000200
2022-01-21 21:46:52,445 - INFO - joeynmt.training - Epoch   5, Step:   108900, Batch Loss:     2.470409, Tokens per Sec:     3552, Lr: 0.000200
2022-01-21 21:47:11,534 - INFO - joeynmt.training - Epoch   5, Step:   109000, Batch Loss:     2.804540, Tokens per Sec:     3448, Lr: 0.000200
2022-01-21 22:08:53,991 - INFO - joeynmt.training - Example #0
2022-01-21 22:08:53,992 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 22:08:53,992 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 22:08:53,992 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-21 22:08:53,992 - INFO - joeynmt.training - Example #1
2022-01-21 22:08:53,992 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 22:08:53,993 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 22:08:53,993 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 22:08:53,993 - INFO - joeynmt.training - Example #2
2022-01-21 22:08:53,993 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 22:08:53,993 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 22:08:53,993 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 22:08:53,994 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   109000: bleu:  86.07, loss: 285445.6562, ppl:   1.1940, duration: 1302.4596s
2022-01-21 22:09:12,632 - INFO - joeynmt.training - Epoch   5, Step:   109100, Batch Loss:     3.292994, Tokens per Sec:     3448, Lr: 0.000200
2022-01-21 22:09:31,113 - INFO - joeynmt.training - Epoch   5, Step:   109200, Batch Loss:     3.987603, Tokens per Sec:     3569, Lr: 0.000200
2022-01-21 22:09:49,589 - INFO - joeynmt.training - Epoch   5, Step:   109300, Batch Loss:     2.306873, Tokens per Sec:     3739, Lr: 0.000200
2022-01-21 22:10:08,001 - INFO - joeynmt.training - Epoch   5, Step:   109400, Batch Loss:     3.518489, Tokens per Sec:     3679, Lr: 0.000200
2022-01-21 22:10:26,878 - INFO - joeynmt.training - Epoch   5, Step:   109500, Batch Loss:     1.903100, Tokens per Sec:     3621, Lr: 0.000200
2022-01-21 22:10:46,028 - INFO - joeynmt.training - Epoch   5, Step:   109600, Batch Loss:     2.294956, Tokens per Sec:     3492, Lr: 0.000200
2022-01-21 22:11:05,459 - INFO - joeynmt.training - Epoch   5, Step:   109700, Batch Loss:     1.638776, Tokens per Sec:     3426, Lr: 0.000200
2022-01-21 22:11:25,072 - INFO - joeynmt.training - Epoch   5, Step:   109800, Batch Loss:     3.186177, Tokens per Sec:     3471, Lr: 0.000200
2022-01-21 22:11:44,519 - INFO - joeynmt.training - Epoch   5, Step:   109900, Batch Loss:     3.914639, Tokens per Sec:     3557, Lr: 0.000200
2022-01-21 22:12:03,745 - INFO - joeynmt.training - Epoch   5, Step:   110000, Batch Loss:     3.624795, Tokens per Sec:     3367, Lr: 0.000200
2022-01-21 22:33:49,790 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 22:34:22,543 - INFO - joeynmt.helpers - delete models/a_model/107000.ckpt
2022-01-21 22:34:22,591 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/107000.ckpt
2022-01-21 22:34:22,592 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/107000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/107000.ckpt')
2022-01-21 22:34:22,718 - INFO - joeynmt.training - Example #0
2022-01-21 22:34:22,718 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 22:34:22,718 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 22:34:22,718 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 22:34:22,718 - INFO - joeynmt.training - Example #1
2022-01-21 22:34:22,719 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 22:34:22,719 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 22:34:22,719 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 22:34:22,719 - INFO - joeynmt.training - Example #2
2022-01-21 22:34:22,719 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 22:34:22,719 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 22:34:22,719 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 22:34:22,720 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   110000: bleu:  86.24, loss: 286350.6875, ppl:   1.1946, duration: 1338.9747s
2022-01-21 22:34:41,425 - INFO - joeynmt.training - Epoch   5, Step:   110100, Batch Loss:     3.591801, Tokens per Sec:     3600, Lr: 0.000200
2022-01-21 22:35:00,056 - INFO - joeynmt.training - Epoch   5, Step:   110200, Batch Loss:     6.109687, Tokens per Sec:     3631, Lr: 0.000200
2022-01-21 22:35:18,486 - INFO - joeynmt.training - Epoch   5, Step:   110300, Batch Loss:     3.202819, Tokens per Sec:     3626, Lr: 0.000200
2022-01-21 22:35:36,662 - INFO - joeynmt.training - Epoch   5, Step:   110400, Batch Loss:     2.782406, Tokens per Sec:     3806, Lr: 0.000200
2022-01-21 22:35:55,192 - INFO - joeynmt.training - Epoch   5, Step:   110500, Batch Loss:     3.066177, Tokens per Sec:     3718, Lr: 0.000200
2022-01-21 22:36:13,677 - INFO - joeynmt.training - Epoch   5, Step:   110600, Batch Loss:     4.197116, Tokens per Sec:     3757, Lr: 0.000200
2022-01-21 22:36:32,296 - INFO - joeynmt.training - Epoch   5, Step:   110700, Batch Loss:     5.033067, Tokens per Sec:     3609, Lr: 0.000200
2022-01-21 22:36:50,701 - INFO - joeynmt.training - Epoch   5, Step:   110800, Batch Loss:     7.830029, Tokens per Sec:     3673, Lr: 0.000200
2022-01-21 22:37:09,273 - INFO - joeynmt.training - Epoch   5, Step:   110900, Batch Loss:     7.353172, Tokens per Sec:     3581, Lr: 0.000200
2022-01-21 22:37:27,542 - INFO - joeynmt.training - Epoch   5, Step:   111000, Batch Loss:     2.753314, Tokens per Sec:     3766, Lr: 0.000200
2022-01-21 22:59:13,626 - INFO - joeynmt.training - Example #0
2022-01-21 22:59:13,627 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 22:59:13,627 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 22:59:13,627 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 22:59:13,628 - INFO - joeynmt.training - Example #1
2022-01-21 22:59:13,628 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 22:59:13,628 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 22:59:13,628 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-21 22:59:13,628 - INFO - joeynmt.training - Example #2
2022-01-21 22:59:13,628 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 22:59:13,628 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 22:59:13,628 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 22:59:13,629 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   111000: bleu:  86.24, loss: 282192.4062, ppl:   1.1916, duration: 1306.0866s
2022-01-21 22:59:32,407 - INFO - joeynmt.training - Epoch   5, Step:   111100, Batch Loss:     3.713949, Tokens per Sec:     3515, Lr: 0.000200
2022-01-21 22:59:50,847 - INFO - joeynmt.training - Epoch   5, Step:   111200, Batch Loss:     2.846976, Tokens per Sec:     3775, Lr: 0.000200
2022-01-21 23:00:09,195 - INFO - joeynmt.training - Epoch   5, Step:   111300, Batch Loss:     3.051617, Tokens per Sec:     3660, Lr: 0.000200
2022-01-21 23:00:27,445 - INFO - joeynmt.training - Epoch   5, Step:   111400, Batch Loss:     4.315476, Tokens per Sec:     3750, Lr: 0.000200
2022-01-21 23:00:45,846 - INFO - joeynmt.training - Epoch   5, Step:   111500, Batch Loss:     1.995718, Tokens per Sec:     3717, Lr: 0.000200
2022-01-21 23:01:04,300 - INFO - joeynmt.training - Epoch   5, Step:   111600, Batch Loss:     1.475314, Tokens per Sec:     3623, Lr: 0.000200
2022-01-21 23:01:23,020 - INFO - joeynmt.training - Epoch   5, Step:   111700, Batch Loss:     2.939632, Tokens per Sec:     3560, Lr: 0.000200
2022-01-21 23:01:41,842 - INFO - joeynmt.training - Epoch   5, Step:   111800, Batch Loss:     5.004165, Tokens per Sec:     3491, Lr: 0.000200
2022-01-21 23:02:00,599 - INFO - joeynmt.training - Epoch   5, Step:   111900, Batch Loss:     4.493309, Tokens per Sec:     3644, Lr: 0.000200
2022-01-21 23:02:19,590 - INFO - joeynmt.training - Epoch   5, Step:   112000, Batch Loss:     7.785293, Tokens per Sec:     3675, Lr: 0.000200
2022-01-21 23:24:03,495 - INFO - joeynmt.training - Example #0
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 23:24:03,496 - INFO - joeynmt.training - Example #1
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 23:24:03,496 - INFO - joeynmt.training - Example #2
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 23:24:03,496 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-21 23:24:03,497 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   112000: bleu:  86.14, loss: 293791.0000, ppl:   1.2002, duration: 1303.9061s
2022-01-21 23:24:22,422 - INFO - joeynmt.training - Epoch   5, Step:   112100, Batch Loss:     2.563199, Tokens per Sec:     3630, Lr: 0.000200
2022-01-21 23:24:40,809 - INFO - joeynmt.training - Epoch   5, Step:   112200, Batch Loss:     3.974152, Tokens per Sec:     3726, Lr: 0.000200
2022-01-21 23:24:59,216 - INFO - joeynmt.training - Epoch   5, Step:   112300, Batch Loss:     6.737387, Tokens per Sec:     3679, Lr: 0.000200
2022-01-21 23:25:17,524 - INFO - joeynmt.training - Epoch   5, Step:   112400, Batch Loss:     3.226578, Tokens per Sec:     3652, Lr: 0.000200
2022-01-21 23:25:35,961 - INFO - joeynmt.training - Epoch   5, Step:   112500, Batch Loss:     3.227216, Tokens per Sec:     3786, Lr: 0.000200
2022-01-21 23:26:03,607 - INFO - joeynmt.training - Epoch   5, Step:   112600, Batch Loss:     2.340542, Tokens per Sec:     2445, Lr: 0.000200
2022-01-21 23:26:42,343 - INFO - joeynmt.training - Epoch   5, Step:   112700, Batch Loss:     1.895920, Tokens per Sec:     1727, Lr: 0.000200
2022-01-21 23:27:01,036 - INFO - joeynmt.training - Epoch   5, Step:   112800, Batch Loss:     2.965276, Tokens per Sec:     3662, Lr: 0.000200
2022-01-21 23:27:19,825 - INFO - joeynmt.training - Epoch   5, Step:   112900, Batch Loss:     5.109499, Tokens per Sec:     3735, Lr: 0.000200
2022-01-21 23:27:38,630 - INFO - joeynmt.training - Epoch   5, Step:   113000, Batch Loss:     2.907153, Tokens per Sec:     3713, Lr: 0.000200
2022-01-21 23:49:27,139 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-21 23:49:59,842 - INFO - joeynmt.helpers - delete models/a_model/110000.ckpt
2022-01-21 23:49:59,889 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/110000.ckpt
2022-01-21 23:49:59,889 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/110000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/110000.ckpt')
2022-01-21 23:49:59,933 - INFO - joeynmt.training - Example #0
2022-01-21 23:49:59,933 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-21 23:49:59,933 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 23:49:59,933 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 33 12 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-21 23:49:59,933 - INFO - joeynmt.training - Example #1
2022-01-21 23:49:59,933 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-21 23:49:59,933 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-21 23:49:59,933 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-21 23:49:59,933 - INFO - joeynmt.training - Example #2
2022-01-21 23:49:59,934 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-21 23:49:59,934 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-21 23:49:59,934 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-21 23:49:59,934 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   113000: bleu:  86.31, loss: 285929.1562, ppl:   1.1943, duration: 1341.3043s
2022-01-21 23:50:18,896 - INFO - joeynmt.training - Epoch   5, Step:   113100, Batch Loss:     3.243265, Tokens per Sec:     3576, Lr: 0.000200
2022-01-21 23:50:37,618 - INFO - joeynmt.training - Epoch   5, Step:   113200, Batch Loss:     3.868400, Tokens per Sec:     3576, Lr: 0.000200
2022-01-21 23:50:56,439 - INFO - joeynmt.training - Epoch   5, Step:   113300, Batch Loss:     3.002299, Tokens per Sec:     3582, Lr: 0.000200
2022-01-21 23:51:15,040 - INFO - joeynmt.training - Epoch   5, Step:   113400, Batch Loss:     2.478632, Tokens per Sec:     3624, Lr: 0.000200
2022-01-21 23:51:33,848 - INFO - joeynmt.training - Epoch   5, Step:   113500, Batch Loss:     2.564234, Tokens per Sec:     3609, Lr: 0.000200
2022-01-21 23:51:52,378 - INFO - joeynmt.training - Epoch   5, Step:   113600, Batch Loss:     4.633119, Tokens per Sec:     3615, Lr: 0.000200
2022-01-21 23:52:11,050 - INFO - joeynmt.training - Epoch   5, Step:   113700, Batch Loss:     7.256870, Tokens per Sec:     3594, Lr: 0.000200
2022-01-21 23:52:29,722 - INFO - joeynmt.training - Epoch   5, Step:   113800, Batch Loss:     2.517034, Tokens per Sec:     3604, Lr: 0.000200
2022-01-21 23:52:48,600 - INFO - joeynmt.training - Epoch   5, Step:   113900, Batch Loss:     6.818449, Tokens per Sec:     3586, Lr: 0.000200
2022-01-21 23:53:07,120 - INFO - joeynmt.training - Epoch   5, Step:   114000, Batch Loss:     3.036179, Tokens per Sec:     3664, Lr: 0.000200
2022-01-22 00:14:55,569 - INFO - joeynmt.training - Example #0
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 00:14:55,570 - INFO - joeynmt.training - Example #1
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 00:14:55,570 - INFO - joeynmt.training - Example #2
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 00:14:55,570 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 00:14:55,571 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   114000: bleu:  86.18, loss: 285902.0000, ppl:   1.1943, duration: 1308.4512s
2022-01-22 00:15:15,101 - INFO - joeynmt.training - Epoch   5, Step:   114100, Batch Loss:     4.005686, Tokens per Sec:     3491, Lr: 0.000200
2022-01-22 00:15:34,209 - INFO - joeynmt.training - Epoch   5, Step:   114200, Batch Loss:     2.843958, Tokens per Sec:     3531, Lr: 0.000200
2022-01-22 00:15:53,408 - INFO - joeynmt.training - Epoch   5, Step:   114300, Batch Loss:     3.312428, Tokens per Sec:     3512, Lr: 0.000200
2022-01-22 00:16:12,659 - INFO - joeynmt.training - Epoch   5, Step:   114400, Batch Loss:     2.990228, Tokens per Sec:     3480, Lr: 0.000200
2022-01-22 00:16:31,798 - INFO - joeynmt.training - Epoch   5, Step:   114500, Batch Loss:     2.333477, Tokens per Sec:     3574, Lr: 0.000200
2022-01-22 00:16:50,575 - INFO - joeynmt.training - Epoch   5, Step:   114600, Batch Loss:     3.805910, Tokens per Sec:     3480, Lr: 0.000200
2022-01-22 00:17:09,456 - INFO - joeynmt.training - Epoch   5, Step:   114700, Batch Loss:     4.639350, Tokens per Sec:     3568, Lr: 0.000200
2022-01-22 00:17:28,387 - INFO - joeynmt.training - Epoch   5, Step:   114800, Batch Loss:     3.659443, Tokens per Sec:     3607, Lr: 0.000200
2022-01-22 00:17:47,328 - INFO - joeynmt.training - Epoch   5, Step:   114900, Batch Loss:     5.165275, Tokens per Sec:     3617, Lr: 0.000200
2022-01-22 00:18:06,172 - INFO - joeynmt.training - Epoch   5, Step:   115000, Batch Loss:     2.649685, Tokens per Sec:     3489, Lr: 0.000200
2022-01-22 00:39:51,956 - INFO - joeynmt.training - Example #0
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 00:39:51,957 - INFO - joeynmt.training - Example #1
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 00:39:51,957 - INFO - joeynmt.training - Example #2
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 00:39:51,957 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 00:39:51,958 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   115000: bleu:  86.22, loss: 289054.6250, ppl:   1.1966, duration: 1305.7864s
2022-01-22 00:40:11,037 - INFO - joeynmt.training - Epoch   5, Step:   115100, Batch Loss:     2.345806, Tokens per Sec:     3496, Lr: 0.000200
2022-01-22 00:40:29,450 - INFO - joeynmt.training - Epoch   5, Step:   115200, Batch Loss:     3.908242, Tokens per Sec:     3608, Lr: 0.000200
2022-01-22 00:40:47,860 - INFO - joeynmt.training - Epoch   5, Step:   115300, Batch Loss:     2.656239, Tokens per Sec:     3621, Lr: 0.000200
2022-01-22 00:41:06,583 - INFO - joeynmt.training - Epoch   5, Step:   115400, Batch Loss:     3.060298, Tokens per Sec:     3568, Lr: 0.000200
2022-01-22 00:41:24,740 - INFO - joeynmt.training - Epoch   5, Step:   115500, Batch Loss:     3.030433, Tokens per Sec:     3562, Lr: 0.000200
2022-01-22 00:41:43,083 - INFO - joeynmt.training - Epoch   5, Step:   115600, Batch Loss:     2.216241, Tokens per Sec:     3583, Lr: 0.000200
2022-01-22 00:42:01,504 - INFO - joeynmt.training - Epoch   5, Step:   115700, Batch Loss:     4.154865, Tokens per Sec:     3704, Lr: 0.000200
2022-01-22 00:42:19,945 - INFO - joeynmt.training - Epoch   5, Step:   115800, Batch Loss:     5.279409, Tokens per Sec:     3593, Lr: 0.000200
2022-01-22 00:42:37,616 - INFO - joeynmt.training - Epoch   5, Step:   115900, Batch Loss:     1.953460, Tokens per Sec:     3814, Lr: 0.000200
2022-01-22 00:42:55,422 - INFO - joeynmt.training - Epoch   5, Step:   116000, Batch Loss:     2.825583, Tokens per Sec:     3851, Lr: 0.000200
2022-01-22 01:04:37,865 - INFO - joeynmt.training - Example #0
2022-01-22 01:04:37,866 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 01:04:37,866 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 01:04:37,867 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 01:04:37,867 - INFO - joeynmt.training - Example #1
2022-01-22 01:04:37,867 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 01:04:37,867 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 01:04:37,867 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 01:04:37,867 - INFO - joeynmt.training - Example #2
2022-01-22 01:04:37,867 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 01:04:37,867 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 01:04:37,867 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 01:04:37,868 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   116000: bleu:  86.05, loss: 291712.0938, ppl:   1.1986, duration: 1302.4458s
2022-01-22 01:04:57,014 - INFO - joeynmt.training - Epoch   5, Step:   116100, Batch Loss:     4.878543, Tokens per Sec:     3534, Lr: 0.000200
2022-01-22 01:05:15,451 - INFO - joeynmt.training - Epoch   5, Step:   116200, Batch Loss:     1.514447, Tokens per Sec:     3662, Lr: 0.000200
2022-01-22 01:05:33,924 - INFO - joeynmt.training - Epoch   5, Step:   116300, Batch Loss:     2.968893, Tokens per Sec:     3582, Lr: 0.000200
2022-01-22 01:05:52,481 - INFO - joeynmt.training - Epoch   5, Step:   116400, Batch Loss:     4.273434, Tokens per Sec:     3707, Lr: 0.000200
2022-01-22 01:06:10,705 - INFO - joeynmt.training - Epoch   5, Step:   116500, Batch Loss:     3.578382, Tokens per Sec:     3706, Lr: 0.000200
2022-01-22 01:06:29,360 - INFO - joeynmt.training - Epoch   5, Step:   116600, Batch Loss:     3.028705, Tokens per Sec:     3643, Lr: 0.000200
2022-01-22 01:06:47,767 - INFO - joeynmt.training - Epoch   5, Step:   116700, Batch Loss:     2.466448, Tokens per Sec:     3660, Lr: 0.000200
2022-01-22 01:07:06,078 - INFO - joeynmt.training - Epoch   5, Step:   116800, Batch Loss:     3.335415, Tokens per Sec:     3615, Lr: 0.000200
2022-01-22 01:07:24,545 - INFO - joeynmt.training - Epoch   5, Step:   116900, Batch Loss:     3.539580, Tokens per Sec:     3742, Lr: 0.000200
2022-01-22 01:07:42,732 - INFO - joeynmt.training - Epoch   5, Step:   117000, Batch Loss:     4.153203, Tokens per Sec:     3804, Lr: 0.000200
2022-01-22 01:29:24,339 - INFO - joeynmt.training - Example #0
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 01:29:24,340 - INFO - joeynmt.training - Example #1
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 01:29:24,340 - INFO - joeynmt.training - Example #2
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 01:29:24,340 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 01:29:24,342 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   117000: bleu:  86.16, loss: 286899.6562, ppl:   1.1950, duration: 1301.6096s
2022-01-22 01:29:43,592 - INFO - joeynmt.training - Epoch   5, Step:   117100, Batch Loss:    11.314075, Tokens per Sec:     3446, Lr: 0.000200
2022-01-22 01:30:02,020 - INFO - joeynmt.training - Epoch   5, Step:   117200, Batch Loss:     3.575693, Tokens per Sec:     3720, Lr: 0.000200
2022-01-22 01:30:20,265 - INFO - joeynmt.training - Epoch   5, Step:   117300, Batch Loss:     5.639441, Tokens per Sec:     3607, Lr: 0.000200
2022-01-22 01:30:38,675 - INFO - joeynmt.training - Epoch   5, Step:   117400, Batch Loss:     2.753287, Tokens per Sec:     3639, Lr: 0.000200
2022-01-22 01:30:57,163 - INFO - joeynmt.training - Epoch   5, Step:   117500, Batch Loss:     4.530049, Tokens per Sec:     3630, Lr: 0.000200
2022-01-22 01:31:15,788 - INFO - joeynmt.training - Epoch   5, Step:   117600, Batch Loss:     9.351027, Tokens per Sec:     3674, Lr: 0.000200
2022-01-22 01:31:34,212 - INFO - joeynmt.training - Epoch   5, Step:   117700, Batch Loss:     2.896482, Tokens per Sec:     3743, Lr: 0.000200
2022-01-22 01:31:52,639 - INFO - joeynmt.training - Epoch   5, Step:   117800, Batch Loss:     5.383592, Tokens per Sec:     3605, Lr: 0.000200
2022-01-22 01:32:10,900 - INFO - joeynmt.training - Epoch   5, Step:   117900, Batch Loss:     4.038041, Tokens per Sec:     3613, Lr: 0.000200
2022-01-22 01:32:29,111 - INFO - joeynmt.training - Epoch   5, Step:   118000, Batch Loss:     3.188911, Tokens per Sec:     3696, Lr: 0.000200
2022-01-22 01:54:16,250 - INFO - joeynmt.training - Example #0
2022-01-22 01:54:16,251 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 01:54:16,251 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 01:54:16,251 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 01:54:16,251 - INFO - joeynmt.training - Example #1
2022-01-22 01:54:16,251 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 01:54:16,252 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 01:54:16,252 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 01:54:16,252 - INFO - joeynmt.training - Example #2
2022-01-22 01:54:16,252 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 01:54:16,252 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 01:54:16,252 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 01:54:16,253 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   118000: bleu:  85.96, loss: 284504.7188, ppl:   1.1933, duration: 1307.1419s
2022-01-22 01:54:35,436 - INFO - joeynmt.training - Epoch   5, Step:   118100, Batch Loss:     2.901181, Tokens per Sec:     3452, Lr: 0.000200
2022-01-22 01:54:54,444 - INFO - joeynmt.training - Epoch   5, Step:   118200, Batch Loss:     2.243068, Tokens per Sec:     3597, Lr: 0.000200
2022-01-22 01:55:13,684 - INFO - joeynmt.training - Epoch   5, Step:   118300, Batch Loss:     3.440507, Tokens per Sec:     3433, Lr: 0.000200
2022-01-22 01:55:32,791 - INFO - joeynmt.training - Epoch   5, Step:   118400, Batch Loss:     5.093339, Tokens per Sec:     3547, Lr: 0.000200
2022-01-22 01:55:52,298 - INFO - joeynmt.training - Epoch   5, Step:   118500, Batch Loss:     3.637009, Tokens per Sec:     3633, Lr: 0.000200
2022-01-22 01:56:11,109 - INFO - joeynmt.training - Epoch   5, Step:   118600, Batch Loss:     2.435069, Tokens per Sec:     3550, Lr: 0.000200
2022-01-22 01:56:29,987 - INFO - joeynmt.training - Epoch   5, Step:   118700, Batch Loss:     4.666750, Tokens per Sec:     3568, Lr: 0.000200
2022-01-22 01:56:48,789 - INFO - joeynmt.training - Epoch   5, Step:   118800, Batch Loss:     3.210503, Tokens per Sec:     3569, Lr: 0.000200
2022-01-22 01:57:07,473 - INFO - joeynmt.training - Epoch   5, Step:   118900, Batch Loss:     4.594443, Tokens per Sec:     3500, Lr: 0.000200
2022-01-22 01:57:26,162 - INFO - joeynmt.training - Epoch   5, Step:   119000, Batch Loss:     3.180049, Tokens per Sec:     3717, Lr: 0.000200
2022-01-22 02:19:07,384 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 02:19:40,118 - INFO - joeynmt.helpers - delete models/a_model/113000.ckpt
2022-01-22 02:19:40,154 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/113000.ckpt
2022-01-22 02:19:40,155 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/113000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/113000.ckpt')
2022-01-22 02:19:40,339 - INFO - joeynmt.training - Example #0
2022-01-22 02:19:40,339 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 02:19:40,339 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 02:19:40,339 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 02:19:40,339 - INFO - joeynmt.training - Example #1
2022-01-22 02:19:40,339 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 02:19:40,339 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 02:19:40,339 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 02:19:40,340 - INFO - joeynmt.training - Example #2
2022-01-22 02:19:40,340 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 02:19:40,340 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 02:19:40,340 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 02:19:40,340 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   119000: bleu:  86.42, loss: 282291.5000, ppl:   1.1916, duration: 1334.1784s
2022-01-22 02:19:59,031 - INFO - joeynmt.training - Epoch   5, Step:   119100, Batch Loss:     3.480125, Tokens per Sec:     3705, Lr: 0.000200
2022-01-22 02:20:17,415 - INFO - joeynmt.training - Epoch   5, Step:   119200, Batch Loss:     2.722666, Tokens per Sec:     3667, Lr: 0.000200
2022-01-22 02:20:35,967 - INFO - joeynmt.training - Epoch   5, Step:   119300, Batch Loss:     1.464597, Tokens per Sec:     3632, Lr: 0.000200
2022-01-22 02:20:54,824 - INFO - joeynmt.training - Epoch   5, Step:   119400, Batch Loss:     7.621769, Tokens per Sec:     3569, Lr: 0.000200
2022-01-22 02:21:13,030 - INFO - joeynmt.training - Epoch   5, Step:   119500, Batch Loss:     3.086720, Tokens per Sec:     3758, Lr: 0.000200
2022-01-22 02:21:31,657 - INFO - joeynmt.training - Epoch   5, Step:   119600, Batch Loss:     2.323882, Tokens per Sec:     3637, Lr: 0.000200
2022-01-22 02:21:50,000 - INFO - joeynmt.training - Epoch   5, Step:   119700, Batch Loss:     3.821639, Tokens per Sec:     3689, Lr: 0.000200
2022-01-22 02:22:08,361 - INFO - joeynmt.training - Epoch   5, Step:   119800, Batch Loss:     3.671144, Tokens per Sec:     3747, Lr: 0.000200
2022-01-22 02:22:26,530 - INFO - joeynmt.training - Epoch   5, Step:   119900, Batch Loss:     3.043628, Tokens per Sec:     3723, Lr: 0.000200
2022-01-22 02:22:44,345 - INFO - joeynmt.training - Epoch   5, Step:   120000, Batch Loss:     3.519571, Tokens per Sec:     3818, Lr: 0.000200
2022-01-22 02:44:28,691 - INFO - joeynmt.training - Example #0
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 02:44:28,692 - INFO - joeynmt.training - Example #1
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 02:44:28,692 - INFO - joeynmt.training - Example #2
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 02:44:28,692 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 02:44:28,693 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   120000: bleu:  86.04, loss: 280256.4062, ppl:   1.1901, duration: 1304.3483s
2022-01-22 02:44:48,114 - INFO - joeynmt.training - Epoch   5, Step:   120100, Batch Loss:     5.073215, Tokens per Sec:     3412, Lr: 0.000200
2022-01-22 02:45:06,884 - INFO - joeynmt.training - Epoch   5, Step:   120200, Batch Loss:     4.869802, Tokens per Sec:     3645, Lr: 0.000200
2022-01-22 02:45:25,814 - INFO - joeynmt.training - Epoch   5, Step:   120300, Batch Loss:     3.731723, Tokens per Sec:     3476, Lr: 0.000200
2022-01-22 02:45:44,932 - INFO - joeynmt.training - Epoch   5, Step:   120400, Batch Loss:     3.535882, Tokens per Sec:     3327, Lr: 0.000200
2022-01-22 02:46:03,938 - INFO - joeynmt.training - Epoch   5, Step:   120500, Batch Loss:     4.077250, Tokens per Sec:     3563, Lr: 0.000200
2022-01-22 02:46:22,912 - INFO - joeynmt.training - Epoch   5, Step:   120600, Batch Loss:     3.562681, Tokens per Sec:     3510, Lr: 0.000200
2022-01-22 02:46:41,881 - INFO - joeynmt.training - Epoch   5, Step:   120700, Batch Loss:     2.133319, Tokens per Sec:     3531, Lr: 0.000200
2022-01-22 02:47:00,734 - INFO - joeynmt.training - Epoch   5, Step:   120800, Batch Loss:     3.289733, Tokens per Sec:     3511, Lr: 0.000200
2022-01-22 02:47:19,591 - INFO - joeynmt.training - Epoch   5, Step:   120900, Batch Loss:     1.916799, Tokens per Sec:     3547, Lr: 0.000200
2022-01-22 02:47:38,345 - INFO - joeynmt.training - Epoch   5, Step:   121000, Batch Loss:     3.508961, Tokens per Sec:     3593, Lr: 0.000200
2022-01-22 03:09:44,981 - INFO - joeynmt.training - Example #0
2022-01-22 03:09:44,982 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 03:09:44,982 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 03:09:44,982 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 03:09:44,982 - INFO - joeynmt.training - Example #1
2022-01-22 03:09:44,982 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 03:09:44,982 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 03:09:44,983 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 03:09:44,983 - INFO - joeynmt.training - Example #2
2022-01-22 03:09:44,983 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 03:09:44,983 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 03:09:44,983 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 03:09:44,983 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   121000: bleu:  85.99, loss: 300028.4375, ppl:   1.2048, duration: 1326.6376s
2022-01-22 03:10:03,986 - INFO - joeynmt.training - Epoch   5, Step:   121100, Batch Loss:     8.572515, Tokens per Sec:     3424, Lr: 0.000200
2022-01-22 03:10:22,284 - INFO - joeynmt.training - Epoch   5, Step:   121200, Batch Loss:     4.818458, Tokens per Sec:     3662, Lr: 0.000200
2022-01-22 03:10:41,209 - INFO - joeynmt.training - Epoch   5, Step:   121300, Batch Loss:     4.829557, Tokens per Sec:     3569, Lr: 0.000200
2022-01-22 03:10:59,771 - INFO - joeynmt.training - Epoch   5, Step:   121400, Batch Loss:     1.993706, Tokens per Sec:     3559, Lr: 0.000200
2022-01-22 03:11:18,249 - INFO - joeynmt.training - Epoch   5, Step:   121500, Batch Loss:     2.296204, Tokens per Sec:     3714, Lr: 0.000200
2022-01-22 03:11:36,748 - INFO - joeynmt.training - Epoch   5, Step:   121600, Batch Loss:     3.819879, Tokens per Sec:     3654, Lr: 0.000200
2022-01-22 03:11:55,184 - INFO - joeynmt.training - Epoch   5, Step:   121700, Batch Loss:     4.201388, Tokens per Sec:     3627, Lr: 0.000200
2022-01-22 03:12:13,831 - INFO - joeynmt.training - Epoch   5, Step:   121800, Batch Loss:     6.752092, Tokens per Sec:     3623, Lr: 0.000200
2022-01-22 03:12:32,739 - INFO - joeynmt.training - Epoch   5, Step:   121900, Batch Loss:     8.295013, Tokens per Sec:     3628, Lr: 0.000200
2022-01-22 03:12:51,588 - INFO - joeynmt.training - Epoch   5, Step:   122000, Batch Loss:     2.299144, Tokens per Sec:     3684, Lr: 0.000200
2022-01-22 03:34:36,952 - INFO - joeynmt.training - Example #0
2022-01-22 03:34:36,953 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 03:34:36,953 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 03:34:36,953 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 03:34:36,953 - INFO - joeynmt.training - Example #1
2022-01-22 03:34:36,953 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 03:34:36,953 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 03:34:36,953 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 03:34:36,953 - INFO - joeynmt.training - Example #2
2022-01-22 03:34:36,954 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 03:34:36,954 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 03:34:36,954 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 03:34:36,954 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   122000: bleu:  86.24, loss: 279975.8438, ppl:   1.1899, duration: 1305.3663s
2022-01-22 03:34:56,069 - INFO - joeynmt.training - Epoch   5, Step:   122100, Batch Loss:     2.664478, Tokens per Sec:     3565, Lr: 0.000200
2022-01-22 03:35:14,878 - INFO - joeynmt.training - Epoch   5, Step:   122200, Batch Loss:     3.757371, Tokens per Sec:     3705, Lr: 0.000200
2022-01-22 03:35:33,409 - INFO - joeynmt.training - Epoch   5, Step:   122300, Batch Loss:     7.243071, Tokens per Sec:     3611, Lr: 0.000200
2022-01-22 03:35:51,644 - INFO - joeynmt.training - Epoch   5, Step:   122400, Batch Loss:     2.786462, Tokens per Sec:     3768, Lr: 0.000200
2022-01-22 03:36:11,101 - INFO - joeynmt.training - Epoch   5, Step:   122500, Batch Loss:     5.351588, Tokens per Sec:     3469, Lr: 0.000200
2022-01-22 03:36:30,565 - INFO - joeynmt.training - Epoch   5, Step:   122600, Batch Loss:     3.125728, Tokens per Sec:     3470, Lr: 0.000200
2022-01-22 03:36:49,936 - INFO - joeynmt.training - Epoch   5, Step:   122700, Batch Loss:     3.571047, Tokens per Sec:     3604, Lr: 0.000200
2022-01-22 03:37:09,776 - INFO - joeynmt.training - Epoch   5, Step:   122800, Batch Loss:     2.754397, Tokens per Sec:     3460, Lr: 0.000200
2022-01-22 03:37:29,317 - INFO - joeynmt.training - Epoch   5, Step:   122900, Batch Loss:     2.327926, Tokens per Sec:     3530, Lr: 0.000200
2022-01-22 03:37:48,982 - INFO - joeynmt.training - Epoch   5, Step:   123000, Batch Loss:     2.946760, Tokens per Sec:     3400, Lr: 0.000200
2022-01-22 03:59:36,024 - INFO - joeynmt.training - Example #0
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 03:59:36,025 - INFO - joeynmt.training - Example #1
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 03:59:36,025 - INFO - joeynmt.training - Example #2
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 03:59:36,025 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 30 28 | 0 5 | 18 6
2022-01-22 03:59:36,026 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   123000: bleu:  86.32, loss: 279976.1562, ppl:   1.1899, duration: 1307.0435s
2022-01-22 03:59:55,384 - INFO - joeynmt.training - Epoch   5, Step:   123100, Batch Loss:     5.621511, Tokens per Sec:     3440, Lr: 0.000200
2022-01-22 04:00:14,514 - INFO - joeynmt.training - Epoch   5, Step:   123200, Batch Loss:     2.448847, Tokens per Sec:     3450, Lr: 0.000200
2022-01-22 04:00:33,677 - INFO - joeynmt.training - Epoch   5, Step:   123300, Batch Loss:     2.188622, Tokens per Sec:     3454, Lr: 0.000200
2022-01-22 04:00:52,866 - INFO - joeynmt.training - Epoch   5, Step:   123400, Batch Loss:     2.919596, Tokens per Sec:     3465, Lr: 0.000200
2022-01-22 04:01:11,792 - INFO - joeynmt.training - Epoch   5, Step:   123500, Batch Loss:     1.468368, Tokens per Sec:     3537, Lr: 0.000200
2022-01-22 04:01:31,070 - INFO - joeynmt.training - Epoch   5, Step:   123600, Batch Loss:     3.929833, Tokens per Sec:     3507, Lr: 0.000200
2022-01-22 04:01:50,675 - INFO - joeynmt.training - Epoch   5, Step:   123700, Batch Loss:     3.143876, Tokens per Sec:     3459, Lr: 0.000200
2022-01-22 04:02:10,323 - INFO - joeynmt.training - Epoch   5, Step:   123800, Batch Loss:     2.318274, Tokens per Sec:     3468, Lr: 0.000200
2022-01-22 04:02:30,005 - INFO - joeynmt.training - Epoch   5, Step:   123900, Batch Loss:     3.073893, Tokens per Sec:     3381, Lr: 0.000200
2022-01-22 04:02:49,754 - INFO - joeynmt.training - Epoch   5, Step:   124000, Batch Loss:     1.602046, Tokens per Sec:     3495, Lr: 0.000200
2022-01-22 04:24:29,983 - INFO - joeynmt.training - Example #0
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 04:24:29,984 - INFO - joeynmt.training - Example #1
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 04:24:29,984 - INFO - joeynmt.training - Example #2
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 04:24:29,984 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 04:24:29,985 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   124000: bleu:  86.30, loss: 280129.8125, ppl:   1.1900, duration: 1300.2311s
2022-01-22 04:24:49,295 - INFO - joeynmt.training - Epoch   5, Step:   124100, Batch Loss:     5.554170, Tokens per Sec:     3524, Lr: 0.000200
2022-01-22 04:25:08,394 - INFO - joeynmt.training - Epoch   5, Step:   124200, Batch Loss:     5.180119, Tokens per Sec:     3550, Lr: 0.000200
2022-01-22 04:25:27,359 - INFO - joeynmt.training - Epoch   5, Step:   124300, Batch Loss:     3.235143, Tokens per Sec:     3554, Lr: 0.000200
2022-01-22 04:25:46,485 - INFO - joeynmt.training - Epoch   5, Step:   124400, Batch Loss:     2.624497, Tokens per Sec:     3559, Lr: 0.000200
2022-01-22 04:26:05,452 - INFO - joeynmt.training - Epoch   5, Step:   124500, Batch Loss:     4.530743, Tokens per Sec:     3535, Lr: 0.000200
2022-01-22 04:26:24,787 - INFO - joeynmt.training - Epoch   5, Step:   124600, Batch Loss:     2.515762, Tokens per Sec:     3554, Lr: 0.000200
2022-01-22 04:26:44,017 - INFO - joeynmt.training - Epoch   5, Step:   124700, Batch Loss:     6.402351, Tokens per Sec:     3613, Lr: 0.000200
2022-01-22 04:27:02,920 - INFO - joeynmt.training - Epoch   5, Step:   124800, Batch Loss:     6.626045, Tokens per Sec:     3546, Lr: 0.000200
2022-01-22 04:27:21,769 - INFO - joeynmt.training - Epoch   5, Step:   124900, Batch Loss:     3.627504, Tokens per Sec:     3603, Lr: 0.000200
2022-01-22 04:27:40,486 - INFO - joeynmt.training - Epoch   5, Step:   125000, Batch Loss:     2.175992, Tokens per Sec:     3525, Lr: 0.000200
2022-01-22 04:49:24,435 - INFO - joeynmt.training - Example #0
2022-01-22 04:49:24,436 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 04:49:24,436 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 04:49:24,436 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 04:49:24,436 - INFO - joeynmt.training - Example #1
2022-01-22 04:49:24,436 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 04:49:24,436 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 04:49:24,436 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 04:49:24,437 - INFO - joeynmt.training - Example #2
2022-01-22 04:49:24,437 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 04:49:24,437 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 04:49:24,437 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 04:49:24,437 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   125000: bleu:  86.18, loss: 278286.0625, ppl:   1.1887, duration: 1303.9503s
2022-01-22 04:49:43,839 - INFO - joeynmt.training - Epoch   5, Step:   125100, Batch Loss:     2.925305, Tokens per Sec:     3418, Lr: 0.000200
2022-01-22 04:50:03,100 - INFO - joeynmt.training - Epoch   5, Step:   125200, Batch Loss:     4.842157, Tokens per Sec:     3543, Lr: 0.000200
2022-01-22 04:50:22,313 - INFO - joeynmt.training - Epoch   5, Step:   125300, Batch Loss:     1.756005, Tokens per Sec:     3566, Lr: 0.000200
2022-01-22 04:50:41,117 - INFO - joeynmt.training - Epoch   5, Step:   125400, Batch Loss:     1.696665, Tokens per Sec:     3590, Lr: 0.000200
2022-01-22 04:51:00,047 - INFO - joeynmt.training - Epoch   5, Step:   125500, Batch Loss:     9.833060, Tokens per Sec:     3586, Lr: 0.000200
2022-01-22 04:51:18,795 - INFO - joeynmt.training - Epoch   5, Step:   125600, Batch Loss:     4.513479, Tokens per Sec:     3625, Lr: 0.000200
2022-01-22 04:51:37,885 - INFO - joeynmt.training - Epoch   5, Step:   125700, Batch Loss:     2.782668, Tokens per Sec:     3692, Lr: 0.000200
2022-01-22 04:51:56,840 - INFO - joeynmt.training - Epoch   5, Step:   125800, Batch Loss:     2.971237, Tokens per Sec:     3377, Lr: 0.000200
2022-01-22 04:52:15,674 - INFO - joeynmt.training - Epoch   5, Step:   125900, Batch Loss:     3.804623, Tokens per Sec:     3646, Lr: 0.000200
2022-01-22 04:52:34,518 - INFO - joeynmt.training - Epoch   5, Step:   126000, Batch Loss:     1.453389, Tokens per Sec:     3476, Lr: 0.000200
2022-01-22 05:14:17,827 - INFO - joeynmt.training - Example #0
2022-01-22 05:14:17,828 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 05:14:17,828 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 05:14:17,828 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 05:14:17,828 - INFO - joeynmt.training - Example #1
2022-01-22 05:14:17,829 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 05:14:17,829 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 05:14:17,829 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 05:14:17,829 - INFO - joeynmt.training - Example #2
2022-01-22 05:14:17,829 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 05:14:17,829 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 05:14:17,829 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 05:14:17,830 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   126000: bleu:  86.41, loss: 276051.7188, ppl:   1.1870, duration: 1303.3117s
2022-01-22 05:14:36,739 - INFO - joeynmt.training - Epoch   5, Step:   126100, Batch Loss:     3.297524, Tokens per Sec:     3515, Lr: 0.000200
2022-01-22 05:14:55,122 - INFO - joeynmt.training - Epoch   5, Step:   126200, Batch Loss:     2.861269, Tokens per Sec:     3726, Lr: 0.000200
2022-01-22 05:15:13,534 - INFO - joeynmt.training - Epoch   5, Step:   126300, Batch Loss:     4.155905, Tokens per Sec:     3714, Lr: 0.000200
2022-01-22 05:15:31,967 - INFO - joeynmt.training - Epoch   5, Step:   126400, Batch Loss:     3.541454, Tokens per Sec:     3672, Lr: 0.000200
2022-01-22 05:15:50,580 - INFO - joeynmt.training - Epoch   5, Step:   126500, Batch Loss:     3.049253, Tokens per Sec:     3526, Lr: 0.000200
2022-01-22 05:16:09,067 - INFO - joeynmt.training - Epoch   5, Step:   126600, Batch Loss:     4.960978, Tokens per Sec:     3739, Lr: 0.000200
2022-01-22 05:16:26,945 - INFO - joeynmt.training - Epoch   5, Step:   126700, Batch Loss:     4.376692, Tokens per Sec:     3766, Lr: 0.000200
2022-01-22 05:16:44,839 - INFO - joeynmt.training - Epoch   5, Step:   126800, Batch Loss:     3.452132, Tokens per Sec:     3794, Lr: 0.000200
2022-01-22 05:17:02,768 - INFO - joeynmt.training - Epoch   5, Step:   126900, Batch Loss:     2.532010, Tokens per Sec:     3830, Lr: 0.000200
2022-01-22 05:17:20,834 - INFO - joeynmt.training - Epoch   5, Step:   127000, Batch Loss:     7.374846, Tokens per Sec:     3801, Lr: 0.000200
2022-01-22 05:39:03,292 - INFO - joeynmt.training - Example #0
2022-01-22 05:39:03,293 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 05:39:03,293 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 05:39:03,293 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 05:39:03,293 - INFO - joeynmt.training - Example #1
2022-01-22 05:39:03,294 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 05:39:03,294 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 05:39:03,294 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 05:39:03,294 - INFO - joeynmt.training - Example #2
2022-01-22 05:39:03,294 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 05:39:03,294 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 05:39:03,294 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 05:39:03,295 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   127000: bleu:  86.25, loss: 282026.6875, ppl:   1.1914, duration: 1302.4555s
2022-01-22 05:39:22,016 - INFO - joeynmt.training - Epoch   5, Step:   127100, Batch Loss:     2.378292, Tokens per Sec:     3691, Lr: 0.000200
2022-01-22 05:39:40,629 - INFO - joeynmt.training - Epoch   5, Step:   127200, Batch Loss:     2.558730, Tokens per Sec:     3708, Lr: 0.000200
2022-01-22 05:39:58,990 - INFO - joeynmt.training - Epoch   5, Step:   127300, Batch Loss:     4.368124, Tokens per Sec:     3686, Lr: 0.000200
2022-01-22 05:40:17,332 - INFO - joeynmt.training - Epoch   5, Step:   127400, Batch Loss:     2.770077, Tokens per Sec:     3718, Lr: 0.000200
2022-01-22 05:40:35,783 - INFO - joeynmt.training - Epoch   5, Step:   127500, Batch Loss:     2.361708, Tokens per Sec:     3615, Lr: 0.000200
2022-01-22 05:40:54,099 - INFO - joeynmt.training - Epoch   5, Step:   127600, Batch Loss:     4.387808, Tokens per Sec:     3637, Lr: 0.000200
2022-01-22 05:41:12,027 - INFO - joeynmt.training - Epoch   5, Step:   127700, Batch Loss:     1.757303, Tokens per Sec:     3883, Lr: 0.000200
2022-01-22 05:41:30,021 - INFO - joeynmt.training - Epoch   5, Step:   127800, Batch Loss:     2.243584, Tokens per Sec:     3697, Lr: 0.000200
2022-01-22 05:41:47,989 - INFO - joeynmt.training - Epoch   5, Step:   127900, Batch Loss:     3.965328, Tokens per Sec:     3765, Lr: 0.000200
2022-01-22 05:42:05,710 - INFO - joeynmt.training - Epoch   5, Step:   128000, Batch Loss:     3.007256, Tokens per Sec:     3883, Lr: 0.000200
2022-01-22 06:03:45,147 - INFO - joeynmt.training - Example #0
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 06:03:45,148 - INFO - joeynmt.training - Example #1
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 06:03:45,148 - INFO - joeynmt.training - Example #2
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 06:03:45,148 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 06:03:45,149 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   128000: bleu:  86.24, loss: 282777.9688, ppl:   1.1920, duration: 1299.4388s
2022-01-22 06:04:04,138 - INFO - joeynmt.training - Epoch   5, Step:   128100, Batch Loss:     1.742216, Tokens per Sec:     3605, Lr: 0.000200
2022-01-22 06:04:22,785 - INFO - joeynmt.training - Epoch   5, Step:   128200, Batch Loss:     3.044143, Tokens per Sec:     3578, Lr: 0.000200
2022-01-22 06:04:41,271 - INFO - joeynmt.training - Epoch   5, Step:   128300, Batch Loss:     2.480830, Tokens per Sec:     3699, Lr: 0.000200
2022-01-22 06:04:59,787 - INFO - joeynmt.training - Epoch   5, Step:   128400, Batch Loss:     3.153030, Tokens per Sec:     3774, Lr: 0.000200
2022-01-22 06:05:18,265 - INFO - joeynmt.training - Epoch   5, Step:   128500, Batch Loss:     6.792280, Tokens per Sec:     3673, Lr: 0.000200
2022-01-22 06:05:36,653 - INFO - joeynmt.training - Epoch   5, Step:   128600, Batch Loss:     3.099403, Tokens per Sec:     3754, Lr: 0.000200
2022-01-22 06:05:55,249 - INFO - joeynmt.training - Epoch   5, Step:   128700, Batch Loss:     1.882556, Tokens per Sec:     3693, Lr: 0.000200
2022-01-22 06:06:13,704 - INFO - joeynmt.training - Epoch   5, Step:   128800, Batch Loss:     7.038148, Tokens per Sec:     3792, Lr: 0.000200
2022-01-22 06:06:31,953 - INFO - joeynmt.training - Epoch   5, Step:   128900, Batch Loss:     3.128802, Tokens per Sec:     3785, Lr: 0.000200
2022-01-22 06:06:50,823 - INFO - joeynmt.training - Epoch   5, Step:   129000, Batch Loss:     6.000335, Tokens per Sec:     3533, Lr: 0.000200
2022-01-22 06:28:36,882 - INFO - joeynmt.training - Example #0
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 06:28:36,883 - INFO - joeynmt.training - Example #1
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 06:28:36,883 - INFO - joeynmt.training - Example #2
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 06:28:36,883 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 06:28:36,884 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   129000: bleu:  86.13, loss: 276469.7812, ppl:   1.1873, duration: 1306.0612s
2022-01-22 06:28:56,679 - INFO - joeynmt.training - Epoch   5, Step:   129100, Batch Loss:     6.180684, Tokens per Sec:     3516, Lr: 0.000200
2022-01-22 06:29:15,897 - INFO - joeynmt.training - Epoch   5, Step:   129200, Batch Loss:     3.255694, Tokens per Sec:     3628, Lr: 0.000200
2022-01-22 06:29:34,941 - INFO - joeynmt.training - Epoch   5, Step:   129300, Batch Loss:     3.753360, Tokens per Sec:     3499, Lr: 0.000200
2022-01-22 06:29:54,060 - INFO - joeynmt.training - Epoch   5, Step:   129400, Batch Loss:     2.386509, Tokens per Sec:     3607, Lr: 0.000200
2022-01-22 06:30:13,633 - INFO - joeynmt.training - Epoch   5, Step:   129500, Batch Loss:     3.030384, Tokens per Sec:     3498, Lr: 0.000200
2022-01-22 06:30:33,482 - INFO - joeynmt.training - Epoch   5, Step:   129600, Batch Loss:     6.364607, Tokens per Sec:     3479, Lr: 0.000200
2022-01-22 06:30:52,930 - INFO - joeynmt.training - Epoch   5, Step:   129700, Batch Loss:     1.604470, Tokens per Sec:     3497, Lr: 0.000200
2022-01-22 06:31:12,661 - INFO - joeynmt.training - Epoch   5, Step:   129800, Batch Loss:     2.721456, Tokens per Sec:     3554, Lr: 0.000200
2022-01-22 06:31:32,328 - INFO - joeynmt.training - Epoch   5, Step:   129900, Batch Loss:     3.493792, Tokens per Sec:     3427, Lr: 0.000200
2022-01-22 06:31:51,774 - INFO - joeynmt.training - Epoch   5, Step:   130000, Batch Loss:     5.900301, Tokens per Sec:     3368, Lr: 0.000200
2022-01-22 06:53:34,198 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 06:54:06,911 - INFO - joeynmt.helpers - delete models/a_model/119000.ckpt
2022-01-22 06:54:06,950 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/119000.ckpt
2022-01-22 06:54:06,951 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/119000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/119000.ckpt')
2022-01-22 06:54:06,997 - INFO - joeynmt.training - Example #0
2022-01-22 06:54:06,997 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 06:54:06,998 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 06:54:06,998 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 06:54:06,998 - INFO - joeynmt.training - Example #1
2022-01-22 06:54:06,998 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 06:54:06,998 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 06:54:06,998 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 06:54:06,998 - INFO - joeynmt.training - Example #2
2022-01-22 06:54:06,998 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 06:54:06,998 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 06:54:06,998 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 06:54:06,999 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   130000: bleu:  86.49, loss: 278472.0938, ppl:   1.1888, duration: 1335.2245s
2022-01-22 06:54:25,043 - INFO - joeynmt.training - Epoch   5, Step:   130100, Batch Loss:     2.893240, Tokens per Sec:     3680, Lr: 0.000200
2022-01-22 06:54:42,941 - INFO - joeynmt.training - Epoch   5, Step:   130200, Batch Loss:     2.275833, Tokens per Sec:     3749, Lr: 0.000200
2022-01-22 06:55:01,465 - INFO - joeynmt.training - Epoch   5, Step:   130300, Batch Loss:     7.733851, Tokens per Sec:     3539, Lr: 0.000200
2022-01-22 06:55:20,275 - INFO - joeynmt.training - Epoch   5, Step:   130400, Batch Loss:     4.551106, Tokens per Sec:     3543, Lr: 0.000200
2022-01-22 06:55:39,224 - INFO - joeynmt.training - Epoch   5, Step:   130500, Batch Loss:     4.685892, Tokens per Sec:     3507, Lr: 0.000200
2022-01-22 06:55:57,777 - INFO - joeynmt.training - Epoch   5, Step:   130600, Batch Loss:     2.839077, Tokens per Sec:     3611, Lr: 0.000200
2022-01-22 06:56:16,213 - INFO - joeynmt.training - Epoch   5, Step:   130700, Batch Loss:     2.585213, Tokens per Sec:     3766, Lr: 0.000200
2022-01-22 06:56:34,812 - INFO - joeynmt.training - Epoch   5, Step:   130800, Batch Loss:     3.596653, Tokens per Sec:     3591, Lr: 0.000200
2022-01-22 06:56:53,546 - INFO - joeynmt.training - Epoch   5, Step:   130900, Batch Loss:     9.573450, Tokens per Sec:     3683, Lr: 0.000200
2022-01-22 06:57:12,073 - INFO - joeynmt.training - Epoch   5, Step:   131000, Batch Loss:     3.041746, Tokens per Sec:     3629, Lr: 0.000200
2022-01-22 07:18:59,739 - INFO - joeynmt.training - Example #0
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 07:18:59,740 - INFO - joeynmt.training - Example #1
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 07:18:59,740 - INFO - joeynmt.training - Example #2
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 07:18:59,740 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 07:18:59,741 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   131000: bleu:  86.26, loss: 281560.6562, ppl:   1.1911, duration: 1307.6679s
2022-01-22 07:19:18,776 - INFO - joeynmt.training - Epoch   5, Step:   131100, Batch Loss:     2.828441, Tokens per Sec:     3651, Lr: 0.000200
2022-01-22 07:19:37,299 - INFO - joeynmt.training - Epoch   5, Step:   131200, Batch Loss:     2.828102, Tokens per Sec:     3688, Lr: 0.000200
2022-01-22 07:19:55,816 - INFO - joeynmt.training - Epoch   5, Step:   131300, Batch Loss:     5.609536, Tokens per Sec:     3664, Lr: 0.000200
2022-01-22 07:20:13,988 - INFO - joeynmt.training - Epoch   5, Step:   131400, Batch Loss:     4.658095, Tokens per Sec:     3715, Lr: 0.000200
2022-01-22 07:20:32,376 - INFO - joeynmt.training - Epoch   5, Step:   131500, Batch Loss:     3.726996, Tokens per Sec:     3713, Lr: 0.000200
2022-01-22 07:20:51,084 - INFO - joeynmt.training - Epoch   5, Step:   131600, Batch Loss:     3.274579, Tokens per Sec:     3602, Lr: 0.000200
2022-01-22 07:21:09,578 - INFO - joeynmt.training - Epoch   5, Step:   131700, Batch Loss:     3.983514, Tokens per Sec:     3708, Lr: 0.000200
2022-01-22 07:21:28,016 - INFO - joeynmt.training - Epoch   5, Step:   131800, Batch Loss:     2.687492, Tokens per Sec:     3724, Lr: 0.000200
2022-01-22 07:21:46,663 - INFO - joeynmt.training - Epoch   5, Step:   131900, Batch Loss:     5.722458, Tokens per Sec:     3573, Lr: 0.000200
2022-01-22 07:22:05,256 - INFO - joeynmt.training - Epoch   5, Step:   132000, Batch Loss:     4.964972, Tokens per Sec:     3662, Lr: 0.000200
2022-01-22 07:43:46,555 - INFO - joeynmt.training - Example #0
2022-01-22 07:43:46,556 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 07:43:46,556 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 07:43:46,556 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 07:43:46,556 - INFO - joeynmt.training - Example #1
2022-01-22 07:43:46,557 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 07:43:46,557 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 07:43:46,557 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 07:43:46,557 - INFO - joeynmt.training - Example #2
2022-01-22 07:43:46,557 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 07:43:46,557 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 07:43:46,557 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 07:43:46,558 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step   132000: bleu:  86.25, loss: 281263.7500, ppl:   1.1909, duration: 1301.3022s
2022-01-22 07:44:05,741 - INFO - joeynmt.training - Epoch   5, Step:   132100, Batch Loss:     4.567807, Tokens per Sec:     3524, Lr: 0.000200
2022-01-22 07:44:24,536 - INFO - joeynmt.training - Epoch   5, Step:   132200, Batch Loss:     3.140051, Tokens per Sec:     3575, Lr: 0.000200
2022-01-22 07:44:43,474 - INFO - joeynmt.training - Epoch   5, Step:   132300, Batch Loss:     4.807608, Tokens per Sec:     3562, Lr: 0.000200
2022-01-22 07:45:02,426 - INFO - joeynmt.training - Epoch   5, Step:   132400, Batch Loss:     1.858075, Tokens per Sec:     3592, Lr: 0.000200
2022-01-22 07:45:21,140 - INFO - joeynmt.training - Epoch   5, Step:   132500, Batch Loss:     9.727892, Tokens per Sec:     3465, Lr: 0.000200
2022-01-22 07:45:39,955 - INFO - joeynmt.training - Epoch   5, Step:   132600, Batch Loss:     2.476515, Tokens per Sec:     3517, Lr: 0.000200
2022-01-22 07:45:58,254 - INFO - joeynmt.training - Epoch   5, Step:   132700, Batch Loss:     3.029439, Tokens per Sec:     3623, Lr: 0.000200
2022-01-22 07:46:16,870 - INFO - joeynmt.training - Epoch   5, Step:   132800, Batch Loss:     5.844678, Tokens per Sec:     3610, Lr: 0.000200
2022-01-22 07:46:17,347 - INFO - joeynmt.training - Epoch   5: total training loss 104463.05
2022-01-22 07:46:17,347 - INFO - joeynmt.training - EPOCH 6
2022-01-22 07:46:36,028 - INFO - joeynmt.training - Epoch   6, Step:   132900, Batch Loss:     4.340718, Tokens per Sec:     3479, Lr: 0.000200
2022-01-22 07:46:54,837 - INFO - joeynmt.training - Epoch   6, Step:   133000, Batch Loss:     3.355540, Tokens per Sec:     3560, Lr: 0.000200
2022-01-22 08:08:35,439 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 08:09:08,351 - INFO - joeynmt.helpers - delete models/a_model/130000.ckpt
2022-01-22 08:09:08,448 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/130000.ckpt
2022-01-22 08:09:08,449 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/130000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/130000.ckpt')
2022-01-22 08:09:08,614 - INFO - joeynmt.training - Example #0
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-22 08:09:08,615 - INFO - joeynmt.training - Example #1
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 08:09:08,615 - INFO - joeynmt.training - Example #2
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 08:09:08,615 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 08:09:08,616 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   133000: bleu:  86.52, loss: 279827.6875, ppl:   1.1898, duration: 1333.7788s
2022-01-22 08:09:27,712 - INFO - joeynmt.training - Epoch   6, Step:   133100, Batch Loss:     3.619118, Tokens per Sec:     3628, Lr: 0.000200
2022-01-22 08:09:47,321 - INFO - joeynmt.training - Epoch   6, Step:   133200, Batch Loss:     4.864432, Tokens per Sec:     3557, Lr: 0.000200
2022-01-22 08:10:06,983 - INFO - joeynmt.training - Epoch   6, Step:   133300, Batch Loss:     1.089791, Tokens per Sec:     3387, Lr: 0.000200
2022-01-22 08:10:26,680 - INFO - joeynmt.training - Epoch   6, Step:   133400, Batch Loss:     3.772820, Tokens per Sec:     3295, Lr: 0.000200
2022-01-22 08:10:46,506 - INFO - joeynmt.training - Epoch   6, Step:   133500, Batch Loss:     2.817539, Tokens per Sec:     3440, Lr: 0.000200
2022-01-22 08:11:06,157 - INFO - joeynmt.training - Epoch   6, Step:   133600, Batch Loss:     5.922377, Tokens per Sec:     3400, Lr: 0.000200
2022-01-22 08:11:25,610 - INFO - joeynmt.training - Epoch   6, Step:   133700, Batch Loss:     5.709399, Tokens per Sec:     3525, Lr: 0.000200
2022-01-22 08:11:45,079 - INFO - joeynmt.training - Epoch   6, Step:   133800, Batch Loss:     2.024415, Tokens per Sec:     3385, Lr: 0.000200
2022-01-22 08:12:04,657 - INFO - joeynmt.training - Epoch   6, Step:   133900, Batch Loss:     4.138201, Tokens per Sec:     3443, Lr: 0.000200
2022-01-22 08:12:24,408 - INFO - joeynmt.training - Epoch   6, Step:   134000, Batch Loss:     4.453702, Tokens per Sec:     3465, Lr: 0.000200
2022-01-22 08:34:16,056 - INFO - joeynmt.training - Example #0
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 08:34:16,058 - INFO - joeynmt.training - Example #1
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 08:34:16,058 - INFO - joeynmt.training - Example #2
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 08:34:16,058 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 08:34:16,059 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   134000: bleu:  86.16, loss: 277116.1875, ppl:   1.1878, duration: 1311.6508s
2022-01-22 08:34:35,056 - INFO - joeynmt.training - Epoch   6, Step:   134100, Batch Loss:     2.513082, Tokens per Sec:     3526, Lr: 0.000200
2022-01-22 08:34:53,349 - INFO - joeynmt.training - Epoch   6, Step:   134200, Batch Loss:     2.794953, Tokens per Sec:     3689, Lr: 0.000200
2022-01-22 08:35:11,848 - INFO - joeynmt.training - Epoch   6, Step:   134300, Batch Loss:     2.924395, Tokens per Sec:     3786, Lr: 0.000200
2022-01-22 08:35:30,489 - INFO - joeynmt.training - Epoch   6, Step:   134400, Batch Loss:     3.630960, Tokens per Sec:     3701, Lr: 0.000200
2022-01-22 08:35:49,020 - INFO - joeynmt.training - Epoch   6, Step:   134500, Batch Loss:     2.911885, Tokens per Sec:     3728, Lr: 0.000200
2022-01-22 08:36:07,608 - INFO - joeynmt.training - Epoch   6, Step:   134600, Batch Loss:     2.761189, Tokens per Sec:     3679, Lr: 0.000200
2022-01-22 08:36:26,119 - INFO - joeynmt.training - Epoch   6, Step:   134700, Batch Loss:     6.436531, Tokens per Sec:     3716, Lr: 0.000200
2022-01-22 08:36:44,669 - INFO - joeynmt.training - Epoch   6, Step:   134800, Batch Loss:     4.257316, Tokens per Sec:     3721, Lr: 0.000200
2022-01-22 08:37:02,818 - INFO - joeynmt.training - Epoch   6, Step:   134900, Batch Loss:     4.735238, Tokens per Sec:     3807, Lr: 0.000200
2022-01-22 08:37:20,893 - INFO - joeynmt.training - Epoch   6, Step:   135000, Batch Loss:     2.333538, Tokens per Sec:     3859, Lr: 0.000200
2022-01-22 08:59:04,181 - INFO - joeynmt.training - Example #0
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 08:59:04,182 - INFO - joeynmt.training - Example #1
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 08:59:04,182 - INFO - joeynmt.training - Example #2
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 08:59:04,182 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 08:59:04,183 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   135000: bleu:  86.28, loss: 280977.1875, ppl:   1.1907, duration: 1303.2899s
2022-01-22 08:59:23,509 - INFO - joeynmt.training - Epoch   6, Step:   135100, Batch Loss:     2.744808, Tokens per Sec:     3609, Lr: 0.000200
2022-01-22 08:59:42,269 - INFO - joeynmt.training - Epoch   6, Step:   135200, Batch Loss:     3.045710, Tokens per Sec:     3600, Lr: 0.000200
2022-01-22 09:00:00,856 - INFO - joeynmt.training - Epoch   6, Step:   135300, Batch Loss:     3.263049, Tokens per Sec:     3592, Lr: 0.000200
2022-01-22 09:00:19,752 - INFO - joeynmt.training - Epoch   6, Step:   135400, Batch Loss:     2.645788, Tokens per Sec:     3710, Lr: 0.000200
2022-01-22 09:00:38,523 - INFO - joeynmt.training - Epoch   6, Step:   135500, Batch Loss:     2.864003, Tokens per Sec:     3430, Lr: 0.000200
2022-01-22 09:00:56,983 - INFO - joeynmt.training - Epoch   6, Step:   135600, Batch Loss:     2.620120, Tokens per Sec:     3608, Lr: 0.000200
2022-01-22 09:01:15,438 - INFO - joeynmt.training - Epoch   6, Step:   135700, Batch Loss:     2.727935, Tokens per Sec:     3580, Lr: 0.000200
2022-01-22 09:01:34,287 - INFO - joeynmt.training - Epoch   6, Step:   135800, Batch Loss:     5.574320, Tokens per Sec:     3618, Lr: 0.000200
2022-01-22 09:01:53,109 - INFO - joeynmt.training - Epoch   6, Step:   135900, Batch Loss:     3.904449, Tokens per Sec:     3640, Lr: 0.000200
2022-01-22 09:02:12,107 - INFO - joeynmt.training - Epoch   6, Step:   136000, Batch Loss:     3.574595, Tokens per Sec:     3637, Lr: 0.000200
2022-01-22 09:24:09,057 - INFO - joeynmt.training - Example #0
2022-01-22 09:24:09,058 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 09:24:09,058 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 09:24:09,058 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 09:24:09,058 - INFO - joeynmt.training - Example #1
2022-01-22 09:24:09,058 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 09:24:09,058 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 09:24:09,058 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 09:24:09,058 - INFO - joeynmt.training - Example #2
2022-01-22 09:24:09,059 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 09:24:09,059 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 09:24:09,059 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 09:24:09,059 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   136000: bleu:  86.29, loss: 281981.5938, ppl:   1.1914, duration: 1316.9524s
2022-01-22 09:24:27,769 - INFO - joeynmt.training - Epoch   6, Step:   136100, Batch Loss:     4.673042, Tokens per Sec:     3662, Lr: 0.000200
2022-01-22 09:24:46,257 - INFO - joeynmt.training - Epoch   6, Step:   136200, Batch Loss:     4.514370, Tokens per Sec:     3522, Lr: 0.000200
2022-01-22 09:25:04,673 - INFO - joeynmt.training - Epoch   6, Step:   136300, Batch Loss:     3.149804, Tokens per Sec:     3637, Lr: 0.000200
2022-01-22 09:25:23,488 - INFO - joeynmt.training - Epoch   6, Step:   136400, Batch Loss:     6.676119, Tokens per Sec:     3697, Lr: 0.000200
2022-01-22 09:25:41,786 - INFO - joeynmt.training - Epoch   6, Step:   136500, Batch Loss:     4.693069, Tokens per Sec:     3768, Lr: 0.000200
2022-01-22 09:26:00,098 - INFO - joeynmt.training - Epoch   6, Step:   136600, Batch Loss:     2.098801, Tokens per Sec:     3570, Lr: 0.000200
2022-01-22 09:26:18,449 - INFO - joeynmt.training - Epoch   6, Step:   136700, Batch Loss:     3.095810, Tokens per Sec:     3541, Lr: 0.000200
2022-01-22 09:26:36,891 - INFO - joeynmt.training - Epoch   6, Step:   136800, Batch Loss:     3.210171, Tokens per Sec:     3631, Lr: 0.000200
2022-01-22 09:26:55,134 - INFO - joeynmt.training - Epoch   6, Step:   136900, Batch Loss:     3.834275, Tokens per Sec:     3737, Lr: 0.000200
2022-01-22 09:27:13,495 - INFO - joeynmt.training - Epoch   6, Step:   137000, Batch Loss:     3.550720, Tokens per Sec:     3701, Lr: 0.000200
2022-01-22 09:49:02,102 - INFO - joeynmt.training - Example #0
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 09:49:02,103 - INFO - joeynmt.training - Example #1
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 09:49:02,103 - INFO - joeynmt.training - Example #2
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 09:49:02,103 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 09:49:02,105 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   137000: bleu:  86.32, loss: 275030.1250, ppl:   1.1863, duration: 1308.6097s
2022-01-22 09:49:21,470 - INFO - joeynmt.training - Epoch   6, Step:   137100, Batch Loss:     4.067146, Tokens per Sec:     3476, Lr: 0.000200
2022-01-22 09:49:40,427 - INFO - joeynmt.training - Epoch   6, Step:   137200, Batch Loss:     5.304521, Tokens per Sec:     3587, Lr: 0.000200
2022-01-22 09:50:00,068 - INFO - joeynmt.training - Epoch   6, Step:   137300, Batch Loss:     3.898869, Tokens per Sec:     3413, Lr: 0.000200
2022-01-22 09:50:19,599 - INFO - joeynmt.training - Epoch   6, Step:   137400, Batch Loss:     2.901436, Tokens per Sec:     3327, Lr: 0.000200
2022-01-22 09:50:38,865 - INFO - joeynmt.training - Epoch   6, Step:   137500, Batch Loss:     4.465042, Tokens per Sec:     3425, Lr: 0.000200
2022-01-22 09:50:58,517 - INFO - joeynmt.training - Epoch   6, Step:   137600, Batch Loss:     1.688637, Tokens per Sec:     3350, Lr: 0.000200
2022-01-22 09:51:17,762 - INFO - joeynmt.training - Epoch   6, Step:   137700, Batch Loss:     3.249430, Tokens per Sec:     3434, Lr: 0.000200
2022-01-22 09:51:37,252 - INFO - joeynmt.training - Epoch   6, Step:   137800, Batch Loss:     5.435368, Tokens per Sec:     3597, Lr: 0.000200
2022-01-22 09:51:56,694 - INFO - joeynmt.training - Epoch   6, Step:   137900, Batch Loss:     9.813031, Tokens per Sec:     3488, Lr: 0.000200
2022-01-22 09:52:16,172 - INFO - joeynmt.training - Epoch   6, Step:   138000, Batch Loss:     6.041479, Tokens per Sec:     3423, Lr: 0.000200
2022-01-22 10:13:58,797 - INFO - joeynmt.training - Example #0
2022-01-22 10:13:58,798 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 10:13:58,798 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 10:13:58,798 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-22 10:13:58,798 - INFO - joeynmt.training - Example #1
2022-01-22 10:13:58,798 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 10:13:58,798 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 10:13:58,798 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 10:13:58,799 - INFO - joeynmt.training - Example #2
2022-01-22 10:13:58,799 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 10:13:58,799 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 10:13:58,799 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 10:13:58,800 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   138000: bleu:  86.26, loss: 277474.5625, ppl:   1.1881, duration: 1302.6274s
2022-01-22 10:14:18,203 - INFO - joeynmt.training - Epoch   6, Step:   138100, Batch Loss:     4.765666, Tokens per Sec:     3432, Lr: 0.000200
2022-01-22 10:14:37,159 - INFO - joeynmt.training - Epoch   6, Step:   138200, Batch Loss:     4.890571, Tokens per Sec:     3480, Lr: 0.000200
2022-01-22 10:14:56,163 - INFO - joeynmt.training - Epoch   6, Step:   138300, Batch Loss:     6.272136, Tokens per Sec:     3508, Lr: 0.000200
2022-01-22 10:15:15,220 - INFO - joeynmt.training - Epoch   6, Step:   138400, Batch Loss:     4.245710, Tokens per Sec:     3513, Lr: 0.000200
2022-01-22 10:15:34,244 - INFO - joeynmt.training - Epoch   6, Step:   138500, Batch Loss:     3.195469, Tokens per Sec:     3479, Lr: 0.000200
2022-01-22 10:15:53,422 - INFO - joeynmt.training - Epoch   6, Step:   138600, Batch Loss:     6.519328, Tokens per Sec:     3529, Lr: 0.000200
2022-01-22 10:16:12,550 - INFO - joeynmt.training - Epoch   6, Step:   138700, Batch Loss:     3.647205, Tokens per Sec:     3655, Lr: 0.000200
2022-01-22 10:16:31,559 - INFO - joeynmt.training - Epoch   6, Step:   138800, Batch Loss:     2.666247, Tokens per Sec:     3546, Lr: 0.000200
2022-01-22 10:16:50,587 - INFO - joeynmt.training - Epoch   6, Step:   138900, Batch Loss:     4.596656, Tokens per Sec:     3549, Lr: 0.000200
2022-01-22 10:17:09,532 - INFO - joeynmt.training - Epoch   6, Step:   139000, Batch Loss:     5.435477, Tokens per Sec:     3594, Lr: 0.000200
2022-01-22 10:38:51,934 - INFO - joeynmt.training - Example #0
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 10:38:51,935 - INFO - joeynmt.training - Example #1
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 10:38:51,935 - INFO - joeynmt.training - Example #2
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 10:38:51,935 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 10:38:51,936 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   139000: bleu:  86.49, loss: 278965.1875, ppl:   1.1892, duration: 1302.4036s
2022-01-22 10:39:11,455 - INFO - joeynmt.training - Epoch   6, Step:   139100, Batch Loss:     2.834187, Tokens per Sec:     3496, Lr: 0.000200
2022-01-22 10:39:30,400 - INFO - joeynmt.training - Epoch   6, Step:   139200, Batch Loss:     5.690699, Tokens per Sec:     3496, Lr: 0.000200
2022-01-22 10:39:49,257 - INFO - joeynmt.training - Epoch   6, Step:   139300, Batch Loss:     3.653446, Tokens per Sec:     3537, Lr: 0.000200
2022-01-22 10:40:08,405 - INFO - joeynmt.training - Epoch   6, Step:   139400, Batch Loss:     2.857099, Tokens per Sec:     3552, Lr: 0.000200
2022-01-22 10:40:27,606 - INFO - joeynmt.training - Epoch   6, Step:   139500, Batch Loss:     5.367533, Tokens per Sec:     3546, Lr: 0.000200
2022-01-22 10:40:46,378 - INFO - joeynmt.training - Epoch   6, Step:   139600, Batch Loss:     2.662950, Tokens per Sec:     3580, Lr: 0.000200
2022-01-22 10:41:05,264 - INFO - joeynmt.training - Epoch   6, Step:   139700, Batch Loss:     2.075333, Tokens per Sec:     3659, Lr: 0.000200
2022-01-22 10:41:24,460 - INFO - joeynmt.training - Epoch   6, Step:   139800, Batch Loss:     2.182438, Tokens per Sec:     3484, Lr: 0.000200
2022-01-22 10:41:43,302 - INFO - joeynmt.training - Epoch   6, Step:   139900, Batch Loss:     1.753344, Tokens per Sec:     3617, Lr: 0.000200
2022-01-22 10:42:02,349 - INFO - joeynmt.training - Epoch   6, Step:   140000, Batch Loss:     3.360799, Tokens per Sec:     3508, Lr: 0.000200
2022-01-22 11:03:43,078 - INFO - joeynmt.training - Example #0
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 11:03:43,079 - INFO - joeynmt.training - Example #1
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 11:03:43,079 - INFO - joeynmt.training - Example #2
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 11:03:43,079 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 11:03:43,080 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   140000: bleu:  86.38, loss: 278292.6562, ppl:   1.1887, duration: 1300.7306s
2022-01-22 11:04:02,097 - INFO - joeynmt.training - Epoch   6, Step:   140100, Batch Loss:     2.590718, Tokens per Sec:     3683, Lr: 0.000200
2022-01-22 11:04:20,546 - INFO - joeynmt.training - Epoch   6, Step:   140200, Batch Loss:     5.271914, Tokens per Sec:     3558, Lr: 0.000200
2022-01-22 11:04:39,045 - INFO - joeynmt.training - Epoch   6, Step:   140300, Batch Loss:     2.952941, Tokens per Sec:     3676, Lr: 0.000200
2022-01-22 11:04:57,485 - INFO - joeynmt.training - Epoch   6, Step:   140400, Batch Loss:     5.617380, Tokens per Sec:     3619, Lr: 0.000200
2022-01-22 11:05:15,867 - INFO - joeynmt.training - Epoch   6, Step:   140500, Batch Loss:     1.294997, Tokens per Sec:     3723, Lr: 0.000200
2022-01-22 11:05:34,226 - INFO - joeynmt.training - Epoch   6, Step:   140600, Batch Loss:     3.584212, Tokens per Sec:     3590, Lr: 0.000200
2022-01-22 11:05:52,751 - INFO - joeynmt.training - Epoch   6, Step:   140700, Batch Loss:     2.644663, Tokens per Sec:     3546, Lr: 0.000200
2022-01-22 11:06:11,012 - INFO - joeynmt.training - Epoch   6, Step:   140800, Batch Loss:     2.949780, Tokens per Sec:     3782, Lr: 0.000200
2022-01-22 11:06:29,681 - INFO - joeynmt.training - Epoch   6, Step:   140900, Batch Loss:     2.482787, Tokens per Sec:     3594, Lr: 0.000200
2022-01-22 11:06:48,113 - INFO - joeynmt.training - Epoch   6, Step:   141000, Batch Loss:     1.917061, Tokens per Sec:     3681, Lr: 0.000200
2022-01-22 11:28:30,978 - INFO - joeynmt.training - Example #0
2022-01-22 11:28:30,979 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 11:28:30,980 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 11:28:30,980 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 11:28:30,980 - INFO - joeynmt.training - Example #1
2022-01-22 11:28:30,980 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 11:28:30,980 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 11:28:30,980 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 11:28:30,980 - INFO - joeynmt.training - Example #2
2022-01-22 11:28:30,980 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 11:28:30,980 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 11:28:30,980 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 11:28:30,981 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   141000: bleu:  86.45, loss: 277244.0938, ppl:   1.1879, duration: 1302.8673s
2022-01-22 11:28:50,345 - INFO - joeynmt.training - Epoch   6, Step:   141100, Batch Loss:     1.927300, Tokens per Sec:     3494, Lr: 0.000200
2022-01-22 11:29:09,364 - INFO - joeynmt.training - Epoch   6, Step:   141200, Batch Loss:     1.436053, Tokens per Sec:     3683, Lr: 0.000200
2022-01-22 11:29:28,233 - INFO - joeynmt.training - Epoch   6, Step:   141300, Batch Loss:     3.189026, Tokens per Sec:     3546, Lr: 0.000200
2022-01-22 11:29:47,203 - INFO - joeynmt.training - Epoch   6, Step:   141400, Batch Loss:     4.015050, Tokens per Sec:     3542, Lr: 0.000200
2022-01-22 11:30:05,959 - INFO - joeynmt.training - Epoch   6, Step:   141500, Batch Loss:     1.796292, Tokens per Sec:     3582, Lr: 0.000200
2022-01-22 11:30:24,576 - INFO - joeynmt.training - Epoch   6, Step:   141600, Batch Loss:     1.965062, Tokens per Sec:     3553, Lr: 0.000200
2022-01-22 11:30:43,599 - INFO - joeynmt.training - Epoch   6, Step:   141700, Batch Loss:     2.274980, Tokens per Sec:     3587, Lr: 0.000200
2022-01-22 11:31:02,653 - INFO - joeynmt.training - Epoch   6, Step:   141800, Batch Loss:     1.374145, Tokens per Sec:     3502, Lr: 0.000200
2022-01-22 11:31:21,658 - INFO - joeynmt.training - Epoch   6, Step:   141900, Batch Loss:     6.432392, Tokens per Sec:     3644, Lr: 0.000200
2022-01-22 11:31:40,683 - INFO - joeynmt.training - Epoch   6, Step:   142000, Batch Loss:     2.096600, Tokens per Sec:     3584, Lr: 0.000200
2022-01-22 11:53:24,948 - INFO - joeynmt.training - Example #0
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 11:53:24,949 - INFO - joeynmt.training - Example #1
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 11:53:24,949 - INFO - joeynmt.training - Example #2
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 11:53:24,949 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 11:53:24,950 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   142000: bleu:  86.43, loss: 277243.4062, ppl:   1.1879, duration: 1304.2671s
2022-01-22 11:53:44,270 - INFO - joeynmt.training - Epoch   6, Step:   142100, Batch Loss:     2.041351, Tokens per Sec:     3518, Lr: 0.000200
2022-01-22 11:54:03,320 - INFO - joeynmt.training - Epoch   6, Step:   142200, Batch Loss:     3.515374, Tokens per Sec:     3464, Lr: 0.000200
2022-01-22 11:54:22,494 - INFO - joeynmt.training - Epoch   6, Step:   142300, Batch Loss:     4.269500, Tokens per Sec:     3569, Lr: 0.000200
2022-01-22 11:54:42,283 - INFO - joeynmt.training - Epoch   6, Step:   142400, Batch Loss:     2.083083, Tokens per Sec:     3559, Lr: 0.000200
2022-01-22 11:55:01,858 - INFO - joeynmt.training - Epoch   6, Step:   142500, Batch Loss:     2.696315, Tokens per Sec:     3420, Lr: 0.000200
2022-01-22 11:55:21,435 - INFO - joeynmt.training - Epoch   6, Step:   142600, Batch Loss:     3.821625, Tokens per Sec:     3441, Lr: 0.000200
2022-01-22 11:55:41,327 - INFO - joeynmt.training - Epoch   6, Step:   142700, Batch Loss:     2.629260, Tokens per Sec:     3280, Lr: 0.000200
2022-01-22 11:56:00,839 - INFO - joeynmt.training - Epoch   6, Step:   142800, Batch Loss:     4.301717, Tokens per Sec:     3422, Lr: 0.000200
2022-01-22 11:56:20,255 - INFO - joeynmt.training - Epoch   6, Step:   142900, Batch Loss:     1.647963, Tokens per Sec:     3404, Lr: 0.000200
2022-01-22 11:56:39,883 - INFO - joeynmt.training - Epoch   6, Step:   143000, Batch Loss:     3.490540, Tokens per Sec:     3533, Lr: 0.000200
2022-01-22 12:18:25,888 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 12:18:58,790 - INFO - joeynmt.helpers - delete models/a_model/133000.ckpt
2022-01-22 12:18:58,829 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/133000.ckpt
2022-01-22 12:18:58,830 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/133000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/133000.ckpt')
2022-01-22 12:18:58,934 - INFO - joeynmt.training - Example #0
2022-01-22 12:18:58,934 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 12:18:58,934 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 12:18:58,934 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 12:18:58,934 - INFO - joeynmt.training - Example #1
2022-01-22 12:18:58,934 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 12:18:58,935 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 12:18:58,935 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 12:18:58,935 - INFO - joeynmt.training - Example #2
2022-01-22 12:18:58,935 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 12:18:58,935 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 12:18:58,935 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 12:18:58,936 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   143000: bleu:  86.63, loss: 269641.0312, ppl:   1.1823, duration: 1339.0522s
2022-01-22 12:19:18,293 - INFO - joeynmt.training - Epoch   6, Step:   143100, Batch Loss:     2.303949, Tokens per Sec:     3485, Lr: 0.000200
2022-01-22 12:19:37,516 - INFO - joeynmt.training - Epoch   6, Step:   143200, Batch Loss:     1.676900, Tokens per Sec:     3541, Lr: 0.000200
2022-01-22 12:19:56,452 - INFO - joeynmt.training - Epoch   6, Step:   143300, Batch Loss:     3.120542, Tokens per Sec:     3493, Lr: 0.000200
2022-01-22 12:20:15,493 - INFO - joeynmt.training - Epoch   6, Step:   143400, Batch Loss:     2.183056, Tokens per Sec:     3602, Lr: 0.000200
2022-01-22 12:20:34,157 - INFO - joeynmt.training - Epoch   6, Step:   143500, Batch Loss:     4.038331, Tokens per Sec:     3716, Lr: 0.000200
2022-01-22 12:20:52,548 - INFO - joeynmt.training - Epoch   6, Step:   143600, Batch Loss:     3.017670, Tokens per Sec:     3591, Lr: 0.000200
2022-01-22 12:21:10,617 - INFO - joeynmt.training - Epoch   6, Step:   143700, Batch Loss:     2.960460, Tokens per Sec:     3816, Lr: 0.000200
2022-01-22 12:21:28,518 - INFO - joeynmt.training - Epoch   6, Step:   143800, Batch Loss:     3.623282, Tokens per Sec:     3746, Lr: 0.000200
2022-01-22 12:21:46,612 - INFO - joeynmt.training - Epoch   6, Step:   143900, Batch Loss:     2.918562, Tokens per Sec:     3844, Lr: 0.000200
2022-01-22 12:22:04,504 - INFO - joeynmt.training - Epoch   6, Step:   144000, Batch Loss:     4.704637, Tokens per Sec:     3747, Lr: 0.000200
2022-01-22 12:43:56,141 - INFO - joeynmt.training - Example #0
2022-01-22 12:43:56,142 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 12:43:56,142 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 12:43:56,143 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 12:43:56,143 - INFO - joeynmt.training - Example #1
2022-01-22 12:43:56,143 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 12:43:56,143 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 12:43:56,143 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 12:43:56,143 - INFO - joeynmt.training - Example #2
2022-01-22 12:43:56,143 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 12:43:56,143 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 12:43:56,143 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 12:43:56,144 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   144000: bleu:  86.54, loss: 275116.0625, ppl:   1.1863, duration: 1311.6396s
2022-01-22 12:44:15,184 - INFO - joeynmt.training - Epoch   6, Step:   144100, Batch Loss:     3.201024, Tokens per Sec:     3440, Lr: 0.000200
2022-01-22 12:44:34,156 - INFO - joeynmt.training - Epoch   6, Step:   144200, Batch Loss:     1.349715, Tokens per Sec:     3506, Lr: 0.000200
2022-01-22 12:44:53,473 - INFO - joeynmt.training - Epoch   6, Step:   144300, Batch Loss:     9.535851, Tokens per Sec:     3582, Lr: 0.000200
2022-01-22 12:45:12,623 - INFO - joeynmt.training - Epoch   6, Step:   144400, Batch Loss:     1.324171, Tokens per Sec:     3514, Lr: 0.000200
2022-01-22 12:45:31,635 - INFO - joeynmt.training - Epoch   6, Step:   144500, Batch Loss:     2.285339, Tokens per Sec:     3516, Lr: 0.000200
2022-01-22 12:45:51,004 - INFO - joeynmt.training - Epoch   6, Step:   144600, Batch Loss:     1.658279, Tokens per Sec:     3449, Lr: 0.000200
2022-01-22 12:46:10,334 - INFO - joeynmt.training - Epoch   6, Step:   144700, Batch Loss:     2.908224, Tokens per Sec:     3523, Lr: 0.000200
2022-01-22 12:46:29,323 - INFO - joeynmt.training - Epoch   6, Step:   144800, Batch Loss:     3.001633, Tokens per Sec:     3517, Lr: 0.000200
2022-01-22 12:46:48,345 - INFO - joeynmt.training - Epoch   6, Step:   144900, Batch Loss:     1.833069, Tokens per Sec:     3527, Lr: 0.000200
2022-01-22 12:47:07,305 - INFO - joeynmt.training - Epoch   6, Step:   145000, Batch Loss:     1.755648, Tokens per Sec:     3526, Lr: 0.000200
2022-01-22 13:08:48,768 - INFO - joeynmt.training - Example #0
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 13:08:48,769 - INFO - joeynmt.training - Example #1
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 13:08:48,769 - INFO - joeynmt.training - Example #2
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 13:08:48,769 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 13:08:48,770 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   145000: bleu:  86.37, loss: 272942.7500, ppl:   1.1847, duration: 1301.4650s
2022-01-22 13:09:07,613 - INFO - joeynmt.training - Epoch   6, Step:   145100, Batch Loss:     3.292009, Tokens per Sec:     3627, Lr: 0.000200
2022-01-22 13:09:26,017 - INFO - joeynmt.training - Epoch   6, Step:   145200, Batch Loss:     2.144889, Tokens per Sec:     3724, Lr: 0.000200
2022-01-22 13:09:44,674 - INFO - joeynmt.training - Epoch   6, Step:   145300, Batch Loss:     3.683137, Tokens per Sec:     3517, Lr: 0.000200
2022-01-22 13:10:03,286 - INFO - joeynmt.training - Epoch   6, Step:   145400, Batch Loss:     2.637866, Tokens per Sec:     3703, Lr: 0.000200
2022-01-22 13:10:22,069 - INFO - joeynmt.training - Epoch   6, Step:   145500, Batch Loss:     3.581764, Tokens per Sec:     3686, Lr: 0.000200
2022-01-22 13:10:40,686 - INFO - joeynmt.training - Epoch   6, Step:   145600, Batch Loss:     4.878180, Tokens per Sec:     3540, Lr: 0.000200
2022-01-22 13:10:58,911 - INFO - joeynmt.training - Epoch   6, Step:   145700, Batch Loss:     2.680184, Tokens per Sec:     3689, Lr: 0.000200
2022-01-22 13:11:17,456 - INFO - joeynmt.training - Epoch   6, Step:   145800, Batch Loss:     2.338738, Tokens per Sec:     3615, Lr: 0.000200
2022-01-22 13:11:35,738 - INFO - joeynmt.training - Epoch   6, Step:   145900, Batch Loss:     4.160569, Tokens per Sec:     3699, Lr: 0.000200
2022-01-22 13:11:53,597 - INFO - joeynmt.training - Epoch   6, Step:   146000, Batch Loss:     3.339251, Tokens per Sec:     3773, Lr: 0.000200
2022-01-22 13:34:33,122 - INFO - joeynmt.training - Example #0
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 13:34:33,123 - INFO - joeynmt.training - Example #1
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 13:34:33,123 - INFO - joeynmt.training - Example #2
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 13:34:33,123 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 13:34:33,124 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   146000: bleu:  86.27, loss: 279481.9062, ppl:   1.1896, duration: 1359.5263s
2022-01-22 13:34:52,216 - INFO - joeynmt.training - Epoch   6, Step:   146100, Batch Loss:     2.988244, Tokens per Sec:     3528, Lr: 0.000200
2022-01-22 13:35:11,086 - INFO - joeynmt.training - Epoch   6, Step:   146200, Batch Loss:     3.263801, Tokens per Sec:     3526, Lr: 0.000200
2022-01-22 13:35:29,709 - INFO - joeynmt.training - Epoch   6, Step:   146300, Batch Loss:     3.931805, Tokens per Sec:     3510, Lr: 0.000200
2022-01-22 13:35:48,418 - INFO - joeynmt.training - Epoch   6, Step:   146400, Batch Loss:     3.845016, Tokens per Sec:     3525, Lr: 0.000200
2022-01-22 13:36:07,089 - INFO - joeynmt.training - Epoch   6, Step:   146500, Batch Loss:     3.450424, Tokens per Sec:     3681, Lr: 0.000200
2022-01-22 13:36:25,730 - INFO - joeynmt.training - Epoch   6, Step:   146600, Batch Loss:     2.518010, Tokens per Sec:     3649, Lr: 0.000200
2022-01-22 13:36:44,226 - INFO - joeynmt.training - Epoch   6, Step:   146700, Batch Loss:     3.916185, Tokens per Sec:     3662, Lr: 0.000200
2022-01-22 13:37:02,600 - INFO - joeynmt.training - Epoch   6, Step:   146800, Batch Loss:     3.888921, Tokens per Sec:     3678, Lr: 0.000200
2022-01-22 13:37:20,862 - INFO - joeynmt.training - Epoch   6, Step:   146900, Batch Loss:     4.233819, Tokens per Sec:     3648, Lr: 0.000200
2022-01-22 13:37:39,457 - INFO - joeynmt.training - Epoch   6, Step:   147000, Batch Loss:     2.494580, Tokens per Sec:     3637, Lr: 0.000200
2022-01-22 14:02:57,246 - INFO - joeynmt.training - Example #0
2022-01-22 14:02:57,247 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 14:02:57,247 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 14:02:57,247 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 14:02:57,247 - INFO - joeynmt.training - Example #1
2022-01-22 14:02:57,248 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 14:02:57,248 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 14:02:57,248 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 14:02:57,248 - INFO - joeynmt.training - Example #2
2022-01-22 14:02:57,248 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 14:02:57,248 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 14:02:57,248 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 14:02:57,249 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   147000: bleu:  86.37, loss: 272947.2500, ppl:   1.1847, duration: 1517.7914s
2022-01-22 14:03:16,607 - INFO - joeynmt.training - Epoch   6, Step:   147100, Batch Loss:     3.620535, Tokens per Sec:     3491, Lr: 0.000200
2022-01-22 14:03:35,603 - INFO - joeynmt.training - Epoch   6, Step:   147200, Batch Loss:     3.948252, Tokens per Sec:     3472, Lr: 0.000200
2022-01-22 14:03:54,911 - INFO - joeynmt.training - Epoch   6, Step:   147300, Batch Loss:     2.621036, Tokens per Sec:     3562, Lr: 0.000200
2022-01-22 14:04:13,968 - INFO - joeynmt.training - Epoch   6, Step:   147400, Batch Loss:     1.321388, Tokens per Sec:     3545, Lr: 0.000200
2022-01-22 14:04:32,936 - INFO - joeynmt.training - Epoch   6, Step:   147500, Batch Loss:     2.134469, Tokens per Sec:     3521, Lr: 0.000200
2022-01-22 14:04:51,559 - INFO - joeynmt.training - Epoch   6, Step:   147600, Batch Loss:     1.529187, Tokens per Sec:     3545, Lr: 0.000200
2022-01-22 14:05:10,270 - INFO - joeynmt.training - Epoch   6, Step:   147700, Batch Loss:     1.802317, Tokens per Sec:     3611, Lr: 0.000200
2022-01-22 14:05:28,827 - INFO - joeynmt.training - Epoch   6, Step:   147800, Batch Loss:     2.790345, Tokens per Sec:     3744, Lr: 0.000200
2022-01-22 14:05:47,238 - INFO - joeynmt.training - Epoch   6, Step:   147900, Batch Loss:    12.725250, Tokens per Sec:     3723, Lr: 0.000200
2022-01-22 14:06:05,728 - INFO - joeynmt.training - Epoch   6, Step:   148000, Batch Loss:     7.414607, Tokens per Sec:     3611, Lr: 0.000200
2022-01-22 14:31:44,884 - INFO - joeynmt.training - Example #0
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 14:31:44,885 - INFO - joeynmt.training - Example #1
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 14:31:44,885 - INFO - joeynmt.training - Example #2
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 14:31:44,885 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 14:31:44,886 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   148000: bleu:  86.39, loss: 280133.8438, ppl:   1.1900, duration: 1539.1579s
2022-01-22 14:32:04,029 - INFO - joeynmt.training - Epoch   6, Step:   148100, Batch Loss:     3.045496, Tokens per Sec:     3483, Lr: 0.000200
2022-01-22 14:32:22,496 - INFO - joeynmt.training - Epoch   6, Step:   148200, Batch Loss:     5.103141, Tokens per Sec:     3566, Lr: 0.000200
2022-01-22 14:32:41,309 - INFO - joeynmt.training - Epoch   6, Step:   148300, Batch Loss:     3.422775, Tokens per Sec:     3690, Lr: 0.000200
2022-01-22 14:32:59,679 - INFO - joeynmt.training - Epoch   6, Step:   148400, Batch Loss:     2.532016, Tokens per Sec:     3627, Lr: 0.000200
2022-01-22 14:33:18,217 - INFO - joeynmt.training - Epoch   6, Step:   148500, Batch Loss:     2.691277, Tokens per Sec:     3560, Lr: 0.000200
2022-01-22 14:33:38,284 - INFO - joeynmt.training - Epoch   6, Step:   148600, Batch Loss:     1.976030, Tokens per Sec:     3336, Lr: 0.000200
2022-01-22 14:34:17,338 - INFO - joeynmt.training - Epoch   6, Step:   148700, Batch Loss:     1.883480, Tokens per Sec:     1778, Lr: 0.000200
2022-01-22 14:34:36,581 - INFO - joeynmt.training - Epoch   6, Step:   148800, Batch Loss:     1.195356, Tokens per Sec:     3386, Lr: 0.000200
2022-01-22 14:34:55,616 - INFO - joeynmt.training - Epoch   6, Step:   148900, Batch Loss:     4.287455, Tokens per Sec:     3453, Lr: 0.000200
2022-01-22 14:35:14,328 - INFO - joeynmt.training - Epoch   6, Step:   149000, Batch Loss:     2.311233, Tokens per Sec:     3621, Lr: 0.000200
2022-01-22 15:00:39,725 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 15:01:12,480 - INFO - joeynmt.helpers - delete models/a_model/143000.ckpt
2022-01-22 15:01:12,515 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/143000.ckpt
2022-01-22 15:01:12,516 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/143000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/143000.ckpt')
2022-01-22 15:01:12,596 - INFO - joeynmt.training - Example #0
2022-01-22 15:01:12,596 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 15:01:12,596 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 15:01:12,596 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 15:01:12,596 - INFO - joeynmt.training - Example #1
2022-01-22 15:01:12,596 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 15:01:12,596 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 15:01:12,597 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 15:01:12,597 - INFO - joeynmt.training - Example #2
2022-01-22 15:01:12,597 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 15:01:12,597 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 15:01:12,597 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 15:01:12,598 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   149000: bleu:  86.66, loss: 273879.7812, ppl:   1.1854, duration: 1558.2692s
2022-01-22 15:01:31,560 - INFO - joeynmt.training - Epoch   6, Step:   149100, Batch Loss:     2.677155, Tokens per Sec:     3534, Lr: 0.000200
2022-01-22 15:01:50,419 - INFO - joeynmt.training - Epoch   6, Step:   149200, Batch Loss:     2.896399, Tokens per Sec:     3581, Lr: 0.000200
2022-01-22 15:02:09,111 - INFO - joeynmt.training - Epoch   6, Step:   149300, Batch Loss:     2.713448, Tokens per Sec:     3739, Lr: 0.000200
2022-01-22 15:02:27,503 - INFO - joeynmt.training - Epoch   6, Step:   149400, Batch Loss:     2.357349, Tokens per Sec:     3782, Lr: 0.000200
2022-01-22 15:02:46,002 - INFO - joeynmt.training - Epoch   6, Step:   149500, Batch Loss:     1.891943, Tokens per Sec:     3520, Lr: 0.000200
2022-01-22 15:03:04,672 - INFO - joeynmt.training - Epoch   6, Step:   149600, Batch Loss:     4.676927, Tokens per Sec:     3600, Lr: 0.000200
2022-01-22 15:03:23,221 - INFO - joeynmt.training - Epoch   6, Step:   149700, Batch Loss:     2.403750, Tokens per Sec:     3612, Lr: 0.000200
2022-01-22 15:03:41,737 - INFO - joeynmt.training - Epoch   6, Step:   149800, Batch Loss:     5.635126, Tokens per Sec:     3553, Lr: 0.000200
2022-01-22 15:04:14,871 - INFO - joeynmt.training - Epoch   6, Step:   149900, Batch Loss:     2.882001, Tokens per Sec:     2032, Lr: 0.000200
2022-01-22 15:04:40,823 - INFO - joeynmt.training - Epoch   6, Step:   150000, Batch Loss:     2.418944, Tokens per Sec:     2637, Lr: 0.000200
2022-01-22 15:30:02,794 - INFO - joeynmt.training - Example #0
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 15:30:02,795 - INFO - joeynmt.training - Example #1
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 15:30:02,795 - INFO - joeynmt.training - Example #2
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 15:30:02,795 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 15:30:02,796 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   150000: bleu:  86.51, loss: 270659.9062, ppl:   1.1831, duration: 1521.9724s
2022-01-22 15:30:21,733 - INFO - joeynmt.training - Epoch   6, Step:   150100, Batch Loss:     4.364511, Tokens per Sec:     3488, Lr: 0.000200
2022-01-22 15:30:39,881 - INFO - joeynmt.training - Epoch   6, Step:   150200, Batch Loss:     1.968943, Tokens per Sec:     3621, Lr: 0.000200
2022-01-22 15:30:58,775 - INFO - joeynmt.training - Epoch   6, Step:   150300, Batch Loss:     4.423163, Tokens per Sec:     3641, Lr: 0.000200
2022-01-22 15:31:17,251 - INFO - joeynmt.training - Epoch   6, Step:   150400, Batch Loss:     4.838140, Tokens per Sec:     3749, Lr: 0.000200
2022-01-22 15:31:35,780 - INFO - joeynmt.training - Epoch   6, Step:   150500, Batch Loss:     4.164745, Tokens per Sec:     3753, Lr: 0.000200
2022-01-22 15:31:54,541 - INFO - joeynmt.training - Epoch   6, Step:   150600, Batch Loss:     5.103983, Tokens per Sec:     3697, Lr: 0.000200
2022-01-22 15:32:13,237 - INFO - joeynmt.training - Epoch   6, Step:   150700, Batch Loss:     6.499117, Tokens per Sec:     3717, Lr: 0.000200
2022-01-22 15:32:31,579 - INFO - joeynmt.training - Epoch   6, Step:   150800, Batch Loss:     2.004336, Tokens per Sec:     3618, Lr: 0.000200
2022-01-22 15:32:50,036 - INFO - joeynmt.training - Epoch   6, Step:   150900, Batch Loss:     3.653958, Tokens per Sec:     3585, Lr: 0.000200
2022-01-22 15:33:08,715 - INFO - joeynmt.training - Epoch   6, Step:   151000, Batch Loss:     3.105945, Tokens per Sec:     3524, Lr: 0.000200
2022-01-22 16:00:45,789 - INFO - joeynmt.training - Example #0
2022-01-22 16:00:45,790 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 16:00:45,790 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 16:00:45,790 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 16:00:45,790 - INFO - joeynmt.training - Example #1
2022-01-22 16:00:45,791 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 16:00:45,791 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 16:00:45,791 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 16:00:45,791 - INFO - joeynmt.training - Example #2
2022-01-22 16:00:45,791 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 16:00:45,791 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 16:00:45,791 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 16:00:45,792 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   151000: bleu:  86.51, loss: 273270.4688, ppl:   1.1850, duration: 1657.0765s
2022-01-22 16:01:05,010 - INFO - joeynmt.training - Epoch   6, Step:   151100, Batch Loss:     4.223567, Tokens per Sec:     3654, Lr: 0.000200
2022-01-22 16:01:23,899 - INFO - joeynmt.training - Epoch   6, Step:   151200, Batch Loss:     3.249268, Tokens per Sec:     3566, Lr: 0.000200
2022-01-22 16:01:42,870 - INFO - joeynmt.training - Epoch   6, Step:   151300, Batch Loss:     4.847956, Tokens per Sec:     3641, Lr: 0.000200
2022-01-22 16:02:01,350 - INFO - joeynmt.training - Epoch   6, Step:   151400, Batch Loss:     2.009572, Tokens per Sec:     3723, Lr: 0.000200
2022-01-22 16:02:19,964 - INFO - joeynmt.training - Epoch   6, Step:   151500, Batch Loss:     1.750341, Tokens per Sec:     3582, Lr: 0.000200
2022-01-22 16:02:38,885 - INFO - joeynmt.training - Epoch   6, Step:   151600, Batch Loss:     4.231529, Tokens per Sec:     3446, Lr: 0.000200
2022-01-22 16:02:57,480 - INFO - joeynmt.training - Epoch   6, Step:   151700, Batch Loss:     5.284081, Tokens per Sec:     3566, Lr: 0.000200
2022-01-22 16:03:15,859 - INFO - joeynmt.training - Epoch   6, Step:   151800, Batch Loss:     2.692406, Tokens per Sec:     3679, Lr: 0.000200
2022-01-22 16:03:34,272 - INFO - joeynmt.training - Epoch   6, Step:   151900, Batch Loss:     2.302767, Tokens per Sec:     3722, Lr: 0.000200
2022-01-22 16:03:52,790 - INFO - joeynmt.training - Epoch   6, Step:   152000, Batch Loss:     4.253584, Tokens per Sec:     3713, Lr: 0.000200
2022-01-22 16:31:34,564 - INFO - joeynmt.training - Example #0
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-22 16:31:34,565 - INFO - joeynmt.training - Example #1
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 16:31:34,565 - INFO - joeynmt.training - Example #2
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 16:31:34,565 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 16:31:34,566 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   152000: bleu:  86.29, loss: 286090.8438, ppl:   1.1944, duration: 1661.7749s
2022-01-22 16:31:53,793 - INFO - joeynmt.training - Epoch   6, Step:   152100, Batch Loss:     2.425882, Tokens per Sec:     3424, Lr: 0.000200
2022-01-22 16:32:12,671 - INFO - joeynmt.training - Epoch   6, Step:   152200, Batch Loss:     2.467510, Tokens per Sec:     3586, Lr: 0.000200
2022-01-22 16:32:31,645 - INFO - joeynmt.training - Epoch   6, Step:   152300, Batch Loss:     1.578254, Tokens per Sec:     3536, Lr: 0.000200
2022-01-22 16:32:50,564 - INFO - joeynmt.training - Epoch   6, Step:   152400, Batch Loss:     3.893672, Tokens per Sec:     3583, Lr: 0.000200
2022-01-22 16:33:09,146 - INFO - joeynmt.training - Epoch   6, Step:   152500, Batch Loss:     2.211747, Tokens per Sec:     3490, Lr: 0.000200
2022-01-22 16:33:28,304 - INFO - joeynmt.training - Epoch   6, Step:   152600, Batch Loss:     1.709962, Tokens per Sec:     3644, Lr: 0.000200
2022-01-22 16:33:47,112 - INFO - joeynmt.training - Epoch   6, Step:   152700, Batch Loss:     4.748264, Tokens per Sec:     3636, Lr: 0.000200
2022-01-22 16:34:06,041 - INFO - joeynmt.training - Epoch   6, Step:   152800, Batch Loss:     2.943931, Tokens per Sec:     3567, Lr: 0.000200
2022-01-22 16:34:24,565 - INFO - joeynmt.training - Epoch   6, Step:   152900, Batch Loss:     2.880547, Tokens per Sec:     3558, Lr: 0.000200
2022-01-22 16:34:43,099 - INFO - joeynmt.training - Epoch   6, Step:   153000, Batch Loss:     6.774132, Tokens per Sec:     3623, Lr: 0.000200
2022-01-22 17:01:56,274 - INFO - joeynmt.training - Example #0
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 17:01:56,275 - INFO - joeynmt.training - Example #1
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 17:01:56,275 - INFO - joeynmt.training - Example #2
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 17:01:56,275 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 17:01:56,276 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   153000: bleu:  86.43, loss: 277622.2500, ppl:   1.1882, duration: 1633.1767s
2022-01-22 17:02:14,944 - INFO - joeynmt.training - Epoch   6, Step:   153100, Batch Loss:     3.347898, Tokens per Sec:     3631, Lr: 0.000200
2022-01-22 17:02:33,585 - INFO - joeynmt.training - Epoch   6, Step:   153200, Batch Loss:     4.386755, Tokens per Sec:     3726, Lr: 0.000200
2022-01-22 17:02:52,051 - INFO - joeynmt.training - Epoch   6, Step:   153300, Batch Loss:     2.823879, Tokens per Sec:     3495, Lr: 0.000200
2022-01-22 17:03:10,582 - INFO - joeynmt.training - Epoch   6, Step:   153400, Batch Loss:     2.666487, Tokens per Sec:     3485, Lr: 0.000200
2022-01-22 17:03:29,052 - INFO - joeynmt.training - Epoch   6, Step:   153500, Batch Loss:     3.508230, Tokens per Sec:     3695, Lr: 0.000200
2022-01-22 17:03:47,714 - INFO - joeynmt.training - Epoch   6, Step:   153600, Batch Loss:     1.552457, Tokens per Sec:     3652, Lr: 0.000200
2022-01-22 17:04:06,078 - INFO - joeynmt.training - Epoch   6, Step:   153700, Batch Loss:     2.776752, Tokens per Sec:     3603, Lr: 0.000200
2022-01-22 17:04:24,932 - INFO - joeynmt.training - Epoch   6, Step:   153800, Batch Loss:     2.934774, Tokens per Sec:     3585, Lr: 0.000200
2022-01-22 17:04:43,752 - INFO - joeynmt.training - Epoch   6, Step:   153900, Batch Loss:     2.213820, Tokens per Sec:     3497, Lr: 0.000200
2022-01-22 17:05:02,583 - INFO - joeynmt.training - Epoch   6, Step:   154000, Batch Loss:     4.658463, Tokens per Sec:     3649, Lr: 0.000200
2022-01-22 17:32:39,495 - INFO - joeynmt.training - Example #0
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 17:32:39,496 - INFO - joeynmt.training - Example #1
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 17:32:39,496 - INFO - joeynmt.training - Example #2
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 17:32:39,496 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 17:32:39,497 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   154000: bleu:  86.65, loss: 272153.0000, ppl:   1.1841, duration: 1656.9135s
2022-01-22 17:32:58,698 - INFO - joeynmt.training - Epoch   6, Step:   154100, Batch Loss:     1.915848, Tokens per Sec:     3461, Lr: 0.000200
2022-01-22 17:33:17,274 - INFO - joeynmt.training - Epoch   6, Step:   154200, Batch Loss:     3.124314, Tokens per Sec:     3587, Lr: 0.000200
2022-01-22 17:33:36,196 - INFO - joeynmt.training - Epoch   6, Step:   154300, Batch Loss:     2.633616, Tokens per Sec:     3647, Lr: 0.000200
2022-01-22 17:33:55,055 - INFO - joeynmt.training - Epoch   6, Step:   154400, Batch Loss:     3.864873, Tokens per Sec:     3792, Lr: 0.000200
2022-01-22 17:34:13,651 - INFO - joeynmt.training - Epoch   6, Step:   154500, Batch Loss:     3.277538, Tokens per Sec:     3585, Lr: 0.000200
2022-01-22 17:34:32,324 - INFO - joeynmt.training - Epoch   6, Step:   154600, Batch Loss:     1.624062, Tokens per Sec:     3645, Lr: 0.000200
2022-01-22 17:34:51,077 - INFO - joeynmt.training - Epoch   6, Step:   154700, Batch Loss:     4.823853, Tokens per Sec:     3658, Lr: 0.000200
2022-01-22 17:35:09,805 - INFO - joeynmt.training - Epoch   6, Step:   154800, Batch Loss:     5.016298, Tokens per Sec:     3682, Lr: 0.000200
2022-01-22 17:35:28,514 - INFO - joeynmt.training - Epoch   6, Step:   154900, Batch Loss:     4.256570, Tokens per Sec:     3647, Lr: 0.000200
2022-01-22 17:35:47,466 - INFO - joeynmt.training - Epoch   6, Step:   155000, Batch Loss:     2.572222, Tokens per Sec:     3542, Lr: 0.000200
2022-01-22 18:03:08,929 - INFO - joeynmt.training - Example #0
2022-01-22 18:03:08,930 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 18:03:08,930 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 18:03:08,930 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 33 12 | 37 17 | 8 13
2022-01-22 18:03:08,930 - INFO - joeynmt.training - Example #1
2022-01-22 18:03:08,931 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 18:03:08,931 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 18:03:08,931 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 18:03:08,931 - INFO - joeynmt.training - Example #2
2022-01-22 18:03:08,931 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 18:03:08,931 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 18:03:08,931 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 18:03:08,932 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   155000: bleu:  86.41, loss: 274362.7500, ppl:   1.1858, duration: 1641.4655s
2022-01-22 18:03:27,954 - INFO - joeynmt.training - Epoch   6, Step:   155100, Batch Loss:     1.818198, Tokens per Sec:     3573, Lr: 0.000200
2022-01-22 18:03:46,538 - INFO - joeynmt.training - Epoch   6, Step:   155200, Batch Loss:     4.217016, Tokens per Sec:     3738, Lr: 0.000200
2022-01-22 18:04:05,244 - INFO - joeynmt.training - Epoch   6, Step:   155300, Batch Loss:     3.301222, Tokens per Sec:     3792, Lr: 0.000200
2022-01-22 18:04:24,049 - INFO - joeynmt.training - Epoch   6, Step:   155400, Batch Loss:     3.907611, Tokens per Sec:     3652, Lr: 0.000200
2022-01-22 18:04:42,452 - INFO - joeynmt.training - Epoch   6, Step:   155500, Batch Loss:     1.853104, Tokens per Sec:     3574, Lr: 0.000200
2022-01-22 18:05:01,322 - INFO - joeynmt.training - Epoch   6, Step:   155600, Batch Loss:     4.405603, Tokens per Sec:     3539, Lr: 0.000200
2022-01-22 18:05:19,905 - INFO - joeynmt.training - Epoch   6, Step:   155700, Batch Loss:     4.413358, Tokens per Sec:     3534, Lr: 0.000200
2022-01-22 18:05:38,369 - INFO - joeynmt.training - Epoch   6, Step:   155800, Batch Loss:     3.463639, Tokens per Sec:     3668, Lr: 0.000200
2022-01-22 18:05:57,103 - INFO - joeynmt.training - Epoch   6, Step:   155900, Batch Loss:     2.976377, Tokens per Sec:     3601, Lr: 0.000200
2022-01-22 18:06:16,136 - INFO - joeynmt.training - Epoch   6, Step:   156000, Batch Loss:     2.969694, Tokens per Sec:     3570, Lr: 0.000200
2022-01-22 18:34:09,583 - INFO - joeynmt.training - Example #0
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 18:34:09,585 - INFO - joeynmt.training - Example #1
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 23 34 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 18:34:09,585 - INFO - joeynmt.training - Example #2
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 18:34:09,585 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 18:34:09,586 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   156000: bleu:  86.60, loss: 271452.3750, ppl:   1.1836, duration: 1673.4504s
2022-01-22 18:34:28,403 - INFO - joeynmt.training - Epoch   6, Step:   156100, Batch Loss:     2.916553, Tokens per Sec:     3521, Lr: 0.000200
2022-01-22 18:34:47,608 - INFO - joeynmt.training - Epoch   6, Step:   156200, Batch Loss:     1.663067, Tokens per Sec:     3428, Lr: 0.000200
2022-01-22 18:35:06,446 - INFO - joeynmt.training - Epoch   6, Step:   156300, Batch Loss:     3.195270, Tokens per Sec:     3593, Lr: 0.000200
2022-01-22 18:35:25,196 - INFO - joeynmt.training - Epoch   6, Step:   156400, Batch Loss:     2.718571, Tokens per Sec:     3603, Lr: 0.000200
2022-01-22 18:35:44,068 - INFO - joeynmt.training - Epoch   6, Step:   156500, Batch Loss:     4.744591, Tokens per Sec:     3588, Lr: 0.000200
2022-01-22 18:36:03,166 - INFO - joeynmt.training - Epoch   6, Step:   156600, Batch Loss:     5.406369, Tokens per Sec:     3579, Lr: 0.000200
2022-01-22 18:36:21,970 - INFO - joeynmt.training - Epoch   6, Step:   156700, Batch Loss:     4.662393, Tokens per Sec:     3539, Lr: 0.000200
2022-01-22 18:36:40,515 - INFO - joeynmt.training - Epoch   6, Step:   156800, Batch Loss:     1.604166, Tokens per Sec:     3683, Lr: 0.000200
2022-01-22 18:36:59,219 - INFO - joeynmt.training - Epoch   6, Step:   156900, Batch Loss:     2.553110, Tokens per Sec:     3686, Lr: 0.000200
2022-01-22 18:37:17,746 - INFO - joeynmt.training - Epoch   6, Step:   157000, Batch Loss:     2.401729, Tokens per Sec:     3594, Lr: 0.000200
2022-01-22 19:05:16,153 - INFO - joeynmt.training - Example #0
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 19:05:16,154 - INFO - joeynmt.training - Example #1
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 19:05:16,154 - INFO - joeynmt.training - Example #2
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 19:05:16,154 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6 | 30 28
2022-01-22 19:05:16,155 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   157000: bleu:  86.58, loss: 272197.4688, ppl:   1.1842, duration: 1678.4087s
2022-01-22 19:05:35,197 - INFO - joeynmt.training - Epoch   6, Step:   157100, Batch Loss:     2.226289, Tokens per Sec:     3634, Lr: 0.000200
2022-01-22 19:05:53,933 - INFO - joeynmt.training - Epoch   6, Step:   157200, Batch Loss:     2.592286, Tokens per Sec:     3636, Lr: 0.000200
2022-01-22 19:06:12,656 - INFO - joeynmt.training - Epoch   6, Step:   157300, Batch Loss:     8.207980, Tokens per Sec:     3632, Lr: 0.000200
2022-01-22 19:06:31,190 - INFO - joeynmt.training - Epoch   6, Step:   157400, Batch Loss:     2.911263, Tokens per Sec:     3672, Lr: 0.000200
2022-01-22 19:06:50,319 - INFO - joeynmt.training - Epoch   6, Step:   157500, Batch Loss:     2.949167, Tokens per Sec:     3554, Lr: 0.000200
2022-01-22 19:07:09,146 - INFO - joeynmt.training - Epoch   6, Step:   157600, Batch Loss:     3.029358, Tokens per Sec:     3657, Lr: 0.000200
2022-01-22 19:07:28,030 - INFO - joeynmt.training - Epoch   6, Step:   157700, Batch Loss:     7.315668, Tokens per Sec:     3655, Lr: 0.000200
2022-01-22 19:07:46,865 - INFO - joeynmt.training - Epoch   6, Step:   157800, Batch Loss:     6.865638, Tokens per Sec:     3462, Lr: 0.000200
2022-01-22 19:08:05,806 - INFO - joeynmt.training - Epoch   6, Step:   157900, Batch Loss:     2.200130, Tokens per Sec:     3592, Lr: 0.000200
2022-01-22 19:08:24,517 - INFO - joeynmt.training - Epoch   6, Step:   158000, Batch Loss:     2.388801, Tokens per Sec:     3693, Lr: 0.000200
2022-01-22 19:35:53,253 - INFO - joeynmt.training - Example #0
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 19:35:53,254 - INFO - joeynmt.training - Example #1
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 19:35:53,254 - INFO - joeynmt.training - Example #2
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 19:35:53,254 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 19:35:53,255 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   158000: bleu:  86.65, loss: 268189.4688, ppl:   1.1812, duration: 1648.7373s
2022-01-22 19:36:12,973 - INFO - joeynmt.training - Epoch   6, Step:   158100, Batch Loss:     2.098010, Tokens per Sec:     3473, Lr: 0.000200
2022-01-22 19:36:31,786 - INFO - joeynmt.training - Epoch   6, Step:   158200, Batch Loss:     2.946403, Tokens per Sec:     3574, Lr: 0.000200
2022-01-22 19:36:50,341 - INFO - joeynmt.training - Epoch   6, Step:   158300, Batch Loss:     1.726216, Tokens per Sec:     3629, Lr: 0.000200
2022-01-22 19:37:09,330 - INFO - joeynmt.training - Epoch   6, Step:   158400, Batch Loss:     4.173802, Tokens per Sec:     3586, Lr: 0.000200
2022-01-22 19:37:27,833 - INFO - joeynmt.training - Epoch   6, Step:   158500, Batch Loss:     2.113398, Tokens per Sec:     3686, Lr: 0.000200
2022-01-22 19:37:46,542 - INFO - joeynmt.training - Epoch   6, Step:   158600, Batch Loss:     3.812780, Tokens per Sec:     3589, Lr: 0.000200
2022-01-22 19:38:09,082 - INFO - joeynmt.training - Epoch   6, Step:   158700, Batch Loss:     4.472346, Tokens per Sec:     3026, Lr: 0.000200
2022-01-22 19:39:17,547 - INFO - joeynmt.training - Epoch   6, Step:   158800, Batch Loss:     3.146533, Tokens per Sec:      977, Lr: 0.000200
2022-01-22 19:39:47,167 - INFO - joeynmt.training - Epoch   6, Step:   158900, Batch Loss:     2.532216, Tokens per Sec:     2229, Lr: 0.000200
2022-01-22 19:40:05,601 - INFO - joeynmt.training - Epoch   6, Step:   159000, Batch Loss:     2.732906, Tokens per Sec:     3648, Lr: 0.000200
2022-01-22 20:08:37,574 - INFO - joeynmt.training - Example #0
2022-01-22 20:08:37,575 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 20:08:37,575 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 20:08:37,575 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 20:08:37,575 - INFO - joeynmt.training - Example #1
2022-01-22 20:08:37,576 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 20:08:37,576 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 20:08:37,576 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 20:08:37,576 - INFO - joeynmt.training - Example #2
2022-01-22 20:08:37,576 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 20:08:37,576 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 20:08:37,576 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 20:08:37,577 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step   159000: bleu:  86.54, loss: 277507.9062, ppl:   1.1881, duration: 1711.9749s
2022-01-22 20:08:56,620 - INFO - joeynmt.training - Epoch   6, Step:   159100, Batch Loss:     3.575743, Tokens per Sec:     3563, Lr: 0.000200
2022-01-22 20:09:15,342 - INFO - joeynmt.training - Epoch   6, Step:   159200, Batch Loss:     3.575388, Tokens per Sec:     3607, Lr: 0.000200
2022-01-22 20:09:34,024 - INFO - joeynmt.training - Epoch   6, Step:   159300, Batch Loss:     3.305279, Tokens per Sec:     3529, Lr: 0.000200
2022-01-22 20:09:44,777 - INFO - joeynmt.training - Epoch   6: total training loss 95308.79
2022-01-22 20:09:44,777 - INFO - joeynmt.training - EPOCH 7
2022-01-22 20:09:53,397 - INFO - joeynmt.training - Epoch   7, Step:   159400, Batch Loss:     7.548317, Tokens per Sec:     3329, Lr: 0.000200
2022-01-22 20:10:12,111 - INFO - joeynmt.training - Epoch   7, Step:   159500, Batch Loss:     3.646818, Tokens per Sec:     3573, Lr: 0.000200
2022-01-22 20:10:30,867 - INFO - joeynmt.training - Epoch   7, Step:   159600, Batch Loss:     2.421299, Tokens per Sec:     3561, Lr: 0.000200
2022-01-22 20:10:50,074 - INFO - joeynmt.training - Epoch   7, Step:   159700, Batch Loss:     2.891245, Tokens per Sec:     3471, Lr: 0.000200
2022-01-22 20:11:08,989 - INFO - joeynmt.training - Epoch   7, Step:   159800, Batch Loss:     5.654153, Tokens per Sec:     3622, Lr: 0.000200
2022-01-22 20:11:27,816 - INFO - joeynmt.training - Epoch   7, Step:   159900, Batch Loss:     4.784005, Tokens per Sec:     3516, Lr: 0.000200
2022-01-22 20:11:46,558 - INFO - joeynmt.training - Epoch   7, Step:   160000, Batch Loss:     3.878741, Tokens per Sec:     3658, Lr: 0.000200
2022-01-22 20:40:37,143 - INFO - joeynmt.training - Example #0
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 20:40:37,144 - INFO - joeynmt.training - Example #1
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15 | 23 34
2022-01-22 20:40:37,144 - INFO - joeynmt.training - Example #2
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 20:40:37,144 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 20:40:37,145 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step   160000: bleu:  86.61, loss: 280647.9375, ppl:   1.1904, duration: 1730.5865s
2022-01-22 20:40:55,786 - INFO - joeynmt.training - Epoch   7, Step:   160100, Batch Loss:     3.300132, Tokens per Sec:     3617, Lr: 0.000020
2022-01-22 20:41:14,992 - INFO - joeynmt.training - Epoch   7, Step:   160200, Batch Loss:     2.222516, Tokens per Sec:     3631, Lr: 0.000020
2022-01-22 20:41:33,849 - INFO - joeynmt.training - Epoch   7, Step:   160300, Batch Loss:     3.002067, Tokens per Sec:     3635, Lr: 0.000020
2022-01-22 20:41:52,823 - INFO - joeynmt.training - Epoch   7, Step:   160400, Batch Loss:     3.782967, Tokens per Sec:     3588, Lr: 0.000020
2022-01-22 20:42:11,920 - INFO - joeynmt.training - Epoch   7, Step:   160500, Batch Loss:     2.948507, Tokens per Sec:     3555, Lr: 0.000020
2022-01-22 20:42:30,874 - INFO - joeynmt.training - Epoch   7, Step:   160600, Batch Loss:     3.095298, Tokens per Sec:     3600, Lr: 0.000020
2022-01-22 20:42:49,674 - INFO - joeynmt.training - Epoch   7, Step:   160700, Batch Loss:     2.236937, Tokens per Sec:     3518, Lr: 0.000020
2022-01-22 20:43:08,639 - INFO - joeynmt.training - Epoch   7, Step:   160800, Batch Loss:     2.934831, Tokens per Sec:     3606, Lr: 0.000020
2022-01-22 20:43:27,640 - INFO - joeynmt.training - Epoch   7, Step:   160900, Batch Loss:     5.391399, Tokens per Sec:     3602, Lr: 0.000020
2022-01-22 20:43:46,219 - INFO - joeynmt.training - Epoch   7, Step:   161000, Batch Loss:     4.167296, Tokens per Sec:     3698, Lr: 0.000020
2022-01-22 21:12:48,070 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 21:13:21,474 - INFO - joeynmt.helpers - delete models/a_model/149000.ckpt
2022-01-22 21:13:21,505 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/149000.ckpt
2022-01-22 21:13:21,506 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/149000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/149000.ckpt')
2022-01-22 21:13:21,597 - INFO - joeynmt.training - Example #0
2022-01-22 21:13:21,597 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 21:13:21,597 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 21:13:21,597 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 21:13:21,598 - INFO - joeynmt.training - Example #1
2022-01-22 21:13:21,598 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 21:13:21,598 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 21:13:21,598 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 21:13:21,598 - INFO - joeynmt.training - Example #2
2022-01-22 21:13:21,598 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 21:13:21,598 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 21:13:21,598 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 21:13:21,599 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step   161000: bleu:  86.87, loss: 266469.6562, ppl:   1.1800, duration: 1775.3793s
2022-01-22 21:14:02,343 - INFO - joeynmt.training - Epoch   7, Step:   161100, Batch Loss:     2.482263, Tokens per Sec:     1657, Lr: 0.000020
2022-01-22 21:14:21,082 - INFO - joeynmt.training - Epoch   7, Step:   161200, Batch Loss:     2.901584, Tokens per Sec:     3691, Lr: 0.000020
2022-01-22 21:14:39,939 - INFO - joeynmt.training - Epoch   7, Step:   161300, Batch Loss:     4.643627, Tokens per Sec:     3540, Lr: 0.000020
2022-01-22 21:14:58,772 - INFO - joeynmt.training - Epoch   7, Step:   161400, Batch Loss:     2.032954, Tokens per Sec:     3500, Lr: 0.000020
2022-01-22 21:15:17,618 - INFO - joeynmt.training - Epoch   7, Step:   161500, Batch Loss:     3.061610, Tokens per Sec:     3508, Lr: 0.000020
2022-01-22 21:15:36,655 - INFO - joeynmt.training - Epoch   7, Step:   161600, Batch Loss:     3.405263, Tokens per Sec:     3573, Lr: 0.000020
2022-01-22 21:15:55,630 - INFO - joeynmt.training - Epoch   7, Step:   161700, Batch Loss:     3.060558, Tokens per Sec:     3582, Lr: 0.000020
2022-01-22 21:16:14,465 - INFO - joeynmt.training - Epoch   7, Step:   161800, Batch Loss:     4.001538, Tokens per Sec:     3458, Lr: 0.000020
2022-01-22 21:16:33,557 - INFO - joeynmt.training - Epoch   7, Step:   161900, Batch Loss:     3.761825, Tokens per Sec:     3614, Lr: 0.000020
2022-01-22 21:16:52,454 - INFO - joeynmt.training - Epoch   7, Step:   162000, Batch Loss:     2.873751, Tokens per Sec:     3651, Lr: 0.000020
2022-01-22 21:45:59,479 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 21:46:32,200 - INFO - joeynmt.helpers - delete models/a_model/161000.ckpt
2022-01-22 21:46:32,273 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/161000.ckpt
2022-01-22 21:46:32,274 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/161000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/161000.ckpt')
2022-01-22 21:46:32,308 - INFO - joeynmt.training - Example #0
2022-01-22 21:46:32,308 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 21:46:32,308 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 21:46:32,308 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-22 21:46:32,308 - INFO - joeynmt.training - Example #1
2022-01-22 21:46:32,308 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 21:46:32,308 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 21:46:32,308 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 21:46:32,309 - INFO - joeynmt.training - Example #2
2022-01-22 21:46:32,309 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 21:46:32,309 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 21:46:32,309 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 21:46:32,309 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step   162000: bleu:  87.02, loss: 264452.1875, ppl:   1.1785, duration: 1779.8550s
2022-01-22 21:46:51,286 - INFO - joeynmt.training - Epoch   7, Step:   162100, Batch Loss:     4.858526, Tokens per Sec:     3434, Lr: 0.000020
2022-01-22 21:47:31,434 - INFO - joeynmt.training - Epoch   7, Step:   162200, Batch Loss:     2.065973, Tokens per Sec:     1670, Lr: 0.000020
2022-01-22 21:47:50,388 - INFO - joeynmt.training - Epoch   7, Step:   162300, Batch Loss:     2.625285, Tokens per Sec:     3631, Lr: 0.000020
2022-01-22 21:48:09,325 - INFO - joeynmt.training - Epoch   7, Step:   162400, Batch Loss:     1.965276, Tokens per Sec:     3576, Lr: 0.000020
2022-01-22 21:48:28,179 - INFO - joeynmt.training - Epoch   7, Step:   162500, Batch Loss:     4.018865, Tokens per Sec:     3476, Lr: 0.000020
2022-01-22 21:48:47,274 - INFO - joeynmt.training - Epoch   7, Step:   162600, Batch Loss:     2.849877, Tokens per Sec:     3517, Lr: 0.000020
2022-01-22 21:49:06,298 - INFO - joeynmt.training - Epoch   7, Step:   162700, Batch Loss:     3.130818, Tokens per Sec:     3454, Lr: 0.000020
2022-01-22 21:49:25,413 - INFO - joeynmt.training - Epoch   7, Step:   162800, Batch Loss:     2.008096, Tokens per Sec:     3512, Lr: 0.000020
2022-01-22 21:49:44,128 - INFO - joeynmt.training - Epoch   7, Step:   162900, Batch Loss:     0.821163, Tokens per Sec:     3648, Lr: 0.000020
2022-01-22 21:50:03,020 - INFO - joeynmt.training - Epoch   7, Step:   163000, Batch Loss:     6.483541, Tokens per Sec:     3673, Lr: 0.000020
2022-01-22 22:14:44,322 - INFO - joeynmt.training - Example #0
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 22:14:44,323 - INFO - joeynmt.training - Example #1
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 22:14:44,323 - INFO - joeynmt.training - Example #2
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 22:14:44,323 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 22:14:44,324 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step   163000: bleu:  86.99, loss: 261398.4375, ppl:   1.1763, duration: 1481.3037s
2022-01-22 22:15:02,914 - INFO - joeynmt.training - Epoch   7, Step:   163100, Batch Loss:     2.086186, Tokens per Sec:     3616, Lr: 0.000020
2022-01-22 22:15:21,654 - INFO - joeynmt.training - Epoch   7, Step:   163200, Batch Loss:     3.457643, Tokens per Sec:     3456, Lr: 0.000020
2022-01-22 22:15:40,442 - INFO - joeynmt.training - Epoch   7, Step:   163300, Batch Loss:     5.605943, Tokens per Sec:     3667, Lr: 0.000020
2022-01-22 22:15:59,068 - INFO - joeynmt.training - Epoch   7, Step:   163400, Batch Loss:     2.339593, Tokens per Sec:     3681, Lr: 0.000020
2022-01-22 22:16:17,942 - INFO - joeynmt.training - Epoch   7, Step:   163500, Batch Loss:     1.875514, Tokens per Sec:     3626, Lr: 0.000020
2022-01-22 22:16:36,478 - INFO - joeynmt.training - Epoch   7, Step:   163600, Batch Loss:     2.770066, Tokens per Sec:     3609, Lr: 0.000020
2022-01-22 22:16:55,288 - INFO - joeynmt.training - Epoch   7, Step:   163700, Batch Loss:     3.063762, Tokens per Sec:     3578, Lr: 0.000020
2022-01-22 22:17:13,845 - INFO - joeynmt.training - Epoch   7, Step:   163800, Batch Loss:     2.165648, Tokens per Sec:     3658, Lr: 0.000020
2022-01-22 22:17:32,757 - INFO - joeynmt.training - Epoch   7, Step:   163900, Batch Loss:     5.985060, Tokens per Sec:     3563, Lr: 0.000020
2022-01-22 22:17:51,335 - INFO - joeynmt.training - Epoch   7, Step:   164000, Batch Loss:     1.524459, Tokens per Sec:     3640, Lr: 0.000020
2022-01-22 22:39:36,867 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 22:40:09,643 - INFO - joeynmt.helpers - delete models/a_model/162000.ckpt
2022-01-22 22:40:09,733 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/162000.ckpt
2022-01-22 22:40:09,733 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/162000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/162000.ckpt')
2022-01-22 22:40:09,820 - INFO - joeynmt.training - Example #0
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 22:40:09,820 - INFO - joeynmt.training - Example #1
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 22:40:09,820 - INFO - joeynmt.training - Example #2
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 22:40:09,820 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 22:40:09,821 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step   164000: bleu:  87.04, loss: 260614.9219, ppl:   1.1757, duration: 1338.4863s
2022-01-22 22:40:29,877 - INFO - joeynmt.training - Epoch   7, Step:   164100, Batch Loss:     2.312875, Tokens per Sec:     3383, Lr: 0.000020
2022-01-22 22:40:49,239 - INFO - joeynmt.training - Epoch   7, Step:   164200, Batch Loss:     2.146816, Tokens per Sec:     3581, Lr: 0.000020
2022-01-22 22:41:08,646 - INFO - joeynmt.training - Epoch   7, Step:   164300, Batch Loss:     2.651257, Tokens per Sec:     3421, Lr: 0.000020
2022-01-22 22:41:28,530 - INFO - joeynmt.training - Epoch   7, Step:   164400, Batch Loss:     1.707594, Tokens per Sec:     3424, Lr: 0.000020
2022-01-22 22:41:48,172 - INFO - joeynmt.training - Epoch   7, Step:   164500, Batch Loss:     1.435633, Tokens per Sec:     3496, Lr: 0.000020
2022-01-22 22:42:07,784 - INFO - joeynmt.training - Epoch   7, Step:   164600, Batch Loss:     2.174484, Tokens per Sec:     3474, Lr: 0.000020
2022-01-22 22:42:27,334 - INFO - joeynmt.training - Epoch   7, Step:   164700, Batch Loss:     1.493145, Tokens per Sec:     3428, Lr: 0.000020
2022-01-22 22:42:46,923 - INFO - joeynmt.training - Epoch   7, Step:   164800, Batch Loss:     3.364430, Tokens per Sec:     3481, Lr: 0.000020
2022-01-22 22:43:06,534 - INFO - joeynmt.training - Epoch   7, Step:   164900, Batch Loss:     2.608535, Tokens per Sec:     3402, Lr: 0.000020
2022-01-22 22:43:25,559 - INFO - joeynmt.training - Epoch   7, Step:   165000, Batch Loss:     2.325519, Tokens per Sec:     3457, Lr: 0.000020
2022-01-22 23:05:08,143 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 23:05:40,850 - INFO - joeynmt.helpers - delete models/a_model/164000.ckpt
2022-01-22 23:05:40,939 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/164000.ckpt
2022-01-22 23:05:40,940 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/164000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/164000.ckpt')
2022-01-22 23:05:41,048 - INFO - joeynmt.training - Example #0
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-22 23:05:41,048 - INFO - joeynmt.training - Example #1
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 23:05:41,048 - INFO - joeynmt.training - Example #2
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 23:05:41,048 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 23:05:41,049 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step   165000: bleu:  87.06, loss: 258986.7500, ppl:   1.1745, duration: 1335.4896s
2022-01-22 23:06:00,078 - INFO - joeynmt.training - Epoch   7, Step:   165100, Batch Loss:     2.531728, Tokens per Sec:     3511, Lr: 0.000020
2022-01-22 23:06:19,044 - INFO - joeynmt.training - Epoch   7, Step:   165200, Batch Loss:     3.031660, Tokens per Sec:     3686, Lr: 0.000020
2022-01-22 23:06:37,735 - INFO - joeynmt.training - Epoch   7, Step:   165300, Batch Loss:     3.010149, Tokens per Sec:     3672, Lr: 0.000020
2022-01-22 23:06:56,693 - INFO - joeynmt.training - Epoch   7, Step:   165400, Batch Loss:     2.418586, Tokens per Sec:     3599, Lr: 0.000020
2022-01-22 23:07:15,648 - INFO - joeynmt.training - Epoch   7, Step:   165500, Batch Loss:     5.276330, Tokens per Sec:     3440, Lr: 0.000020
2022-01-22 23:07:34,506 - INFO - joeynmt.training - Epoch   7, Step:   165600, Batch Loss:     4.075603, Tokens per Sec:     3581, Lr: 0.000020
2022-01-22 23:07:53,325 - INFO - joeynmt.training - Epoch   7, Step:   165700, Batch Loss:     2.278987, Tokens per Sec:     3555, Lr: 0.000020
2022-01-22 23:08:12,224 - INFO - joeynmt.training - Epoch   7, Step:   165800, Batch Loss:     3.040344, Tokens per Sec:     3580, Lr: 0.000020
2022-01-22 23:08:31,240 - INFO - joeynmt.training - Epoch   7, Step:   165900, Batch Loss:     2.196743, Tokens per Sec:     3637, Lr: 0.000020
2022-01-22 23:08:50,317 - INFO - joeynmt.training - Epoch   7, Step:   166000, Batch Loss:     1.727549, Tokens per Sec:     3500, Lr: 0.000020
2022-01-22 23:30:32,876 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-22 23:31:09,868 - INFO - joeynmt.helpers - delete models/a_model/165000.ckpt
2022-01-22 23:31:09,955 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/a_model/165000.ckpt
2022-01-22 23:31:09,956 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/a_model/165000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/a_model/165000.ckpt')
2022-01-22 23:31:10,049 - INFO - joeynmt.training - Example #0
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 33 12 | 25 5 | 37 17 | 8 13
2022-01-22 23:31:10,050 - INFO - joeynmt.training - Example #1
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Source:     ( 40 / 1 :6 ( 26 / 22 :6 ( 37 / 28 :20 ( 9 / 14 :25 ( 21 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 38 / 32 :6 ( 33 / 39 :29 ( 35 / 5 ) ) ) :6-of ( 23 / 17 ) ) ) ) SEP ( 31 / 1 :6 ( 10 / 22 :6 ( 0 / 28 :20 ( 18 / 14 :25 ( 3 / 25 :16 30 :2 27 :4 19 ) :24 12 ) :6 ( 8 / 32 :6 ( 7 / 39 :29 ( 15 / 5 ) ) ) :6-of ( 34 / 17 ) ) ) )
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Reference:  40 31 | 26 10 | 37 0 | 23 34 | 9 18 | 21 3 | 38 8 | 33 7 | 35 15
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Hypothesis: 40 31 | 26 10 | 37 0 | 9 18 | 21 3 | 23 34 | 38 8 | 33 7 | 35 15
2022-01-22 23:31:10,050 - INFO - joeynmt.training - Example #2
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Source:     ( 37 / 17 :3 ( 2 / 11 :3 ( 10 / 35 :13 ( 23 / 40 :19 ( 9 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 32 / 22 :3 ( 0 / 34 :24 ( 18 / 21 ) ) ) :3-of ( 30 / 29 ) ) ) ) SEP ( 39 / 17 :3 ( 14 / 11 :3 ( 7 / 35 :13 ( 27 / 40 :19 ( 25 / 19 :16 36 :8 4 :15 1 ) :26 12 ) :3 ( 33 / 22 :3 ( 5 / 34 :24 ( 6 / 21 ) ) ) :3-of ( 28 / 29 ) ) ) )
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Reference:  37 39 | 2 14 | 10 7 | 30 28 | 23 27 | 9 25 | 32 33 | 0 5 | 18 6
2022-01-22 23:31:10,050 - INFO - joeynmt.training - 	Hypothesis: 37 39 | 2 14 | 10 7 | 23 27 | 9 25 | 30 28 | 32 33 | 0 5 | 18 6
2022-01-22 23:31:10,051 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step   166000: bleu:  87.12, loss: 258900.6562, ppl:   1.1744, duration: 1339.7340s
2022-01-22 23:31:29,094 - INFO - joeynmt.training - Epoch   7, Step:   166100, Batch Loss:     2.777166, Tokens per Sec:     3457, Lr: 0.000020
2022-01-22 23:31:47,867 - INFO - joeynmt.training - Epoch   7, Step:   166200, Batch Loss:     1.498827, Tokens per Sec:     3462, Lr: 0.000020
2022-01-22 23:32:06,677 - INFO - joeynmt.training - Epoch   7, Step:   166300, Batch Loss:     4.794467, Tokens per Sec:     3591, Lr: 0.000020
2022-01-22 23:32:25,344 - INFO - joeynmt.training - Epoch   7, Step:   166400, Batch Loss:     2.674478, Tokens per Sec:     3619, Lr: 0.000020
2022-01-22 23:32:43,993 - INFO - joeynmt.training - Epoch   7, Step:   166500, Batch Loss:     3.838034, Tokens per Sec:     3669, Lr: 0.000020
2022-01-22 23:33:02,746 - INFO - joeynmt.training - Epoch   7, Step:   166600, Batch Loss:     2.519508, Tokens per Sec:     3563, Lr: 0.000020
2022-01-22 23:33:21,759 - INFO - joeynmt.training - Epoch   7, Step:   166700, Batch Loss:     3.162756, Tokens per Sec:     3530, Lr: 0.000020
2022-01-22 23:33:40,665 - INFO - joeynmt.training - Epoch   7, Step:   166800, Batch Loss:     2.134097, Tokens per Sec:     3621, Lr: 0.000020
2022-01-22 23:33:59,265 - INFO - joeynmt.training - Epoch   7, Step:   166900, Batch Loss:     2.275637, Tokens per Sec:     3695, Lr: 0.000020
2022-01-22 23:34:18,095 - INFO - joeynmt.training - Epoch   7, Step:   167000, Batch Loss:     1.857549, Tokens per Sec:     3576, Lr: 0.000020
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd-gpu08: error: *** JOB 1182 ON gpu08 CANCELLED AT 2022-01-22T23:41:09 DUE TO TIME LIMIT ***
slurmstepd-gpu08: error: *** STEP 1182.0 ON gpu08 CANCELLED AT 2022-01-22T23:41:09 DUE TO TIME LIMIT ***
srun: got SIGCONT
srun: forcing job termination
srun: error: gpu08: task 0: Terminated
