Matplotlib created a temporary config/cache directory at /tmp/matplotlib-pyzd5xfg because the default path (/home/students/meier/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
2022-01-18 08:52:58,887 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2022-01-18 08:52:58,976 - INFO - joeynmt.data - Loading training data...
2022-01-18 08:53:01,890 - INFO - joeynmt.data - Building vocabulary...
2022-01-18 08:53:02,868 - INFO - joeynmt.data - Loading dev data...
2022-01-18 08:53:03,136 - INFO - joeynmt.data - Loading test data...
2022-01-18 08:53:03,183 - INFO - joeynmt.data - Data loaded.
2022-01-18 08:53:03,183 - INFO - joeynmt.model - Building an encoder-decoder model...
2022-01-18 08:53:03,636 - INFO - joeynmt.model - Enc-dec model built.
2022-01-18 08:53:03,644 - INFO - joeynmt.training - Total params: 29873664
2022-01-18 08:53:03,646 - WARNING - joeynmt.training - `keep_last_ckpts` option is outdated. Please use `keep_best_ckpts`, instead.
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.name                           : amr_Transformer_short_800_B
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.data.src                       : src
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.data.trg                       : tgt
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.data.train                     : ~/AMR_ablation/data/B_data/train/b_train
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.data.dev                       : ~/AMR_ablation/data/B_data/dev/b_dev
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.data.test                      : ~/AMR_ablation/data/B_data/test/b_test
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.data.level                     : word
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 800
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2022-01-18 08:53:07,047 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0002
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 2
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 5000
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.batch_size            : 8192
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.batch_type            : token
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.epochs                : 30
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/B_ablation
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2022-01-18 08:53:07,048 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2]
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 1
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : False
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 4
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 4
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.0
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048
2022-01-18 08:53:07,049 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.1
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 4
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 4
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.0
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.1
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - Data set sizes: 
	train 54223,
	valid 3500,
	test 1500
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - First training example:
	[SRC] ( 28 / 5 :8 ( 10 / 30 :14 ( 29 / 21 ) :26 ( 9 / 13 :12 ( 22 / 12 :8 23 ) :18 17 :27 1 ) ) :0 ( 17 / 15 :14 29 ) ) SEP ( 24 / 5 :8 ( 19 / 30 :14 ( 7 / 21 ) :26 ( 3 / 2 :12 ( 4 / 12 :8 23 ) :27 1 ) ) :0 ( 25 / 15 :14 7 :26 3 ) )
	[TRG] 28 24 | 10 19 | 29 7 | 9 3 | 22 4 | 17 25
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ( (5) ) (6) / (7) 2 (8) 4 (9) SEP
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) | (5) None (6) 2 (7) 0 (8) 7 (9) 4
2022-01-18 08:53:07,050 - INFO - joeynmt.helpers - Number of Src words (types): 644
2022-01-18 08:53:07,051 - INFO - joeynmt.helpers - Number of Trg words (types): 227
2022-01-18 08:53:07,051 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=4),
	decoder=TransformerDecoder(num_layers=4, num_heads=4),
	src_embed=Embeddings(embedding_dim=512, vocab_size=644),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=227))
2022-01-18 08:53:07,056 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 8192
	total batch size (w. parallel & accumulation): 8192
2022-01-18 08:53:07,056 - INFO - joeynmt.training - EPOCH 1
2022-01-18 08:53:26,140 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:   105.268753, Tokens per Sec:     3560, Lr: 0.000200
2022-01-18 08:53:45,119 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:    78.817223, Tokens per Sec:     3653, Lr: 0.000200
2022-01-18 08:54:03,948 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:   125.564819, Tokens per Sec:     3741, Lr: 0.000200
2022-01-18 08:54:22,772 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:    89.248558, Tokens per Sec:     3637, Lr: 0.000200
2022-01-18 08:54:41,558 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:   119.505974, Tokens per Sec:     3481, Lr: 0.000200
2022-01-18 08:55:00,350 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:    88.239380, Tokens per Sec:     3624, Lr: 0.000200
2022-01-18 08:55:19,024 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:    76.003387, Tokens per Sec:     3615, Lr: 0.000200
2022-01-18 08:55:37,704 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:    75.527504, Tokens per Sec:     3620, Lr: 0.000200
2022-01-18 08:55:56,558 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:    95.143486, Tokens per Sec:     3520, Lr: 0.000200
2022-01-18 08:56:15,194 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:    94.205101, Tokens per Sec:     3563, Lr: 0.000200
2022-01-18 09:00:36,185 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 09:01:08,998 - INFO - joeynmt.training - Example #0
2022-01-18 09:01:08,998 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 09:01:08,998 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 09:01:08,998 - INFO - joeynmt.training - 	Hypothesis: 33 33 | 35 35 | 29 29 | 35 35 | 35 35 | 35 35 | 35 None | 33 None | 33 None
2022-01-18 09:01:08,998 - INFO - joeynmt.training - Example #1
2022-01-18 09:01:08,998 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 09:01:08,998 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 09:01:08,998 - INFO - joeynmt.training - 	Hypothesis: 61 61 | 32 32 | 61 61 | 32 32 | 32 32 | 32 32 | 32 32 | 32 32 | 32 None | 32 None | 32 None | 32 None | 32 None | 32 None | 32 None | 32 None | 32 None | 59 | 59 | 59
2022-01-18 09:01:08,999 - INFO - joeynmt.training - Example #2
2022-01-18 09:01:08,999 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 09:01:08,999 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 09:01:08,999 - INFO - joeynmt.training - 	Hypothesis: 21 21 | 21 21 21 21 21 | 21 21 | 21 21 | 32 None | 21 None | 21 None | 21 None | 33 None | 33 None
2022-01-18 09:01:08,999 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     1000: bleu:   1.04, loss: 432867.0938, ppl:  14.7066, duration: 293.8040s
2022-01-18 09:01:27,495 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:    70.718834, Tokens per Sec:     3708, Lr: 0.000200
2022-01-18 09:01:45,758 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:    82.285919, Tokens per Sec:     3705, Lr: 0.000200
2022-01-18 09:02:04,499 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:    67.685547, Tokens per Sec:     3597, Lr: 0.000200
2022-01-18 09:02:23,363 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:    64.649574, Tokens per Sec:     3496, Lr: 0.000200
2022-01-18 09:02:41,670 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:    75.381340, Tokens per Sec:     3704, Lr: 0.000200
2022-01-18 09:03:00,155 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:   104.963173, Tokens per Sec:     3674, Lr: 0.000200
2022-01-18 09:03:18,710 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:   100.605736, Tokens per Sec:     3623, Lr: 0.000200
2022-01-18 09:03:36,991 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:    78.142891, Tokens per Sec:     3624, Lr: 0.000200
2022-01-18 09:03:55,510 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:    54.973988, Tokens per Sec:     3563, Lr: 0.000200
2022-01-18 09:04:13,608 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:    79.475693, Tokens per Sec:     3648, Lr: 0.000200
2022-01-18 09:08:32,676 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 09:09:05,456 - INFO - joeynmt.helpers - delete models/B_ablation/1000.ckpt
2022-01-18 09:09:05,537 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/1000.ckpt
2022-01-18 09:09:05,538 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/1000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/1000.ckpt')
2022-01-18 09:09:05,567 - INFO - joeynmt.training - Example #0
2022-01-18 09:09:05,567 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 09:09:05,568 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 09:09:05,568 - INFO - joeynmt.training - 	Hypothesis: 36 36 | 36 36 | 36 36 | 36 36 | 36 36 | 36 36 | 36 36 | 36 36 | 36 None | 36 None
2022-01-18 09:09:05,568 - INFO - joeynmt.training - Example #1
2022-01-18 09:09:05,568 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 09:09:05,568 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 09:09:05,568 - INFO - joeynmt.training - 	Hypothesis: 61 None | 61 None | 61 None | 61 None | 61 None | 61 None | 61 None | 61 None | 61 None | 61 None | 61 None | 61 None | 61 None | 63 None | 63 None | 63 None | 63 None | 63 None | 12 None
2022-01-18 09:09:05,568 - INFO - joeynmt.training - Example #2
2022-01-18 09:09:05,568 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 09:09:05,568 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 09:09:05,568 - INFO - joeynmt.training - 	Hypothesis: 12 None | 40 40 | 40 40 | 40 None | 40 None | 40 None | 40 None | 40 None | 40 None | 40 None | 40 None | 12 None
2022-01-18 09:09:05,568 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     2000: bleu:   1.42, loss: 419357.6250, ppl:  13.5231, duration: 291.9598s
2022-01-18 09:09:24,226 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:   123.877525, Tokens per Sec:     3554, Lr: 0.000200
2022-01-18 09:09:42,035 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:    71.619629, Tokens per Sec:     3778, Lr: 0.000200
2022-01-18 09:10:00,001 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:    82.393532, Tokens per Sec:     3811, Lr: 0.000200
2022-01-18 09:10:18,038 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:    75.592361, Tokens per Sec:     3646, Lr: 0.000200
2022-01-18 09:10:36,589 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:    95.809494, Tokens per Sec:     3702, Lr: 0.000200
2022-01-18 09:10:54,883 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:    88.330856, Tokens per Sec:     3745, Lr: 0.000200
2022-01-18 09:11:05,680 - INFO - joeynmt.training - Epoch   1: total training loss 230952.53
2022-01-18 09:11:05,680 - INFO - joeynmt.training - EPOCH 2
2022-01-18 09:11:13,070 - INFO - joeynmt.training - Epoch   2, Step:     2700, Batch Loss:   115.290352, Tokens per Sec:     3745, Lr: 0.000200
2022-01-18 09:11:31,159 - INFO - joeynmt.training - Epoch   2, Step:     2800, Batch Loss:    80.023018, Tokens per Sec:     3621, Lr: 0.000200
2022-01-18 09:11:49,327 - INFO - joeynmt.training - Epoch   2, Step:     2900, Batch Loss:    76.433128, Tokens per Sec:     3768, Lr: 0.000200
2022-01-18 09:12:07,618 - INFO - joeynmt.training - Epoch   2, Step:     3000, Batch Loss:    89.465401, Tokens per Sec:     3548, Lr: 0.000200
2022-01-18 09:16:20,483 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 09:16:53,205 - INFO - joeynmt.helpers - delete models/B_ablation/2000.ckpt
2022-01-18 09:16:53,285 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/2000.ckpt
2022-01-18 09:16:53,286 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/2000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/2000.ckpt')
2022-01-18 09:16:53,307 - INFO - joeynmt.training - Example #0
2022-01-18 09:16:53,307 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 09:16:53,307 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 09:16:53,307 - INFO - joeynmt.training - 	Hypothesis: 34 None | 34 None | 33 None | 34 None | 40 None | 34 None | 40 None | 40 None | 40 None
2022-01-18 09:16:53,307 - INFO - joeynmt.training - Example #1
2022-01-18 09:16:53,308 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 09:16:53,308 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 09:16:53,308 - INFO - joeynmt.training - 	Hypothesis: 15 None | 3 None | 38 None | 38 None | 38 None | 38 None | 38 None | 38 None | 38 None | 38 None | 3 None | 3 None | 38 None | 38 None | 13 None | 38 None | 13 None | 40 None
2022-01-18 09:16:53,308 - INFO - joeynmt.training - Example #2
2022-01-18 09:16:53,308 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 09:16:53,308 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 09:16:53,308 - INFO - joeynmt.training - 	Hypothesis: 8 40 | 18 40 | 18 None | 18 None | 18 None | 18 None | 18 None | 18 None | 18 None | 1 None | 1 None
2022-01-18 09:16:53,308 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     3000: bleu:   1.69, loss: 409160.3750, ppl:  12.6932, duration: 285.6894s
2022-01-18 09:17:11,574 - INFO - joeynmt.training - Epoch   2, Step:     3100, Batch Loss:    70.166817, Tokens per Sec:     3745, Lr: 0.000200
2022-01-18 09:17:30,083 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:   110.702965, Tokens per Sec:     3626, Lr: 0.000200
2022-01-18 09:17:48,332 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:    76.994034, Tokens per Sec:     3615, Lr: 0.000200
2022-01-18 09:18:06,540 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:   104.218010, Tokens per Sec:     3715, Lr: 0.000200
2022-01-18 09:18:24,583 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:    71.975182, Tokens per Sec:     3599, Lr: 0.000200
2022-01-18 09:18:42,837 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:    68.609253, Tokens per Sec:     3651, Lr: 0.000200
2022-01-18 09:19:01,281 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:    58.368176, Tokens per Sec:     3910, Lr: 0.000200
2022-01-18 09:19:19,185 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:    55.260311, Tokens per Sec:     3794, Lr: 0.000200
2022-01-18 09:19:37,354 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:    77.663063, Tokens per Sec:     3701, Lr: 0.000200
2022-01-18 09:19:55,695 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:    70.397682, Tokens per Sec:     3689, Lr: 0.000200
2022-01-18 09:24:02,830 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 09:24:35,608 - INFO - joeynmt.helpers - delete models/B_ablation/3000.ckpt
2022-01-18 09:24:35,684 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/3000.ckpt
2022-01-18 09:24:35,684 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/3000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/3000.ckpt')
2022-01-18 09:24:35,715 - INFO - joeynmt.training - Example #0
2022-01-18 09:24:35,715 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 09:24:35,715 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 09:24:35,715 - INFO - joeynmt.training - 	Hypothesis: 34 4 | 32 3 | 31 30 | 31 30 | 18 17 | 37 30 | 37 30 | 37 30 | 37 None
2022-01-18 09:24:35,716 - INFO - joeynmt.training - Example #1
2022-01-18 09:24:35,716 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 09:24:35,716 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 09:24:35,716 - INFO - joeynmt.training - 	Hypothesis: 13 None | 35 None | 65 None | 32 None | 32 None | 17 None | 38 None | 38 None | 38 None | 38 None | 40 None | 40 None | 40 None | 40 None | 40 None | 40 None | 40 None | 40 None
2022-01-18 09:24:35,716 - INFO - joeynmt.training - Example #2
2022-01-18 09:24:35,716 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 09:24:35,716 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 09:24:35,716 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 40 | 50 40 | 37 40 | 37 40 | 11 40 | 6 None | 22 None | 22 None | 22 None | 27 None
2022-01-18 09:24:35,716 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     4000: bleu:   5.08, loss: 374383.5625, ppl:  10.2276, duration: 280.0211s
2022-01-18 09:24:54,564 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:    77.606323, Tokens per Sec:     3578, Lr: 0.000200
2022-01-18 09:25:12,689 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:    62.265900, Tokens per Sec:     3734, Lr: 0.000200
2022-01-18 09:25:31,281 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:    92.412437, Tokens per Sec:     3684, Lr: 0.000200
2022-01-18 09:25:49,821 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:    71.401237, Tokens per Sec:     3625, Lr: 0.000200
2022-01-18 09:26:08,344 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:    66.241066, Tokens per Sec:     3497, Lr: 0.000200
2022-01-18 09:26:27,037 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:    46.473740, Tokens per Sec:     3544, Lr: 0.000200
2022-01-18 09:26:45,684 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:    62.387569, Tokens per Sec:     3655, Lr: 0.000200
2022-01-18 09:27:04,939 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:    62.525101, Tokens per Sec:     3555, Lr: 0.000200
2022-01-18 09:27:23,657 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:    65.118179, Tokens per Sec:     3470, Lr: 0.000200
2022-01-18 09:27:42,105 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:    63.854946, Tokens per Sec:     3645, Lr: 0.000200
2022-01-18 09:31:41,896 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 09:32:14,674 - INFO - joeynmt.helpers - delete models/B_ablation/4000.ckpt
2022-01-18 09:32:14,753 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/4000.ckpt
2022-01-18 09:32:14,754 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/4000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/4000.ckpt')
2022-01-18 09:32:14,793 - INFO - joeynmt.training - Example #0
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Hypothesis: 34 36 | 32 36 | 31 36 | 35 36 | 25 17 | 25 7 | 37 17 | 8 None | 8 None
2022-01-18 09:32:14,794 - INFO - joeynmt.training - Example #1
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Hypothesis: 13 None | 35 None | 65 65 | 32 None | 12 None | 8 None | 17 None | 20 69 | 19 None | 19 None | 14 None | 14 None | 16 None | 16 None | 16 None | 36 None | 36 None
2022-01-18 09:32:14,794 - INFO - joeynmt.training - Example #2
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 09:32:14,794 - INFO - joeynmt.training - 	Hypothesis: 8 6 | 23 6 | 50 48 | 37 48 | 4 6 | 11 48 | 21 45 | 39 45 | 39 45 | 22 45
2022-01-18 09:32:14,794 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     5000: bleu:   9.95, loss: 340207.9062, ppl:   8.2717, duration: 272.6890s
2022-01-18 09:32:33,349 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:    60.050941, Tokens per Sec:     3605, Lr: 0.000200
2022-01-18 09:32:52,209 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:    45.382061, Tokens per Sec:     3707, Lr: 0.000200
2022-01-18 09:33:10,808 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:    70.711098, Tokens per Sec:     3620, Lr: 0.000200
2022-01-18 09:33:15,342 - INFO - joeynmt.training - Epoch   2: total training loss 192273.69
2022-01-18 09:33:15,342 - INFO - joeynmt.training - EPOCH 3
2022-01-18 09:33:28,988 - INFO - joeynmt.training - Epoch   3, Step:     5400, Batch Loss:    69.944717, Tokens per Sec:     3720, Lr: 0.000200
2022-01-18 09:33:47,786 - INFO - joeynmt.training - Epoch   3, Step:     5500, Batch Loss:    59.329037, Tokens per Sec:     3532, Lr: 0.000200
2022-01-18 09:34:06,379 - INFO - joeynmt.training - Epoch   3, Step:     5600, Batch Loss:   102.042992, Tokens per Sec:     3592, Lr: 0.000200
2022-01-18 09:34:24,843 - INFO - joeynmt.training - Epoch   3, Step:     5700, Batch Loss:    49.059456, Tokens per Sec:     3621, Lr: 0.000200
2022-01-18 09:34:43,692 - INFO - joeynmt.training - Epoch   3, Step:     5800, Batch Loss:    23.307056, Tokens per Sec:     3459, Lr: 0.000200
2022-01-18 09:35:02,113 - INFO - joeynmt.training - Epoch   3, Step:     5900, Batch Loss:    63.346996, Tokens per Sec:     3564, Lr: 0.000200
2022-01-18 09:35:20,422 - INFO - joeynmt.training - Epoch   3, Step:     6000, Batch Loss:    62.920235, Tokens per Sec:     3685, Lr: 0.000200
2022-01-18 09:39:25,676 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 09:39:58,505 - INFO - joeynmt.helpers - delete models/B_ablation/5000.ckpt
2022-01-18 09:39:58,585 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/5000.ckpt
2022-01-18 09:39:58,586 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/5000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/5000.ckpt')
2022-01-18 09:39:58,606 - INFO - joeynmt.training - Example #0
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 36 | 31 36 | 2 36 | 20 30 | 25 17 | 25 12 | 8 12 | 33 12
2022-01-18 09:39:58,607 - INFO - joeynmt.training - Example #1
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Hypothesis: 13 7 | 35 0 | 65 1 | 32 1 | 12 1 | 8 41 | 29 1 | 17 1 | 19 1 | 19 1 | 14 1 | 56 1 | 56 1 | 14 1 | 30 46 | 30 7 | 30 1 | 30 6
2022-01-18 09:39:58,607 - INFO - joeynmt.training - Example #2
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 09:39:58,607 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 24 | 50 5 | 37 5 | 4 6 | 11 30 | 21 30 | 21 30 | 22 16 | 22 30 | 19 30
2022-01-18 09:39:58,607 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     6000: bleu:  12.88, loss: 313522.8750, ppl:   7.0085, duration: 278.1848s
2022-01-18 09:40:17,507 - INFO - joeynmt.training - Epoch   3, Step:     6100, Batch Loss:    46.598747, Tokens per Sec:     3618, Lr: 0.000200
2022-01-18 09:40:36,291 - INFO - joeynmt.training - Epoch   3, Step:     6200, Batch Loss:    46.827534, Tokens per Sec:     3627, Lr: 0.000200
2022-01-18 09:40:54,745 - INFO - joeynmt.training - Epoch   3, Step:     6300, Batch Loss:    64.050247, Tokens per Sec:     3660, Lr: 0.000200
2022-01-18 09:41:13,229 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:    59.409180, Tokens per Sec:     3665, Lr: 0.000200
2022-01-18 09:41:32,124 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:    46.283600, Tokens per Sec:     3622, Lr: 0.000200
2022-01-18 09:41:50,412 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:    64.633812, Tokens per Sec:     3678, Lr: 0.000200
2022-01-18 09:42:08,855 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:    57.813278, Tokens per Sec:     3704, Lr: 0.000200
2022-01-18 09:42:27,168 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:    53.878525, Tokens per Sec:     3632, Lr: 0.000200
2022-01-18 09:42:45,619 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:    59.331482, Tokens per Sec:     3691, Lr: 0.000200
2022-01-18 09:43:03,972 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:    48.239437, Tokens per Sec:     3735, Lr: 0.000200
2022-01-18 09:47:16,567 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 09:47:49,354 - INFO - joeynmt.helpers - delete models/B_ablation/6000.ckpt
2022-01-18 09:47:49,432 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/6000.ckpt
2022-01-18 09:47:49,433 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/6000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/6000.ckpt')
2022-01-18 09:47:49,461 - INFO - joeynmt.training - Example #0
2022-01-18 09:47:49,461 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 09:47:49,462 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 09:47:49,462 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 24 | 31 36 | 2 36 | 31 36 | 25 36 | 37 12 | 8 17 | 8 5 | 33 5
2022-01-18 09:47:49,462 - INFO - joeynmt.training - Example #1
2022-01-18 09:47:49,462 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 09:47:49,462 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 09:47:49,462 - INFO - joeynmt.training - 	Hypothesis: 13 1 | 35 46 | 65 46 | 32 46 | 12 46 | 17 41 | 21 46 | 20 41 | 19 41 | 19 6 | 14 41 | 56 46 | 56 46 | 16 41 | 36 46 | 36 6 | 36 46 | 26 None
2022-01-18 09:47:49,462 - INFO - joeynmt.training - Example #2
2022-01-18 09:47:49,462 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 09:47:49,462 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 09:47:49,462 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 24 | 50 6 | 18 48 | 4 48 | 11 48 | 21 6 | 39 40 | 39 40 | 22 48 | 19 45
2022-01-18 09:47:49,462 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     7000: bleu:  14.18, loss: 303200.5625, ppl:   6.5733, duration: 285.4895s
2022-01-18 09:48:07,863 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:    52.292015, Tokens per Sec:     3642, Lr: 0.000200
2022-01-18 09:48:26,474 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:    48.349369, Tokens per Sec:     3537, Lr: 0.000200
2022-01-18 09:48:45,104 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:    65.014381, Tokens per Sec:     3643, Lr: 0.000200
2022-01-18 09:49:03,482 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:    64.247299, Tokens per Sec:     3704, Lr: 0.000200
2022-01-18 09:49:21,855 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:    53.300190, Tokens per Sec:     3691, Lr: 0.000200
2022-01-18 09:49:40,455 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:    52.841351, Tokens per Sec:     3599, Lr: 0.000200
2022-01-18 09:49:58,919 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:    69.845306, Tokens per Sec:     3731, Lr: 0.000200
2022-01-18 09:50:17,472 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:    53.134369, Tokens per Sec:     3589, Lr: 0.000200
2022-01-18 09:50:35,863 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:    28.069544, Tokens per Sec:     3707, Lr: 0.000200
2022-01-18 09:50:51,476 - INFO - joeynmt.training - Epoch   3: total training loss 151855.78
2022-01-18 09:50:51,476 - INFO - joeynmt.training - EPOCH 4
2022-01-18 09:50:53,898 - INFO - joeynmt.training - Epoch   4, Step:     8000, Batch Loss:    47.142620, Tokens per Sec:     3544, Lr: 0.000200
2022-01-18 09:55:05,016 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 09:55:37,853 - INFO - joeynmt.helpers - delete models/B_ablation/7000.ckpt
2022-01-18 09:55:37,928 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/7000.ckpt
2022-01-18 09:55:37,929 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/7000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/7000.ckpt')
2022-01-18 09:55:37,950 - INFO - joeynmt.training - Example #0
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 24 | 31 36 | 35 7 | 2 5 | 25 17 | 37 13 | 8 12
2022-01-18 09:55:37,951 - INFO - joeynmt.training - Example #1
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Hypothesis: 13 26 | 35 33 | 65 37 | 32 1 | 12 37 | 8 6 | 21 37 | 20 74 | 17 37 | 19 23 | 19 23 | 14 41 | 56 10 | 22 6 | 56 23 | 36 37 | 36 23 | 30 6 | 26 None
2022-01-18 09:55:37,951 - INFO - joeynmt.training - Example #2
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 09:55:37,951 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 24 | 50 6 | 18 5 | 4 2 | 11 48 | 21 40 | 39 16 | 22 45 | 22 40 | 19 16
2022-01-18 09:55:37,951 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     8000: bleu:  15.75, loss: 293676.7812, ppl:   6.1958, duration: 284.0524s
2022-01-18 09:55:56,077 - INFO - joeynmt.training - Epoch   4, Step:     8100, Batch Loss:    49.057884, Tokens per Sec:     3715, Lr: 0.000200
2022-01-18 09:56:14,449 - INFO - joeynmt.training - Epoch   4, Step:     8200, Batch Loss:    66.270752, Tokens per Sec:     3593, Lr: 0.000200
2022-01-18 09:56:32,962 - INFO - joeynmt.training - Epoch   4, Step:     8300, Batch Loss:    43.039295, Tokens per Sec:     3595, Lr: 0.000200
2022-01-18 09:56:51,359 - INFO - joeynmt.training - Epoch   4, Step:     8400, Batch Loss:    48.844189, Tokens per Sec:     3603, Lr: 0.000200
2022-01-18 09:57:09,823 - INFO - joeynmt.training - Epoch   4, Step:     8500, Batch Loss:    48.171429, Tokens per Sec:     3626, Lr: 0.000200
2022-01-18 09:57:28,127 - INFO - joeynmt.training - Epoch   4, Step:     8600, Batch Loss:    63.211723, Tokens per Sec:     3759, Lr: 0.000200
2022-01-18 09:57:46,474 - INFO - joeynmt.training - Epoch   4, Step:     8700, Batch Loss:    43.331882, Tokens per Sec:     3575, Lr: 0.000200
2022-01-18 09:58:04,882 - INFO - joeynmt.training - Epoch   4, Step:     8800, Batch Loss:    54.539803, Tokens per Sec:     3687, Lr: 0.000200
2022-01-18 09:58:23,287 - INFO - joeynmt.training - Epoch   4, Step:     8900, Batch Loss:    37.982605, Tokens per Sec:     3709, Lr: 0.000200
2022-01-18 09:58:41,605 - INFO - joeynmt.training - Epoch   4, Step:     9000, Batch Loss:    48.238182, Tokens per Sec:     3631, Lr: 0.000200
2022-01-18 10:02:49,753 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 10:03:22,531 - INFO - joeynmt.helpers - delete models/B_ablation/8000.ckpt
2022-01-18 10:03:22,609 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/8000.ckpt
2022-01-18 10:03:22,610 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/8000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/8000.ckpt')
2022-01-18 10:03:22,631 - INFO - joeynmt.training - Example #0
2022-01-18 10:03:22,632 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 10:03:22,632 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 10:03:22,632 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 36 | 31 30 | 35 36 | 2 12 | 25 17 | 37 13 | 8 5 | 33 17
2022-01-18 10:03:22,632 - INFO - joeynmt.training - Example #1
2022-01-18 10:03:22,632 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 10:03:22,632 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 10:03:22,632 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 10 | 65 1 | 32 37 | 8 50 | 12 7 | 21 6 | 20 50 | 71 51 | 19 23 | 14 51 | 56 37 | 56 10 | 22 37 | 36 51 | 22 1 | 36 23 | 26 None | 30 None
2022-01-18 10:03:22,632 - INFO - joeynmt.training - Example #2
2022-01-18 10:03:22,632 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 10:03:22,632 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 10:03:22,633 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 24 | 50 48 | 37 48 | 4 6 | 11 5 | 21 45 | 42 16 | 39 48 | 22 45 | 19 30
2022-01-18 10:03:22,633 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     9000: bleu:  16.67, loss: 282457.0938, ppl:   5.7787, duration: 281.0269s
2022-01-18 10:03:41,109 - INFO - joeynmt.training - Epoch   4, Step:     9100, Batch Loss:    56.072956, Tokens per Sec:     3621, Lr: 0.000200
2022-01-18 10:03:59,603 - INFO - joeynmt.training - Epoch   4, Step:     9200, Batch Loss:    44.210964, Tokens per Sec:     3649, Lr: 0.000200
2022-01-18 10:04:17,722 - INFO - joeynmt.training - Epoch   4, Step:     9300, Batch Loss:    58.139637, Tokens per Sec:     3652, Lr: 0.000200
2022-01-18 10:04:36,723 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:    38.082802, Tokens per Sec:     3504, Lr: 0.000200
2022-01-18 10:04:55,442 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:    70.217522, Tokens per Sec:     3706, Lr: 0.000200
2022-01-18 10:05:14,228 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:    42.320694, Tokens per Sec:     3619, Lr: 0.000200
2022-01-18 10:05:32,612 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:    77.727592, Tokens per Sec:     3614, Lr: 0.000200
2022-01-18 10:05:50,935 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:    38.088753, Tokens per Sec:     3512, Lr: 0.000200
2022-01-18 10:06:09,276 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:    47.689453, Tokens per Sec:     3641, Lr: 0.000200
2022-01-18 10:06:27,611 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:    56.817303, Tokens per Sec:     3678, Lr: 0.000200
2022-01-18 10:10:36,222 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 10:11:09,035 - INFO - joeynmt.helpers - delete models/B_ablation/9000.ckpt
2022-01-18 10:11:09,114 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/9000.ckpt
2022-01-18 10:11:09,115 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/9000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/9000.ckpt')
2022-01-18 10:11:09,136 - INFO - joeynmt.training - Example #0
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 36 | 31 30 | 35 13 | 20 30 | 37 12 | 25 17 | 8 12 | 33 5
2022-01-18 10:11:09,136 - INFO - joeynmt.training - Example #1
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 74 | 65 1 | 32 74 | 8 74 | 12 74 | 21 74 | 20 74 | 20 51 | 19 74 | 71 10 | 14 51 | 56 37 | 22 6 | 30 50 | 36 51 | 26 50 | 30 23 | 26 None
2022-01-18 10:11:09,136 - INFO - joeynmt.training - Example #2
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 10:11:09,136 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 47 | 37 5 | 4 6 | 11 30 | 21 16 | 42 2 | 42 40 | 22 48 | 19 None
2022-01-18 10:11:09,136 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    10000: bleu:  17.33, loss: 274984.8750, ppl:   5.5167, duration: 281.5249s
2022-01-18 10:11:27,694 - INFO - joeynmt.training - Epoch   4, Step:    10100, Batch Loss:    62.679504, Tokens per Sec:     3671, Lr: 0.000200
2022-01-18 10:11:45,997 - INFO - joeynmt.training - Epoch   4, Step:    10200, Batch Loss:    45.478466, Tokens per Sec:     3662, Lr: 0.000200
2022-01-18 10:12:04,124 - INFO - joeynmt.training - Epoch   4, Step:    10300, Batch Loss:    46.575642, Tokens per Sec:     3801, Lr: 0.000200
2022-01-18 10:12:22,649 - INFO - joeynmt.training - Epoch   4, Step:    10400, Batch Loss:    59.450336, Tokens per Sec:     3735, Lr: 0.000200
2022-01-18 10:12:41,048 - INFO - joeynmt.training - Epoch   4, Step:    10500, Batch Loss:    32.229130, Tokens per Sec:     3718, Lr: 0.000200
2022-01-18 10:12:59,540 - INFO - joeynmt.training - Epoch   4, Step:    10600, Batch Loss:    50.912800, Tokens per Sec:     3601, Lr: 0.000200
2022-01-18 10:13:09,398 - INFO - joeynmt.training - Epoch   4: total training loss 136899.05
2022-01-18 10:13:09,398 - INFO - joeynmt.training - EPOCH 5
2022-01-18 10:13:17,889 - INFO - joeynmt.training - Epoch   5, Step:    10700, Batch Loss:    38.677589, Tokens per Sec:     3836, Lr: 0.000200
2022-01-18 10:13:36,568 - INFO - joeynmt.training - Epoch   5, Step:    10800, Batch Loss:    68.866943, Tokens per Sec:     3748, Lr: 0.000200
2022-01-18 10:13:54,982 - INFO - joeynmt.training - Epoch   5, Step:    10900, Batch Loss:    68.190491, Tokens per Sec:     3635, Lr: 0.000200
2022-01-18 10:14:13,367 - INFO - joeynmt.training - Epoch   5, Step:    11000, Batch Loss:    42.235542, Tokens per Sec:     3603, Lr: 0.000200
2022-01-18 10:18:15,764 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 10:18:48,550 - INFO - joeynmt.helpers - delete models/B_ablation/10000.ckpt
2022-01-18 10:18:48,627 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/10000.ckpt
2022-01-18 10:18:48,628 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/10000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/10000.ckpt')
2022-01-18 10:18:48,649 - INFO - joeynmt.training - Example #0
2022-01-18 10:18:48,649 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 10:18:48,649 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 10:18:48,650 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 36 | 31 30 | 2 36 | 25 17 | 2 5 | 37 13 | 8 19 | 33 12
2022-01-18 10:18:48,650 - INFO - joeynmt.training - Example #1
2022-01-18 10:18:48,650 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 10:18:48,650 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 10:18:48,650 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 74 | 32 74 | 12 74 | 8 74 | 17 7 | 20 74 | 19 6 | 71 41 | 14 23 | 56 74 | 16 10 | 22 51 | 36 74 | 30 46 | 26 None | 30 None
2022-01-18 10:18:48,650 - INFO - joeynmt.training - Example #2
2022-01-18 10:18:48,650 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 10:18:48,650 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 10:18:48,650 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 6 | 50 46 | 18 40 | 4 5 | 11 30 | 21 16 | 42 48 | 39 0 | 22 40
2022-01-18 10:18:48,650 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    11000: bleu:  17.98, loss: 269745.3750, ppl:   5.3401, duration: 275.2824s
2022-01-18 10:19:07,120 - INFO - joeynmt.training - Epoch   5, Step:    11100, Batch Loss:    24.294024, Tokens per Sec:     3620, Lr: 0.000200
2022-01-18 10:19:25,411 - INFO - joeynmt.training - Epoch   5, Step:    11200, Batch Loss:    55.659088, Tokens per Sec:     3794, Lr: 0.000200
2022-01-18 10:19:43,888 - INFO - joeynmt.training - Epoch   5, Step:    11300, Batch Loss:    56.777699, Tokens per Sec:     3556, Lr: 0.000200
2022-01-18 10:20:02,670 - INFO - joeynmt.training - Epoch   5, Step:    11400, Batch Loss:    70.283607, Tokens per Sec:     3774, Lr: 0.000200
2022-01-18 10:20:21,369 - INFO - joeynmt.training - Epoch   5, Step:    11500, Batch Loss:    27.489388, Tokens per Sec:     3639, Lr: 0.000200
2022-01-18 10:20:39,721 - INFO - joeynmt.training - Epoch   5, Step:    11600, Batch Loss:    30.075535, Tokens per Sec:     3755, Lr: 0.000200
2022-01-18 10:20:58,245 - INFO - joeynmt.training - Epoch   5, Step:    11700, Batch Loss:    67.749130, Tokens per Sec:     3662, Lr: 0.000200
2022-01-18 10:21:16,722 - INFO - joeynmt.training - Epoch   5, Step:    11800, Batch Loss:    47.407860, Tokens per Sec:     3597, Lr: 0.000200
2022-01-18 10:21:35,027 - INFO - joeynmt.training - Epoch   5, Step:    11900, Batch Loss:    39.228779, Tokens per Sec:     3694, Lr: 0.000200
2022-01-18 10:21:53,379 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:    55.342587, Tokens per Sec:     3764, Lr: 0.000200
2022-01-18 10:25:57,126 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 10:26:29,959 - INFO - joeynmt.helpers - delete models/B_ablation/11000.ckpt
2022-01-18 10:26:30,035 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/11000.ckpt
2022-01-18 10:26:30,036 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/11000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/11000.ckpt')
2022-01-18 10:26:30,056 - INFO - joeynmt.training - Example #0
2022-01-18 10:26:30,056 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 10:26:30,056 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 10:26:30,056 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 36 | 31 19 | 2 30 | 35 5 | 25 7 | 37 17 | 8 13
2022-01-18 10:26:30,056 - INFO - joeynmt.training - Example #1
2022-01-18 10:26:30,056 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 10:26:30,056 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 10:26:30,056 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 2 | 65 6 | 32 10 | 8 74 | 12 7 | 21 46 | 20 51 | 19 1 | 14 61 | 56 23 | 16 37 | 56 61 | 22 46 | 36 61 | 30 61 | 26 6 | 36 61
2022-01-18 10:26:30,056 - INFO - joeynmt.training - Example #2
2022-01-18 10:26:30,056 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 10:26:30,056 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 10:26:30,057 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 2 | 50 5 | 18 16 | 4 6 | 11 45 | 21 48 | 42 0 | 42 40 | 22 45 | 19 30
2022-01-18 10:26:30,057 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    12000: bleu:  18.67, loss: 261944.3906, ppl:   5.0875, duration: 276.6768s
2022-01-18 10:26:48,844 - INFO - joeynmt.training - Epoch   5, Step:    12100, Batch Loss:    57.623146, Tokens per Sec:     3505, Lr: 0.000200
2022-01-18 10:27:07,497 - INFO - joeynmt.training - Epoch   5, Step:    12200, Batch Loss:    28.360266, Tokens per Sec:     3514, Lr: 0.000200
2022-01-18 10:27:26,071 - INFO - joeynmt.training - Epoch   5, Step:    12300, Batch Loss:    44.569489, Tokens per Sec:     3541, Lr: 0.000200
2022-01-18 10:27:44,743 - INFO - joeynmt.training - Epoch   5, Step:    12400, Batch Loss:    40.478733, Tokens per Sec:     3727, Lr: 0.000200
2022-01-18 10:28:03,593 - INFO - joeynmt.training - Epoch   5, Step:    12500, Batch Loss:    59.283138, Tokens per Sec:     3446, Lr: 0.000200
2022-01-18 10:28:22,017 - INFO - joeynmt.training - Epoch   5, Step:    12600, Batch Loss:    45.818523, Tokens per Sec:     3652, Lr: 0.000200
2022-01-18 10:28:40,731 - INFO - joeynmt.training - Epoch   5, Step:    12700, Batch Loss:    35.036900, Tokens per Sec:     3559, Lr: 0.000200
2022-01-18 10:28:59,444 - INFO - joeynmt.training - Epoch   5, Step:    12800, Batch Loss:    49.373386, Tokens per Sec:     3699, Lr: 0.000200
2022-01-18 10:29:17,882 - INFO - joeynmt.training - Epoch   5, Step:    12900, Batch Loss:    65.319290, Tokens per Sec:     3609, Lr: 0.000200
2022-01-18 10:29:36,500 - INFO - joeynmt.training - Epoch   5, Step:    13000, Batch Loss:    81.418991, Tokens per Sec:     3751, Lr: 0.000200
2022-01-18 10:33:39,133 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 10:34:11,960 - INFO - joeynmt.helpers - delete models/B_ablation/12000.ckpt
2022-01-18 10:34:12,041 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/12000.ckpt
2022-01-18 10:34:12,042 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/12000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/12000.ckpt')
2022-01-18 10:34:12,064 - INFO - joeynmt.training - Example #0
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 13 | 2 17 | 25 5 | 37 7 | 8 12 | 33 13
2022-01-18 10:34:12,065 - INFO - joeynmt.training - Example #1
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Hypothesis: 13 7 | 35 0 | 65 50 | 32 1 | 8 74 | 12 51 | 20 41 | 21 6 | 19 10 | 71 37 | 71 23 | 71 73 | 14 63 | 16 67 | 22 73 | 36 73 | 30 73 | 26 73 | 30 None
2022-01-18 10:34:12,065 - INFO - joeynmt.training - Example #2
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 10:34:12,065 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 5 | 50 6 | 18 40 | 4 30 | 11 48 | 21 2 | 42 45 | 39 16 | 22 47
2022-01-18 10:34:12,065 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    13000: bleu:  18.67, loss: 258329.5000, ppl:   4.9746, duration: 275.5649s
2022-01-18 10:34:30,896 - INFO - joeynmt.training - Epoch   5, Step:    13100, Batch Loss:    45.665405, Tokens per Sec:     3484, Lr: 0.000200
2022-01-18 10:34:49,274 - INFO - joeynmt.training - Epoch   5, Step:    13200, Batch Loss:    43.781574, Tokens per Sec:     3656, Lr: 0.000200
2022-01-18 10:35:06,930 - INFO - joeynmt.training - Epoch   5, Step:    13300, Batch Loss:    66.026825, Tokens per Sec:     3887, Lr: 0.000200
2022-01-18 10:35:07,982 - INFO - joeynmt.training - Epoch   5: total training loss 125698.46
2022-01-18 10:35:07,982 - INFO - joeynmt.training - EPOCH 6
2022-01-18 10:35:25,009 - INFO - joeynmt.training - Epoch   6, Step:    13400, Batch Loss:    37.938519, Tokens per Sec:     3763, Lr: 0.000200
2022-01-18 10:35:43,632 - INFO - joeynmt.training - Epoch   6, Step:    13500, Batch Loss:    30.860752, Tokens per Sec:     3658, Lr: 0.000200
2022-01-18 10:36:02,112 - INFO - joeynmt.training - Epoch   6, Step:    13600, Batch Loss:    37.716564, Tokens per Sec:     3776, Lr: 0.000200
2022-01-18 10:36:20,652 - INFO - joeynmt.training - Epoch   6, Step:    13700, Batch Loss:    40.859413, Tokens per Sec:     3711, Lr: 0.000200
2022-01-18 10:36:39,042 - INFO - joeynmt.training - Epoch   6, Step:    13800, Batch Loss:    30.062359, Tokens per Sec:     3589, Lr: 0.000200
2022-01-18 10:36:57,170 - INFO - joeynmt.training - Epoch   6, Step:    13900, Batch Loss:    36.479214, Tokens per Sec:     3759, Lr: 0.000200
2022-01-18 10:37:15,949 - INFO - joeynmt.training - Epoch   6, Step:    14000, Batch Loss:    32.699333, Tokens per Sec:     3665, Lr: 0.000200
2022-01-18 10:41:20,912 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 10:41:53,745 - INFO - joeynmt.helpers - delete models/B_ablation/13000.ckpt
2022-01-18 10:41:53,826 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/13000.ckpt
2022-01-18 10:41:53,826 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/13000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/13000.ckpt')
2022-01-18 10:41:53,849 - INFO - joeynmt.training - Example #0
2022-01-18 10:41:53,849 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 10:41:53,849 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 10:41:53,850 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 36 | 31 19 | 35 30 | 2 13 | 37 7 | 25 17 | 8 5 | 33 12
2022-01-18 10:41:53,850 - INFO - joeynmt.training - Example #1
2022-01-18 10:41:53,850 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 10:41:53,850 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 10:41:53,850 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 6 | 32 74 | 8 7 | 12 41 | 21 74 | 20 46 | 19 10 | 14 51 | 71 61 | 56 6 | 16 23 | 22 61 | 66 1 | 30 61 | 36 61 | 26 6 | 26 10
2022-01-18 10:41:53,850 - INFO - joeynmt.training - Example #2
2022-01-18 10:41:53,850 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 10:41:53,850 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 10:41:53,850 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 6 | 18 5 | 4 16 | 11 40 | 21 48 | 42 30 | 39 6 | 22 47 | 19 45
2022-01-18 10:41:53,850 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    14000: bleu:  19.64, loss: 255112.6562, ppl:   4.8762, duration: 277.9004s
2022-01-18 10:42:12,433 - INFO - joeynmt.training - Epoch   6, Step:    14100, Batch Loss:    37.377975, Tokens per Sec:     3632, Lr: 0.000200
2022-01-18 10:42:30,643 - INFO - joeynmt.training - Epoch   6, Step:    14200, Batch Loss:    72.975388, Tokens per Sec:     3739, Lr: 0.000200
2022-01-18 10:42:49,030 - INFO - joeynmt.training - Epoch   6, Step:    14300, Batch Loss:    54.963478, Tokens per Sec:     3745, Lr: 0.000200
2022-01-18 10:43:07,774 - INFO - joeynmt.training - Epoch   6, Step:    14400, Batch Loss:    45.232826, Tokens per Sec:     3673, Lr: 0.000200
2022-01-18 10:43:26,250 - INFO - joeynmt.training - Epoch   6, Step:    14500, Batch Loss:    27.589174, Tokens per Sec:     3727, Lr: 0.000200
2022-01-18 10:43:44,592 - INFO - joeynmt.training - Epoch   6, Step:    14600, Batch Loss:    29.552649, Tokens per Sec:     3737, Lr: 0.000200
2022-01-18 10:44:02,973 - INFO - joeynmt.training - Epoch   6, Step:    14700, Batch Loss:    40.361622, Tokens per Sec:     3584, Lr: 0.000200
2022-01-18 10:44:21,502 - INFO - joeynmt.training - Epoch   6, Step:    14800, Batch Loss:    33.796341, Tokens per Sec:     3709, Lr: 0.000200
2022-01-18 10:44:39,820 - INFO - joeynmt.training - Epoch   6, Step:    14900, Batch Loss:    52.026882, Tokens per Sec:     3593, Lr: 0.000200
2022-01-18 10:44:58,228 - INFO - joeynmt.training - Epoch   6, Step:    15000, Batch Loss:    26.329355, Tokens per Sec:     3718, Lr: 0.000200
2022-01-18 10:49:02,123 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 10:49:34,906 - INFO - joeynmt.helpers - delete models/B_ablation/14000.ckpt
2022-01-18 10:49:34,986 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/14000.ckpt
2022-01-18 10:49:34,987 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/14000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/14000.ckpt')
2022-01-18 10:49:35,016 - INFO - joeynmt.training - Example #0
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 36 | 31 19 | 35 30 | 2 7 | 25 17 | 37 5 | 8 12 | 33 13
2022-01-18 10:49:35,016 - INFO - joeynmt.training - Example #1
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 1 | 8 6 | 12 41 | 17 46 | 20 51 | 19 23 | 71 10 | 14 41 | 71 42 | 56 37 | 16 6 | 22 61 | 66 61 | 30 61 | 26 10 | 21 46
2022-01-18 10:49:35,016 - INFO - joeynmt.training - Example #2
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 10:49:35,016 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 6 | 37 16 | 4 40 | 11 30 | 21 5 | 42 48 | 39 45 | 22 2 | 19 45
2022-01-18 10:49:35,017 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    15000: bleu:  20.69, loss: 249279.5000, ppl:   4.7027, duration: 276.7886s
2022-01-18 10:49:53,853 - INFO - joeynmt.training - Epoch   6, Step:    15100, Batch Loss:    50.466896, Tokens per Sec:     3605, Lr: 0.000200
2022-01-18 10:50:12,589 - INFO - joeynmt.training - Epoch   6, Step:    15200, Batch Loss:    26.871099, Tokens per Sec:     3611, Lr: 0.000200
2022-01-18 10:50:31,095 - INFO - joeynmt.training - Epoch   6, Step:    15300, Batch Loss:    32.121258, Tokens per Sec:     3637, Lr: 0.000200
2022-01-18 10:50:49,301 - INFO - joeynmt.training - Epoch   6, Step:    15400, Batch Loss:    35.081947, Tokens per Sec:     3631, Lr: 0.000200
2022-01-18 10:51:07,840 - INFO - joeynmt.training - Epoch   6, Step:    15500, Batch Loss:    37.004227, Tokens per Sec:     3605, Lr: 0.000200
2022-01-18 10:51:26,396 - INFO - joeynmt.training - Epoch   6, Step:    15600, Batch Loss:    71.526451, Tokens per Sec:     3500, Lr: 0.000200
2022-01-18 10:51:44,956 - INFO - joeynmt.training - Epoch   6, Step:    15700, Batch Loss:    41.394485, Tokens per Sec:     3615, Lr: 0.000200
2022-01-18 10:52:03,453 - INFO - joeynmt.training - Epoch   6, Step:    15800, Batch Loss:    39.733719, Tokens per Sec:     3634, Lr: 0.000200
2022-01-18 10:52:21,585 - INFO - joeynmt.training - Epoch   6, Step:    15900, Batch Loss:    40.421917, Tokens per Sec:     3719, Lr: 0.000200
2022-01-18 10:52:32,059 - INFO - joeynmt.training - Epoch   6: total training loss 118366.85
2022-01-18 10:52:32,059 - INFO - joeynmt.training - EPOCH 7
2022-01-18 10:52:39,977 - INFO - joeynmt.training - Epoch   7, Step:    16000, Batch Loss:    32.835972, Tokens per Sec:     3598, Lr: 0.000200
2022-01-18 10:56:45,086 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 10:57:17,763 - INFO - joeynmt.helpers - delete models/B_ablation/15000.ckpt
2022-01-18 10:57:17,839 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/15000.ckpt
2022-01-18 10:57:17,839 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/15000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/15000.ckpt')
2022-01-18 10:57:17,860 - INFO - joeynmt.training - Example #0
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 10:57:17,860 - INFO - joeynmt.training - Example #1
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 50 | 32 0 | 8 1 | 12 74 | 21 23 | 20 6 | 19 10 | 71 41 | 14 51 | 56 37 | 16 67 | 22 61 | 66 61 | 66 61 | 30 61 | 36 67 | 26 None
2022-01-18 10:57:17,860 - INFO - joeynmt.training - Example #2
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 10:57:17,860 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 6 | 37 5 | 4 16 | 11 40 | 21 45 | 42 48 | 39 47 | 22 30 | 19 2
2022-01-18 10:57:17,860 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    16000: bleu:  21.79, loss: 243772.6719, ppl:   4.5446, duration: 277.8832s
2022-01-18 10:57:35,761 - INFO - joeynmt.training - Epoch   7, Step:    16100, Batch Loss:    22.680012, Tokens per Sec:     3766, Lr: 0.000200
2022-01-18 10:57:53,827 - INFO - joeynmt.training - Epoch   7, Step:    16200, Batch Loss:    49.902233, Tokens per Sec:     3668, Lr: 0.000200
2022-01-18 10:58:12,181 - INFO - joeynmt.training - Epoch   7, Step:    16300, Batch Loss:    35.245834, Tokens per Sec:     3682, Lr: 0.000200
2022-01-18 10:58:30,305 - INFO - joeynmt.training - Epoch   7, Step:    16400, Batch Loss:    42.490948, Tokens per Sec:     3689, Lr: 0.000200
2022-01-18 10:58:48,862 - INFO - joeynmt.training - Epoch   7, Step:    16500, Batch Loss:    41.073017, Tokens per Sec:     3732, Lr: 0.000200
2022-01-18 10:59:07,503 - INFO - joeynmt.training - Epoch   7, Step:    16600, Batch Loss:    33.047115, Tokens per Sec:     3639, Lr: 0.000200
2022-01-18 10:59:26,008 - INFO - joeynmt.training - Epoch   7, Step:    16700, Batch Loss:    34.724792, Tokens per Sec:     3637, Lr: 0.000200
2022-01-18 10:59:44,382 - INFO - joeynmt.training - Epoch   7, Step:    16800, Batch Loss:    47.548786, Tokens per Sec:     3704, Lr: 0.000200
2022-01-18 11:00:02,850 - INFO - joeynmt.training - Epoch   7, Step:    16900, Batch Loss:    41.178944, Tokens per Sec:     3691, Lr: 0.000200
2022-01-18 11:00:21,294 - INFO - joeynmt.training - Epoch   7, Step:    17000, Batch Loss:    75.298416, Tokens per Sec:     3823, Lr: 0.000200
2022-01-18 11:04:24,024 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 11:04:56,832 - INFO - joeynmt.helpers - delete models/B_ablation/16000.ckpt
2022-01-18 11:04:56,912 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/16000.ckpt
2022-01-18 11:04:56,913 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/16000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/16000.ckpt')
2022-01-18 11:04:56,943 - INFO - joeynmt.training - Example #0
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 35 5 | 25 17 | 37 13 | 8 12 | 33 7
2022-01-18 11:04:56,944 - INFO - joeynmt.training - Example #1
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 74 | 8 74 | 12 51 | 20 1 | 17 6 | 19 61 | 71 41 | 14 23 | 56 74 | 22 10 | 16 37 | 66 42 | 36 61 | 26 61 | 30 61 | 21 61
2022-01-18 11:04:56,944 - INFO - joeynmt.training - Example #2
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 11:04:56,944 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 0 | 37 2 | 4 16 | 11 40 | 21 30 | 42 5 | 39 6 | 22 48 | 19 45
2022-01-18 11:04:56,945 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    17000: bleu:  23.48, loss: 239524.3438, ppl:   4.4263, duration: 275.6506s
2022-01-18 11:05:15,392 - INFO - joeynmt.training - Epoch   7, Step:    17100, Batch Loss:    33.151974, Tokens per Sec:     3696, Lr: 0.000200
2022-01-18 11:05:33,685 - INFO - joeynmt.training - Epoch   7, Step:    17200, Batch Loss:    21.667351, Tokens per Sec:     3615, Lr: 0.000200
2022-01-18 11:05:51,981 - INFO - joeynmt.training - Epoch   7, Step:    17300, Batch Loss:    46.791836, Tokens per Sec:     3672, Lr: 0.000200
2022-01-18 11:06:10,562 - INFO - joeynmt.training - Epoch   7, Step:    17400, Batch Loss:    55.584549, Tokens per Sec:     3604, Lr: 0.000200
2022-01-18 11:06:29,264 - INFO - joeynmt.training - Epoch   7, Step:    17500, Batch Loss:    33.648724, Tokens per Sec:     3655, Lr: 0.000200
2022-01-18 11:06:48,000 - INFO - joeynmt.training - Epoch   7, Step:    17600, Batch Loss:    53.491558, Tokens per Sec:     3542, Lr: 0.000200
2022-01-18 11:07:06,140 - INFO - joeynmt.training - Epoch   7, Step:    17700, Batch Loss:    38.884079, Tokens per Sec:     3759, Lr: 0.000200
2022-01-18 11:07:24,751 - INFO - joeynmt.training - Epoch   7, Step:    17800, Batch Loss:    39.835854, Tokens per Sec:     3560, Lr: 0.000200
2022-01-18 11:07:43,191 - INFO - joeynmt.training - Epoch   7, Step:    17900, Batch Loss:    50.653339, Tokens per Sec:     3673, Lr: 0.000200
2022-01-18 11:08:01,603 - INFO - joeynmt.training - Epoch   7, Step:    18000, Batch Loss:    41.150906, Tokens per Sec:     3613, Lr: 0.000200
2022-01-18 11:12:05,308 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 11:12:38,170 - INFO - joeynmt.helpers - delete models/B_ablation/17000.ckpt
2022-01-18 11:12:38,254 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/17000.ckpt
2022-01-18 11:12:38,254 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/17000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/17000.ckpt')
2022-01-18 11:12:38,276 - INFO - joeynmt.training - Example #0
2022-01-18 11:12:38,276 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 11:12:38,276 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 11:12:38,276 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 37 5 | 25 17 | 8 13 | 33 12
2022-01-18 11:12:38,276 - INFO - joeynmt.training - Example #1
2022-01-18 11:12:38,276 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 11:12:38,276 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 11:12:38,276 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 41 | 8 46 | 12 51 | 17 10 | 20 67 | 19 6 | 71 42 | 14 23 | 56 61 | 16 61 | 22 37 | 30 6 | 36 59 | 26 61 | 66 1 | 58 59
2022-01-18 11:12:38,276 - INFO - joeynmt.training - Example #2
2022-01-18 11:12:38,276 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 11:12:38,277 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 11:12:38,277 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 5 | 37 16 | 4 40 | 11 45 | 21 30 | 42 47 | 39 6 | 22 48 | 19 46
2022-01-18 11:12:38,277 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    18000: bleu:  24.12, loss: 234460.5625, ppl:   4.2892, duration: 276.6729s
2022-01-18 11:13:17,271 - INFO - joeynmt.training - Epoch   7, Step:    18100, Batch Loss:    30.802418, Tokens per Sec:     1759, Lr: 0.000200
2022-01-18 11:13:55,278 - INFO - joeynmt.training - Epoch   7, Step:    18200, Batch Loss:    55.435638, Tokens per Sec:     1766, Lr: 0.000200
2022-01-18 11:14:13,210 - INFO - joeynmt.training - Epoch   7, Step:    18300, Batch Loss:    32.170124, Tokens per Sec:     3822, Lr: 0.000200
2022-01-18 11:14:51,719 - INFO - joeynmt.training - Epoch   7, Step:    18400, Batch Loss:    45.845142, Tokens per Sec:     1784, Lr: 0.000200
2022-01-18 11:15:10,029 - INFO - joeynmt.training - Epoch   7, Step:    18500, Batch Loss:    46.392117, Tokens per Sec:     3713, Lr: 0.000200
2022-01-18 11:15:42,271 - INFO - joeynmt.training - Epoch   7, Step:    18600, Batch Loss:    34.205864, Tokens per Sec:     2066, Lr: 0.000200
2022-01-18 11:15:44,006 - INFO - joeynmt.training - Epoch   7: total training loss 110997.12
2022-01-18 11:15:44,006 - INFO - joeynmt.training - EPOCH 8
2022-01-18 11:16:26,948 - INFO - joeynmt.training - Epoch   8, Step:    18700, Batch Loss:    28.958162, Tokens per Sec:     1390, Lr: 0.000200
2022-01-18 11:17:00,850 - INFO - joeynmt.training - Epoch   8, Step:    18800, Batch Loss:    38.914806, Tokens per Sec:     2045, Lr: 0.000200
2022-01-18 11:17:19,018 - INFO - joeynmt.training - Epoch   8, Step:    18900, Batch Loss:    38.409695, Tokens per Sec:     3555, Lr: 0.000200
2022-01-18 11:17:37,380 - INFO - joeynmt.training - Epoch   8, Step:    19000, Batch Loss:    65.752335, Tokens per Sec:     3666, Lr: 0.000200
2022-01-18 11:21:41,056 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 11:22:13,845 - INFO - joeynmt.helpers - delete models/B_ablation/18000.ckpt
2022-01-18 11:22:13,924 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/18000.ckpt
2022-01-18 11:22:13,925 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/18000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/18000.ckpt')
2022-01-18 11:22:13,945 - INFO - joeynmt.training - Example #0
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 35 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 11:22:13,946 - INFO - joeynmt.training - Example #1
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Hypothesis: 13 7 | 35 50 | 65 74 | 32 0 | 12 74 | 21 51 | 20 73 | 71 41 | 19 23 | 71 46 | 14 6 | 56 10 | 16 42 | 22 59 | 66 37 | 36 61 | 30 61 | 26 67 | 26 59
2022-01-18 11:22:13,946 - INFO - joeynmt.training - Example #2
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 11:22:13,946 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 47 | 37 16 | 4 40 | 11 30 | 21 45 | 42 5 | 39 6 | 22 48 | 19 None
2022-01-18 11:22:13,946 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    19000: bleu:  25.14, loss: 232679.9062, ppl:   4.2420, duration: 276.5663s
2022-01-18 11:22:33,069 - INFO - joeynmt.training - Epoch   8, Step:    19100, Batch Loss:    75.570145, Tokens per Sec:     3444, Lr: 0.000200
2022-01-18 11:22:51,618 - INFO - joeynmt.training - Epoch   8, Step:    19200, Batch Loss:    44.266838, Tokens per Sec:     3600, Lr: 0.000200
2022-01-18 11:23:10,677 - INFO - joeynmt.training - Epoch   8, Step:    19300, Batch Loss:    51.181133, Tokens per Sec:     3610, Lr: 0.000200
2022-01-18 11:23:29,672 - INFO - joeynmt.training - Epoch   8, Step:    19400, Batch Loss:    19.853031, Tokens per Sec:     3625, Lr: 0.000200
2022-01-18 11:23:48,451 - INFO - joeynmt.training - Epoch   8, Step:    19500, Batch Loss:    39.554138, Tokens per Sec:     3606, Lr: 0.000200
2022-01-18 11:24:07,149 - INFO - joeynmt.training - Epoch   8, Step:    19600, Batch Loss:    47.555683, Tokens per Sec:     3677, Lr: 0.000200
2022-01-18 11:24:25,923 - INFO - joeynmt.training - Epoch   8, Step:    19700, Batch Loss:    47.443600, Tokens per Sec:     3512, Lr: 0.000200
2022-01-18 11:24:44,323 - INFO - joeynmt.training - Epoch   8, Step:    19800, Batch Loss:    49.952152, Tokens per Sec:     3656, Lr: 0.000200
2022-01-18 11:25:02,840 - INFO - joeynmt.training - Epoch   8, Step:    19900, Batch Loss:    33.820671, Tokens per Sec:     3628, Lr: 0.000200
2022-01-18 11:25:21,350 - INFO - joeynmt.training - Epoch   8, Step:    20000, Batch Loss:    37.224945, Tokens per Sec:     3671, Lr: 0.000200
2022-01-18 11:29:24,945 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 11:29:57,828 - INFO - joeynmt.helpers - delete models/B_ablation/19000.ckpt
2022-01-18 11:29:57,909 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/19000.ckpt
2022-01-18 11:29:57,909 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/19000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/19000.ckpt')
2022-01-18 11:29:57,929 - INFO - joeynmt.training - Example #0
2022-01-18 11:29:57,929 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 11:29:57,929 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 11:29:57,929 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 35 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 11:29:57,930 - INFO - joeynmt.training - Example #1
2022-01-18 11:29:57,930 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 11:29:57,930 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 11:29:57,930 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 41 | 8 46 | 17 67 | 12 51 | 20 37 | 19 10 | 71 6 | 14 61 | 56 23 | 16 67 | 22 61 | 66 1 | 30 67 | 36 67 | 26 10 | 21 None
2022-01-18 11:29:57,930 - INFO - joeynmt.training - Example #2
2022-01-18 11:29:57,930 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 11:29:57,930 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 11:29:57,930 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 47 | 37 0 | 4 16 | 11 40 | 21 30 | 42 5 | 39 6 | 22 48 | 19 30
2022-01-18 11:29:57,930 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    20000: bleu:  27.04, loss: 226932.4062, ppl:   4.0933, duration: 276.5795s
2022-01-18 11:30:16,130 - INFO - joeynmt.training - Epoch   8, Step:    20100, Batch Loss:    37.830582, Tokens per Sec:     3682, Lr: 0.000200
2022-01-18 11:30:34,056 - INFO - joeynmt.training - Epoch   8, Step:    20200, Batch Loss:    34.660122, Tokens per Sec:     3650, Lr: 0.000200
2022-01-18 11:30:52,507 - INFO - joeynmt.training - Epoch   8, Step:    20300, Batch Loss:    29.943417, Tokens per Sec:     3628, Lr: 0.000200
2022-01-18 11:31:11,252 - INFO - joeynmt.training - Epoch   8, Step:    20400, Batch Loss:    53.448666, Tokens per Sec:     3626, Lr: 0.000200
2022-01-18 11:31:29,856 - INFO - joeynmt.training - Epoch   8, Step:    20500, Batch Loss:    50.942772, Tokens per Sec:     3711, Lr: 0.000200
2022-01-18 11:31:48,428 - INFO - joeynmt.training - Epoch   8, Step:    20600, Batch Loss:    33.540691, Tokens per Sec:     3681, Lr: 0.000200
2022-01-18 11:32:07,526 - INFO - joeynmt.training - Epoch   8, Step:    20700, Batch Loss:    40.266659, Tokens per Sec:     3578, Lr: 0.000200
2022-01-18 11:32:25,949 - INFO - joeynmt.training - Epoch   8, Step:    20800, Batch Loss:    38.934998, Tokens per Sec:     3679, Lr: 0.000200
2022-01-18 11:32:44,253 - INFO - joeynmt.training - Epoch   8, Step:    20900, Batch Loss:    24.285233, Tokens per Sec:     3755, Lr: 0.000200
2022-01-18 11:33:02,903 - INFO - joeynmt.training - Epoch   8, Step:    21000, Batch Loss:    38.580124, Tokens per Sec:     3479, Lr: 0.000200
2022-01-18 11:37:09,139 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 11:37:42,490 - INFO - joeynmt.helpers - delete models/B_ablation/20000.ckpt
2022-01-18 11:37:42,574 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/20000.ckpt
2022-01-18 11:37:42,575 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/20000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/20000.ckpt')
2022-01-18 11:37:42,596 - INFO - joeynmt.training - Example #0
2022-01-18 11:37:42,596 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 11:37:42,596 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 11:37:42,596 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 35 7 | 25 5 | 37 17 | 8 13
2022-01-18 11:37:42,596 - INFO - joeynmt.training - Example #1
2022-01-18 11:37:42,596 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 11:37:42,596 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 11:37:42,596 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 1 | 17 51 | 21 41 | 20 46 | 19 23 | 71 73 | 14 6 | 56 10 | 16 37 | 66 42 | 22 61 | 66 51 | 36 73 | 30 73 | 26 59
2022-01-18 11:37:42,596 - INFO - joeynmt.training - Example #2
2022-01-18 11:37:42,596 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 11:37:42,596 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 11:37:42,597 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 None | 37 None | 4 40 | 11 16 | 21 30 | 42 None | 22 6 | 19 5 | 18 48
2022-01-18 11:37:42,597 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    21000: bleu:  27.25, loss: 225491.0000, ppl:   4.0568, duration: 279.6929s
2022-01-18 11:38:01,046 - INFO - joeynmt.training - Epoch   8, Step:    21100, Batch Loss:    80.408539, Tokens per Sec:     3653, Lr: 0.000200
2022-01-18 11:38:19,732 - INFO - joeynmt.training - Epoch   8, Step:    21200, Batch Loss:    31.355980, Tokens per Sec:     3561, Lr: 0.000200
2022-01-18 11:38:33,098 - INFO - joeynmt.training - Epoch   8: total training loss 104614.97
2022-01-18 11:38:33,099 - INFO - joeynmt.training - EPOCH 9
2022-01-18 11:38:38,023 - INFO - joeynmt.training - Epoch   9, Step:    21300, Batch Loss:    46.236462, Tokens per Sec:     3650, Lr: 0.000200
2022-01-18 11:38:56,510 - INFO - joeynmt.training - Epoch   9, Step:    21400, Batch Loss:    35.418335, Tokens per Sec:     3568, Lr: 0.000200
2022-01-18 11:39:15,175 - INFO - joeynmt.training - Epoch   9, Step:    21500, Batch Loss:    57.423321, Tokens per Sec:     3584, Lr: 0.000200
2022-01-18 11:39:33,991 - INFO - joeynmt.training - Epoch   9, Step:    21600, Batch Loss:    21.461632, Tokens per Sec:     3674, Lr: 0.000200
2022-01-18 11:39:52,738 - INFO - joeynmt.training - Epoch   9, Step:    21700, Batch Loss:    17.024021, Tokens per Sec:     3746, Lr: 0.000200
2022-01-18 11:40:11,614 - INFO - joeynmt.training - Epoch   9, Step:    21800, Batch Loss:    25.748308, Tokens per Sec:     3580, Lr: 0.000200
2022-01-18 11:40:30,459 - INFO - joeynmt.training - Epoch   9, Step:    21900, Batch Loss:    31.322336, Tokens per Sec:     3575, Lr: 0.000200
2022-01-18 11:40:49,341 - INFO - joeynmt.training - Epoch   9, Step:    22000, Batch Loss:    24.623671, Tokens per Sec:     3697, Lr: 0.000200
2022-01-18 11:44:52,733 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 11:45:25,515 - INFO - joeynmt.helpers - delete models/B_ablation/21000.ckpt
2022-01-18 11:45:25,595 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/21000.ckpt
2022-01-18 11:45:25,596 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/21000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/21000.ckpt')
2022-01-18 11:45:25,627 - INFO - joeynmt.training - Example #0
2022-01-18 11:45:25,628 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 11:45:25,628 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 11:45:25,628 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 11:45:25,628 - INFO - joeynmt.training - Example #1
2022-01-18 11:45:25,628 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 11:45:25,628 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 11:45:25,628 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 74 | 12 1 | 21 67 | 20 73 | 71 51 | 14 6 | 56 61 | 16 23 | 22 37 | 66 10 | 36 42 | 30 73 | 26 59 | 66 59 | 8 61 | 20 None
2022-01-18 11:45:25,629 - INFO - joeynmt.training - Example #2
2022-01-18 11:45:25,629 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 11:45:25,629 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 11:45:25,629 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 47 | 37 16 | 4 40 | 11 30 | 21 48 | 42 6 | 39 5 | 22 45 | 19 None
2022-01-18 11:45:25,629 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    22000: bleu:  28.69, loss: 221684.0000, ppl:   3.9620, duration: 276.2878s
2022-01-18 11:45:44,071 - INFO - joeynmt.training - Epoch   9, Step:    22100, Batch Loss:    24.589231, Tokens per Sec:     3751, Lr: 0.000200
2022-01-18 11:46:02,536 - INFO - joeynmt.training - Epoch   9, Step:    22200, Batch Loss:    60.949390, Tokens per Sec:     3730, Lr: 0.000200
2022-01-18 11:46:20,711 - INFO - joeynmt.training - Epoch   9, Step:    22300, Batch Loss:    25.582703, Tokens per Sec:     3730, Lr: 0.000200
2022-01-18 11:46:38,935 - INFO - joeynmt.training - Epoch   9, Step:    22400, Batch Loss:    29.355345, Tokens per Sec:     3594, Lr: 0.000200
2022-01-18 11:46:57,561 - INFO - joeynmt.training - Epoch   9, Step:    22500, Batch Loss:    36.730629, Tokens per Sec:     3652, Lr: 0.000200
2022-01-18 11:47:16,129 - INFO - joeynmt.training - Epoch   9, Step:    22600, Batch Loss:    43.303188, Tokens per Sec:     3733, Lr: 0.000200
2022-01-18 11:47:34,544 - INFO - joeynmt.training - Epoch   9, Step:    22700, Batch Loss:    25.294458, Tokens per Sec:     3601, Lr: 0.000200
2022-01-18 11:47:53,047 - INFO - joeynmt.training - Epoch   9, Step:    22800, Batch Loss:    46.771729, Tokens per Sec:     3718, Lr: 0.000200
2022-01-18 11:48:11,191 - INFO - joeynmt.training - Epoch   9, Step:    22900, Batch Loss:    28.350348, Tokens per Sec:     3647, Lr: 0.000200
2022-01-18 11:48:29,545 - INFO - joeynmt.training - Epoch   9, Step:    23000, Batch Loss:    30.499201, Tokens per Sec:     3663, Lr: 0.000200
2022-01-18 11:52:31,993 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 11:53:04,832 - INFO - joeynmt.helpers - delete models/B_ablation/22000.ckpt
2022-01-18 11:53:04,914 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/22000.ckpt
2022-01-18 11:53:04,915 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/22000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/22000.ckpt')
2022-01-18 11:53:04,943 - INFO - joeynmt.training - Example #0
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 12 | 33 13
2022-01-18 11:53:04,943 - INFO - joeynmt.training - Example #1
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 50 | 32 74 | 8 1 | 17 51 | 20 41 | 71 37 | 19 67 | 14 61 | 56 59 | 22 6 | 16 10 | 66 42 | 30 23 | 36 67 | 66 37 | 26 59 | 21 7
2022-01-18 11:53:04,943 - INFO - joeynmt.training - Example #2
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 11:53:04,943 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 6 | 37 40 | 4 16 | 11 30 | 21 45 | 42 47 | 39 5 | 22 48 | 19 None
2022-01-18 11:53:04,944 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    23000: bleu:  29.68, loss: 217697.9375, ppl:   3.8652, duration: 275.3979s
2022-01-18 11:53:23,295 - INFO - joeynmt.training - Epoch   9, Step:    23100, Batch Loss:    45.408340, Tokens per Sec:     3610, Lr: 0.000200
2022-01-18 11:53:41,492 - INFO - joeynmt.training - Epoch   9, Step:    23200, Batch Loss:    52.012932, Tokens per Sec:     3550, Lr: 0.000200
2022-01-18 11:54:00,284 - INFO - joeynmt.training - Epoch   9, Step:    23300, Batch Loss:    32.492603, Tokens per Sec:     3659, Lr: 0.000200
2022-01-18 11:54:18,883 - INFO - joeynmt.training - Epoch   9, Step:    23400, Batch Loss:    62.202465, Tokens per Sec:     3585, Lr: 0.000200
2022-01-18 11:54:37,461 - INFO - joeynmt.training - Epoch   9, Step:    23500, Batch Loss:    27.777348, Tokens per Sec:     3541, Lr: 0.000200
2022-01-18 11:54:56,318 - INFO - joeynmt.training - Epoch   9, Step:    23600, Batch Loss:    31.104851, Tokens per Sec:     3636, Lr: 0.000200
2022-01-18 11:55:14,964 - INFO - joeynmt.training - Epoch   9, Step:    23700, Batch Loss:    37.350971, Tokens per Sec:     3623, Lr: 0.000200
2022-01-18 11:55:33,756 - INFO - joeynmt.training - Epoch   9, Step:    23800, Batch Loss:    46.416985, Tokens per Sec:     3506, Lr: 0.000200
2022-01-18 11:55:52,423 - INFO - joeynmt.training - Epoch   9, Step:    23900, Batch Loss:    16.945929, Tokens per Sec:     3737, Lr: 0.000200
2022-01-18 11:55:57,522 - INFO - joeynmt.training - Epoch   9: total training loss 98953.64
2022-01-18 11:55:57,523 - INFO - joeynmt.training - EPOCH 10
2022-01-18 11:56:11,153 - INFO - joeynmt.training - Epoch  10, Step:    24000, Batch Loss:    54.551502, Tokens per Sec:     3464, Lr: 0.000200
2022-01-18 12:00:17,110 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 12:00:50,469 - INFO - joeynmt.helpers - delete models/B_ablation/23000.ckpt
2022-01-18 12:00:50,552 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/23000.ckpt
2022-01-18 12:00:50,553 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/23000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/23000.ckpt')
2022-01-18 12:00:50,573 - INFO - joeynmt.training - Example #0
2022-01-18 12:00:50,573 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 12:00:50,573 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 12:00:50,573 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 12:00:50,573 - INFO - joeynmt.training - Example #1
2022-01-18 12:00:50,574 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 12:00:50,574 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 12:00:50,574 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 1 | 12 74 | 21 51 | 20 67 | 19 41 | 71 46 | 14 23 | 56 6 | 16 10 | 22 42 | 66 61 | 30 37 | 36 67 | 26 59 | 20 None
2022-01-18 12:00:50,574 - INFO - joeynmt.training - Example #2
2022-01-18 12:00:50,574 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 12:00:50,574 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:00:50,574 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 40 | 4 16 | 11 48 | 21 47 | 42 6 | 39 5 | 22 30 | 19 45
2022-01-18 12:00:50,574 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    24000: bleu:  30.20, loss: 215537.0469, ppl:   3.8136, duration: 279.4202s
2022-01-18 12:01:09,111 - INFO - joeynmt.training - Epoch  10, Step:    24100, Batch Loss:    49.646076, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 12:01:27,480 - INFO - joeynmt.training - Epoch  10, Step:    24200, Batch Loss:    28.527973, Tokens per Sec:     3715, Lr: 0.000200
2022-01-18 12:01:45,914 - INFO - joeynmt.training - Epoch  10, Step:    24300, Batch Loss:    35.436966, Tokens per Sec:     3697, Lr: 0.000200
2022-01-18 12:02:04,240 - INFO - joeynmt.training - Epoch  10, Step:    24400, Batch Loss:    39.606396, Tokens per Sec:     3668, Lr: 0.000200
2022-01-18 12:02:22,897 - INFO - joeynmt.training - Epoch  10, Step:    24500, Batch Loss:    28.926531, Tokens per Sec:     3651, Lr: 0.000200
2022-01-18 12:02:41,373 - INFO - joeynmt.training - Epoch  10, Step:    24600, Batch Loss:    26.002615, Tokens per Sec:     3588, Lr: 0.000200
2022-01-18 12:02:59,992 - INFO - joeynmt.training - Epoch  10, Step:    24700, Batch Loss:    48.479225, Tokens per Sec:     3595, Lr: 0.000200
2022-01-18 12:03:18,474 - INFO - joeynmt.training - Epoch  10, Step:    24800, Batch Loss:    22.641226, Tokens per Sec:     3657, Lr: 0.000200
2022-01-18 12:03:36,772 - INFO - joeynmt.training - Epoch  10, Step:    24900, Batch Loss:    35.062462, Tokens per Sec:     3648, Lr: 0.000200
2022-01-18 12:03:55,297 - INFO - joeynmt.training - Epoch  10, Step:    25000, Batch Loss:    19.258385, Tokens per Sec:     3691, Lr: 0.000200
2022-01-18 12:08:00,199 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 12:08:32,994 - INFO - joeynmt.helpers - delete models/B_ablation/24000.ckpt
2022-01-18 12:08:33,077 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/24000.ckpt
2022-01-18 12:08:33,078 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/24000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/24000.ckpt')
2022-01-18 12:08:33,104 - INFO - joeynmt.training - Example #0
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 25 7 | 8 5 | 37 13 | 33 12 | 25 17
2022-01-18 12:08:33,105 - INFO - joeynmt.training - Example #1
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 50 | 65 7 | 32 74 | 8 1 | 17 41 | 21 46 | 20 51 | 19 67 | 71 6 | 14 61 | 56 10 | 16 42 | 22 23 | 36 37 | 30 73 | 26 59 | 12 None
2022-01-18 12:08:33,105 - INFO - joeynmt.training - Example #2
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:08:33,105 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 16 | 4 40 | 11 48 | 21 47 | 42 6 | 22 5 | 19 45 | 18 30
2022-01-18 12:08:33,105 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    25000: bleu:  31.74, loss: 213191.6250, ppl:   3.7585, duration: 277.8084s
2022-01-18 12:08:51,277 - INFO - joeynmt.training - Epoch  10, Step:    25100, Batch Loss:    49.834732, Tokens per Sec:     3730, Lr: 0.000200
2022-01-18 12:09:09,689 - INFO - joeynmt.training - Epoch  10, Step:    25200, Batch Loss:    41.038948, Tokens per Sec:     3585, Lr: 0.000200
2022-01-18 12:09:28,210 - INFO - joeynmt.training - Epoch  10, Step:    25300, Batch Loss:    25.644707, Tokens per Sec:     3688, Lr: 0.000200
2022-01-18 12:09:47,032 - INFO - joeynmt.training - Epoch  10, Step:    25400, Batch Loss:    32.375656, Tokens per Sec:     3516, Lr: 0.000200
2022-01-18 12:10:05,758 - INFO - joeynmt.training - Epoch  10, Step:    25500, Batch Loss:    56.941643, Tokens per Sec:     3678, Lr: 0.000200
2022-01-18 12:10:24,412 - INFO - joeynmt.training - Epoch  10, Step:    25600, Batch Loss:    34.406727, Tokens per Sec:     3577, Lr: 0.000200
2022-01-18 12:10:43,421 - INFO - joeynmt.training - Epoch  10, Step:    25700, Batch Loss:    62.088943, Tokens per Sec:     3636, Lr: 0.000200
2022-01-18 12:11:01,960 - INFO - joeynmt.training - Epoch  10, Step:    25800, Batch Loss:    37.741386, Tokens per Sec:     3757, Lr: 0.000200
2022-01-18 12:11:20,814 - INFO - joeynmt.training - Epoch  10, Step:    25900, Batch Loss:    37.507992, Tokens per Sec:     3551, Lr: 0.000200
2022-01-18 12:11:39,623 - INFO - joeynmt.training - Epoch  10, Step:    26000, Batch Loss:    26.751877, Tokens per Sec:     3643, Lr: 0.000200
2022-01-18 12:15:43,564 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 12:16:16,620 - INFO - joeynmt.helpers - delete models/B_ablation/25000.ckpt
2022-01-18 12:16:16,701 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/25000.ckpt
2022-01-18 12:16:16,701 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/25000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/25000.ckpt')
2022-01-18 12:16:16,722 - INFO - joeynmt.training - Example #0
2022-01-18 12:16:16,722 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 12:16:16,722 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 12:16:16,722 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 25 7 | 8 5 | 37 17 | 33 13 | 14 12
2022-01-18 12:16:16,722 - INFO - joeynmt.training - Example #1
2022-01-18 12:16:16,722 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 12:16:16,722 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 12:16:16,723 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 51 | 17 41 | 20 67 | 21 46 | 19 1 | 71 6 | 14 61 | 56 42 | 16 10 | 22 23 | 66 37 | 36 59 | 30 67 | 26 59 | 21 50
2022-01-18 12:16:16,723 - INFO - joeynmt.training - Example #2
2022-01-18 12:16:16,723 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 12:16:16,723 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:16:16,723 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 16 | 4 40 | 11 45 | 21 47 | 42 5 | 39 6 | 22 48 | 19 30
2022-01-18 12:16:16,723 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    26000: bleu:  32.36, loss: 209216.0938, ppl:   3.6668, duration: 277.0995s
2022-01-18 12:16:35,551 - INFO - joeynmt.training - Epoch  10, Step:    26100, Batch Loss:    27.315887, Tokens per Sec:     3534, Lr: 0.000200
2022-01-18 12:16:54,187 - INFO - joeynmt.training - Epoch  10, Step:    26200, Batch Loss:    31.091547, Tokens per Sec:     3577, Lr: 0.000200
2022-01-18 12:17:12,364 - INFO - joeynmt.training - Epoch  10, Step:    26300, Batch Loss:    26.091427, Tokens per Sec:     3750, Lr: 0.000200
2022-01-18 12:17:30,895 - INFO - joeynmt.training - Epoch  10, Step:    26400, Batch Loss:    25.448553, Tokens per Sec:     3666, Lr: 0.000200
2022-01-18 12:17:49,135 - INFO - joeynmt.training - Epoch  10, Step:    26500, Batch Loss:    38.113331, Tokens per Sec:     3568, Lr: 0.000200
2022-01-18 12:18:05,449 - INFO - joeynmt.training - Epoch  10: total training loss 93630.70
2022-01-18 12:18:05,449 - INFO - joeynmt.training - EPOCH 11
2022-01-18 12:18:07,939 - INFO - joeynmt.training - Epoch  11, Step:    26600, Batch Loss:    37.511024, Tokens per Sec:     3839, Lr: 0.000200
2022-01-18 12:18:26,197 - INFO - joeynmt.training - Epoch  11, Step:    26700, Batch Loss:    44.608284, Tokens per Sec:     3674, Lr: 0.000200
2022-01-18 12:18:44,892 - INFO - joeynmt.training - Epoch  11, Step:    26800, Batch Loss:    21.126144, Tokens per Sec:     3580, Lr: 0.000200
2022-01-18 12:19:03,275 - INFO - joeynmt.training - Epoch  11, Step:    26900, Batch Loss:    16.503860, Tokens per Sec:     3758, Lr: 0.000200
2022-01-18 12:19:21,362 - INFO - joeynmt.training - Epoch  11, Step:    27000, Batch Loss:    28.309872, Tokens per Sec:     3723, Lr: 0.000200
2022-01-18 12:23:26,233 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 12:23:59,315 - INFO - joeynmt.helpers - delete models/B_ablation/26000.ckpt
2022-01-18 12:23:59,389 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/26000.ckpt
2022-01-18 12:23:59,390 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/26000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/26000.ckpt')
2022-01-18 12:23:59,413 - INFO - joeynmt.training - Example #0
2022-01-18 12:23:59,413 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 12:23:59,413 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 12:23:59,413 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 28 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 12:23:59,413 - INFO - joeynmt.training - Example #1
2022-01-18 12:23:59,413 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 12:23:59,413 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 12:23:59,413 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 50 | 65 74 | 32 1 | 8 51 | 12 67 | 17 73 | 20 42 | 19 10 | 71 6 | 14 61 | 56 23 | 16 59 | 22 37 | 66 74 | 30 67 | 36 51 | 26 0 | 30 50
2022-01-18 12:23:59,414 - INFO - joeynmt.training - Example #2
2022-01-18 12:23:59,414 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 12:23:59,414 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:23:59,414 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 16 | 11 40 | 21 30 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:23:59,414 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    27000: bleu:  33.29, loss: 207719.6562, ppl:   3.6329, duration: 278.0511s
2022-01-18 12:24:17,905 - INFO - joeynmt.training - Epoch  11, Step:    27100, Batch Loss:    31.823591, Tokens per Sec:     3640, Lr: 0.000200
2022-01-18 12:24:36,653 - INFO - joeynmt.training - Epoch  11, Step:    27200, Batch Loss:    30.295858, Tokens per Sec:     3578, Lr: 0.000200
2022-01-18 12:24:55,113 - INFO - joeynmt.training - Epoch  11, Step:    27300, Batch Loss:    36.803314, Tokens per Sec:     3578, Lr: 0.000200
2022-01-18 12:25:13,562 - INFO - joeynmt.training - Epoch  11, Step:    27400, Batch Loss:    49.260010, Tokens per Sec:     3594, Lr: 0.000200
2022-01-18 12:25:32,065 - INFO - joeynmt.training - Epoch  11, Step:    27500, Batch Loss:    23.255053, Tokens per Sec:     3742, Lr: 0.000200
2022-01-18 12:25:50,453 - INFO - joeynmt.training - Epoch  11, Step:    27600, Batch Loss:    35.122028, Tokens per Sec:     3684, Lr: 0.000200
2022-01-18 12:26:09,056 - INFO - joeynmt.training - Epoch  11, Step:    27700, Batch Loss:    17.015358, Tokens per Sec:     3663, Lr: 0.000200
2022-01-18 12:26:27,601 - INFO - joeynmt.training - Epoch  11, Step:    27800, Batch Loss:    14.428610, Tokens per Sec:     3690, Lr: 0.000200
2022-01-18 12:26:46,212 - INFO - joeynmt.training - Epoch  11, Step:    27900, Batch Loss:    38.497547, Tokens per Sec:     3704, Lr: 0.000200
2022-01-18 12:27:04,607 - INFO - joeynmt.training - Epoch  11, Step:    28000, Batch Loss:    23.291157, Tokens per Sec:     3671, Lr: 0.000200
2022-01-18 12:31:06,590 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 12:31:39,384 - INFO - joeynmt.helpers - delete models/B_ablation/27000.ckpt
2022-01-18 12:31:39,463 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/27000.ckpt
2022-01-18 12:31:39,463 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/27000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/27000.ckpt')
2022-01-18 12:31:39,484 - INFO - joeynmt.training - Example #0
2022-01-18 12:31:39,484 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 12:31:39,484 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 12:31:39,484 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 28 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 12:31:39,484 - INFO - joeynmt.training - Example #1
2022-01-18 12:31:39,484 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 12:31:39,484 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 12:31:39,485 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 7 | 8 1 | 12 51 | 17 46 | 20 67 | 21 41 | 19 6 | 71 61 | 14 23 | 56 59 | 16 10 | 22 37 | 66 42 | 36 73 | 30 59 | 26 67
2022-01-18 12:31:39,485 - INFO - joeynmt.training - Example #2
2022-01-18 12:31:39,485 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 12:31:39,485 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:31:39,485 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 2 | 37 48 | 4 40 | 11 16 | 21 30 | 42 47 | 39 6 | 22 5 | 19 45
2022-01-18 12:31:39,485 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    28000: bleu:  33.89, loss: 205897.9062, ppl:   3.5920, duration: 274.8771s
2022-01-18 12:31:57,236 - INFO - joeynmt.training - Epoch  11, Step:    28100, Batch Loss:    31.631758, Tokens per Sec:     3838, Lr: 0.000200
2022-01-18 12:32:16,070 - INFO - joeynmt.training - Epoch  11, Step:    28200, Batch Loss:    24.041313, Tokens per Sec:     3549, Lr: 0.000200
2022-01-18 12:32:34,332 - INFO - joeynmt.training - Epoch  11, Step:    28300, Batch Loss:    44.699089, Tokens per Sec:     3781, Lr: 0.000200
2022-01-18 12:32:52,768 - INFO - joeynmt.training - Epoch  11, Step:    28400, Batch Loss:    52.219963, Tokens per Sec:     3635, Lr: 0.000200
2022-01-18 12:33:12,148 - INFO - joeynmt.training - Epoch  11, Step:    28500, Batch Loss:    21.134874, Tokens per Sec:     3534, Lr: 0.000200
2022-01-18 12:33:31,481 - INFO - joeynmt.training - Epoch  11, Step:    28600, Batch Loss:    17.957836, Tokens per Sec:     3498, Lr: 0.000200
2022-01-18 12:33:50,268 - INFO - joeynmt.training - Epoch  11, Step:    28700, Batch Loss:    24.264257, Tokens per Sec:     3595, Lr: 0.000200
2022-01-18 12:34:08,954 - INFO - joeynmt.training - Epoch  11, Step:    28800, Batch Loss:    58.043304, Tokens per Sec:     3644, Lr: 0.000200
2022-01-18 12:34:27,359 - INFO - joeynmt.training - Epoch  11, Step:    28900, Batch Loss:    15.927586, Tokens per Sec:     3801, Lr: 0.000200
2022-01-18 12:34:45,815 - INFO - joeynmt.training - Epoch  11, Step:    29000, Batch Loss:    40.442493, Tokens per Sec:     3785, Lr: 0.000200
2022-01-18 12:38:46,625 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 12:39:19,314 - INFO - joeynmt.helpers - delete models/B_ablation/28000.ckpt
2022-01-18 12:39:19,391 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/28000.ckpt
2022-01-18 12:39:19,392 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/28000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/28000.ckpt')
2022-01-18 12:39:19,424 - INFO - joeynmt.training - Example #0
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 25 7 | 37 5 | 8 17 | 33 13
2022-01-18 12:39:19,424 - INFO - joeynmt.training - Example #1
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 74 | 32 7 | 8 1 | 12 41 | 17 46 | 20 67 | 21 51 | 19 61 | 71 6 | 14 23 | 56 10 | 16 42 | 22 37 | 66 None | 36 None | 26 59 | 30 None
2022-01-18 12:39:19,424 - INFO - joeynmt.training - Example #2
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:39:19,424 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 16 | 11 40 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:39:19,424 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    29000: bleu:  34.50, loss: 200569.2188, ppl:   3.4751, duration: 273.6088s
2022-01-18 12:39:37,774 - INFO - joeynmt.training - Epoch  11, Step:    29100, Batch Loss:    20.598450, Tokens per Sec:     3638, Lr: 0.000200
2022-01-18 12:39:56,189 - INFO - joeynmt.training - Epoch  11, Step:    29200, Batch Loss:    46.661690, Tokens per Sec:     3677, Lr: 0.000200
2022-01-18 12:40:01,479 - INFO - joeynmt.training - Epoch  11: total training loss 88686.16
2022-01-18 12:40:01,479 - INFO - joeynmt.training - EPOCH 12
2022-01-18 12:40:14,335 - INFO - joeynmt.training - Epoch  12, Step:    29300, Batch Loss:    28.370541, Tokens per Sec:     3719, Lr: 0.000200
2022-01-18 12:40:32,806 - INFO - joeynmt.training - Epoch  12, Step:    29400, Batch Loss:    36.989182, Tokens per Sec:     3697, Lr: 0.000200
2022-01-18 12:40:51,296 - INFO - joeynmt.training - Epoch  12, Step:    29500, Batch Loss:    21.190744, Tokens per Sec:     3610, Lr: 0.000200
2022-01-18 12:41:09,782 - INFO - joeynmt.training - Epoch  12, Step:    29600, Batch Loss:    44.922352, Tokens per Sec:     3681, Lr: 0.000200
2022-01-18 12:41:28,191 - INFO - joeynmt.training - Epoch  12, Step:    29700, Batch Loss:    28.435246, Tokens per Sec:     3728, Lr: 0.000200
2022-01-18 12:41:46,871 - INFO - joeynmt.training - Epoch  12, Step:    29800, Batch Loss:    31.786345, Tokens per Sec:     3802, Lr: 0.000200
2022-01-18 12:42:05,378 - INFO - joeynmt.training - Epoch  12, Step:    29900, Batch Loss:    49.863747, Tokens per Sec:     3694, Lr: 0.000200
2022-01-18 12:42:23,797 - INFO - joeynmt.training - Epoch  12, Step:    30000, Batch Loss:    29.054989, Tokens per Sec:     3684, Lr: 0.000200
2022-01-18 12:46:33,040 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 12:47:05,925 - INFO - joeynmt.helpers - delete models/B_ablation/29000.ckpt
2022-01-18 12:47:06,006 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/29000.ckpt
2022-01-18 12:47:06,007 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/29000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/29000.ckpt')
2022-01-18 12:47:06,037 - INFO - joeynmt.training - Example #0
2022-01-18 12:47:06,037 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 12:47:06,037 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 12:47:06,038 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 25 5 | 37 17 | 8 13 | 33 12 | 25 19
2022-01-18 12:47:06,038 - INFO - joeynmt.training - Example #1
2022-01-18 12:47:06,038 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 12:47:06,038 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 12:47:06,038 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 50 | 32 0 | 8 41 | 17 46 | 21 67 | 20 51 | 71 1 | 19 61 | 14 6 | 56 23 | 16 10 | 22 73 | 66 42 | 36 37 | 26 59 | 30 67 | 12 74
2022-01-18 12:47:06,038 - INFO - joeynmt.training - Example #2
2022-01-18 12:47:06,038 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 12:47:06,038 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:47:06,038 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:47:06,038 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    30000: bleu:  35.50, loss: 200776.8594, ppl:   3.4796, duration: 282.2411s
2022-01-18 12:47:24,609 - INFO - joeynmt.training - Epoch  12, Step:    30100, Batch Loss:    33.360123, Tokens per Sec:     3663, Lr: 0.000200
2022-01-18 12:47:43,005 - INFO - joeynmt.training - Epoch  12, Step:    30200, Batch Loss:    21.196735, Tokens per Sec:     3636, Lr: 0.000200
2022-01-18 12:48:01,599 - INFO - joeynmt.training - Epoch  12, Step:    30300, Batch Loss:    24.349882, Tokens per Sec:     3595, Lr: 0.000200
2022-01-18 12:48:20,272 - INFO - joeynmt.training - Epoch  12, Step:    30400, Batch Loss:    27.840221, Tokens per Sec:     3626, Lr: 0.000200
2022-01-18 12:48:39,114 - INFO - joeynmt.training - Epoch  12, Step:    30500, Batch Loss:    60.604576, Tokens per Sec:     3415, Lr: 0.000200
2022-01-18 12:48:58,136 - INFO - joeynmt.training - Epoch  12, Step:    30600, Batch Loss:    29.735792, Tokens per Sec:     3495, Lr: 0.000200
2022-01-18 12:49:17,467 - INFO - joeynmt.training - Epoch  12, Step:    30700, Batch Loss:    29.636242, Tokens per Sec:     3438, Lr: 0.000200
2022-01-18 12:49:36,888 - INFO - joeynmt.training - Epoch  12, Step:    30800, Batch Loss:    38.737522, Tokens per Sec:     3493, Lr: 0.000200
2022-01-18 12:49:56,244 - INFO - joeynmt.training - Epoch  12, Step:    30900, Batch Loss:    37.808372, Tokens per Sec:     3465, Lr: 0.000200
2022-01-18 12:50:15,366 - INFO - joeynmt.training - Epoch  12, Step:    31000, Batch Loss:    22.822275, Tokens per Sec:     3491, Lr: 0.000200
2022-01-18 12:54:20,903 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 12:54:53,622 - INFO - joeynmt.helpers - delete models/B_ablation/30000.ckpt
2022-01-18 12:54:53,702 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/30000.ckpt
2022-01-18 12:54:53,703 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/30000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/30000.ckpt')
2022-01-18 12:54:53,732 - INFO - joeynmt.training - Example #0
2022-01-18 12:54:53,733 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 12:54:53,733 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 12:54:53,733 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 2 30 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 12:54:53,733 - INFO - joeynmt.training - Example #1
2022-01-18 12:54:53,733 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 12:54:53,733 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 12:54:53,733 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 7 | 32 50 | 8 1 | 12 46 | 20 67 | 21 51 | 19 61 | 71 6 | 14 23 | 56 10 | 16 42 | 22 37 | 66 59 | 36 73 | 30 73 | 26 67 | 63 37
2022-01-18 12:54:53,733 - INFO - joeynmt.training - Example #2
2022-01-18 12:54:53,733 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 12:54:53,733 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 12:54:53,734 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 40 | 11 16 | 21 48 | 42 47 | 39 6 | 22 5 | 19 45
2022-01-18 12:54:53,734 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    31000: bleu:  35.92, loss: 198836.4375, ppl:   3.4379, duration: 278.3677s
2022-01-18 12:55:12,047 - INFO - joeynmt.training - Epoch  12, Step:    31100, Batch Loss:    19.268703, Tokens per Sec:     3781, Lr: 0.000200
2022-01-18 12:55:30,338 - INFO - joeynmt.training - Epoch  12, Step:    31200, Batch Loss:    26.907064, Tokens per Sec:     3639, Lr: 0.000200
2022-01-18 12:55:48,616 - INFO - joeynmt.training - Epoch  12, Step:    31300, Batch Loss:    46.089504, Tokens per Sec:     3718, Lr: 0.000200
2022-01-18 12:56:06,987 - INFO - joeynmt.training - Epoch  12, Step:    31400, Batch Loss:    24.460720, Tokens per Sec:     3723, Lr: 0.000200
2022-01-18 12:56:25,393 - INFO - joeynmt.training - Epoch  12, Step:    31500, Batch Loss:    47.401913, Tokens per Sec:     3702, Lr: 0.000200
2022-01-18 12:56:43,887 - INFO - joeynmt.training - Epoch  12, Step:    31600, Batch Loss:    31.671087, Tokens per Sec:     3709, Lr: 0.000200
2022-01-18 12:57:02,271 - INFO - joeynmt.training - Epoch  12, Step:    31700, Batch Loss:    27.992441, Tokens per Sec:     3578, Lr: 0.000200
2022-01-18 12:57:21,441 - INFO - joeynmt.training - Epoch  12, Step:    31800, Batch Loss:    32.290676, Tokens per Sec:     3476, Lr: 0.000200
2022-01-18 12:57:37,609 - INFO - joeynmt.training - Epoch  12: total training loss 84447.99
2022-01-18 12:57:37,610 - INFO - joeynmt.training - EPOCH 13
2022-01-18 12:57:40,691 - INFO - joeynmt.training - Epoch  13, Step:    31900, Batch Loss:    20.452795, Tokens per Sec:     3478, Lr: 0.000200
2022-01-18 12:57:59,895 - INFO - joeynmt.training - Epoch  13, Step:    32000, Batch Loss:    29.191332, Tokens per Sec:     3582, Lr: 0.000200
2022-01-18 13:02:04,256 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 13:02:37,075 - INFO - joeynmt.helpers - delete models/B_ablation/31000.ckpt
2022-01-18 13:02:37,157 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/31000.ckpt
2022-01-18 13:02:37,157 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/31000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/31000.ckpt')
2022-01-18 13:02:37,178 - INFO - joeynmt.training - Example #0
2022-01-18 13:02:37,178 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 13:02:37,179 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 13:02:37,179 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 25 5 | 37 17 | 8 13 | 33 12 | 2 None
2022-01-18 13:02:37,179 - INFO - joeynmt.training - Example #1
2022-01-18 13:02:37,179 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 13:02:37,179 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 13:02:37,179 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 1 | 12 41 | 20 46 | 21 51 | 19 73 | 71 7 | 14 6 | 56 61 | 16 37 | 22 10 | 66 23 | 36 59 | 30 42 | 26 67 | 63 37
2022-01-18 13:02:37,179 - INFO - joeynmt.training - Example #2
2022-01-18 13:02:37,179 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 13:02:37,179 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:02:37,179 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 40 | 11 16 | 21 30 | 42 47 | 39 5 | 22 6 | 19 48
2022-01-18 13:02:37,179 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    32000: bleu:  36.27, loss: 198136.0781, ppl:   3.4230, duration: 277.2836s
2022-01-18 13:02:55,686 - INFO - joeynmt.training - Epoch  13, Step:    32100, Batch Loss:    18.666927, Tokens per Sec:     3657, Lr: 0.000200
2022-01-18 13:03:14,235 - INFO - joeynmt.training - Epoch  13, Step:    32200, Batch Loss:    20.316383, Tokens per Sec:     3712, Lr: 0.000200
2022-01-18 13:03:32,441 - INFO - joeynmt.training - Epoch  13, Step:    32300, Batch Loss:    24.140842, Tokens per Sec:     3687, Lr: 0.000200
2022-01-18 13:03:50,923 - INFO - joeynmt.training - Epoch  13, Step:    32400, Batch Loss:    29.131342, Tokens per Sec:     3717, Lr: 0.000200
2022-01-18 13:04:09,400 - INFO - joeynmt.training - Epoch  13, Step:    32500, Batch Loss:    31.726429, Tokens per Sec:     3545, Lr: 0.000200
2022-01-18 13:04:27,881 - INFO - joeynmt.training - Epoch  13, Step:    32600, Batch Loss:    27.793858, Tokens per Sec:     3679, Lr: 0.000200
2022-01-18 13:04:46,167 - INFO - joeynmt.training - Epoch  13, Step:    32700, Batch Loss:    22.681162, Tokens per Sec:     3579, Lr: 0.000200
2022-01-18 13:05:04,607 - INFO - joeynmt.training - Epoch  13, Step:    32800, Batch Loss:    30.522200, Tokens per Sec:     3672, Lr: 0.000200
2022-01-18 13:05:22,833 - INFO - joeynmt.training - Epoch  13, Step:    32900, Batch Loss:    23.955036, Tokens per Sec:     3701, Lr: 0.000200
2022-01-18 13:05:41,430 - INFO - joeynmt.training - Epoch  13, Step:    33000, Batch Loss:    37.437801, Tokens per Sec:     3673, Lr: 0.000200
2022-01-18 13:09:45,105 - INFO - joeynmt.training - Example #0
2022-01-18 13:09:45,106 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 13:09:45,106 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 13:09:45,106 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 13:09:45,106 - INFO - joeynmt.training - Example #1
2022-01-18 13:09:45,106 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 13:09:45,106 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 13:09:45,107 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 50 | 32 0 | 8 1 | 12 46 | 20 67 | 21 41 | 19 73 | 71 6 | 14 23 | 56 59 | 16 10 | 22 42 | 66 37 | 36 51 | 30 61 | 26 None | 58 74
2022-01-18 13:09:45,107 - INFO - joeynmt.training - Example #2
2022-01-18 13:09:45,107 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 13:09:45,107 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:09:45,107 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 2 | 37 None | 4 40 | 11 16 | 21 46 | 42 47 | 39 6 | 22 48
2022-01-18 13:09:45,107 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    33000: bleu:  36.05, loss: 196586.5469, ppl:   3.3902, duration: 243.6764s
2022-01-18 13:10:04,070 - INFO - joeynmt.training - Epoch  13, Step:    33100, Batch Loss:    28.315796, Tokens per Sec:     3571, Lr: 0.000200
2022-01-18 13:10:23,205 - INFO - joeynmt.training - Epoch  13, Step:    33200, Batch Loss:    28.268415, Tokens per Sec:     3492, Lr: 0.000200
2022-01-18 13:10:42,029 - INFO - joeynmt.training - Epoch  13, Step:    33300, Batch Loss:    28.003111, Tokens per Sec:     3567, Lr: 0.000200
2022-01-18 13:11:00,359 - INFO - joeynmt.training - Epoch  13, Step:    33400, Batch Loss:    25.152273, Tokens per Sec:     3643, Lr: 0.000200
2022-01-18 13:11:19,085 - INFO - joeynmt.training - Epoch  13, Step:    33500, Batch Loss:    19.966076, Tokens per Sec:     3754, Lr: 0.000200
2022-01-18 13:11:37,519 - INFO - joeynmt.training - Epoch  13, Step:    33600, Batch Loss:    16.591669, Tokens per Sec:     3522, Lr: 0.000200
2022-01-18 13:11:56,239 - INFO - joeynmt.training - Epoch  13, Step:    33700, Batch Loss:    55.694286, Tokens per Sec:     3666, Lr: 0.000200
2022-01-18 13:12:15,076 - INFO - joeynmt.training - Epoch  13, Step:    33800, Batch Loss:    32.561584, Tokens per Sec:     3581, Lr: 0.000200
2022-01-18 13:12:34,166 - INFO - joeynmt.training - Epoch  13, Step:    33900, Batch Loss:    23.047787, Tokens per Sec:     3545, Lr: 0.000200
2022-01-18 13:12:52,927 - INFO - joeynmt.training - Epoch  13, Step:    34000, Batch Loss:    17.747391, Tokens per Sec:     3760, Lr: 0.000200
2022-01-18 13:16:56,773 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 13:17:29,457 - INFO - joeynmt.helpers - delete models/B_ablation/32000.ckpt
2022-01-18 13:17:29,535 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/32000.ckpt
2022-01-18 13:17:29,536 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/32000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/32000.ckpt')
2022-01-18 13:17:29,556 - INFO - joeynmt.training - Example #0
2022-01-18 13:17:29,556 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 13:17:29,556 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 13:17:29,556 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 30 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 13:17:29,556 - INFO - joeynmt.training - Example #1
2022-01-18 13:17:29,556 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 13:17:29,556 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 13:17:29,556 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 74 | 32 50 | 8 51 | 21 41 | 20 1 | 19 73 | 71 67 | 14 6 | 56 23 | 16 61 | 22 37 | 66 42 | 36 10 | 30 59 | 26 None | 12 73 | 17 37
2022-01-18 13:17:29,556 - INFO - joeynmt.training - Example #2
2022-01-18 13:17:29,557 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 13:17:29,557 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:17:29,557 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:17:29,557 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    34000: bleu:  37.20, loss: 192344.0469, ppl:   3.3020, duration: 276.6297s
2022-01-18 13:17:48,085 - INFO - joeynmt.training - Epoch  13, Step:    34100, Batch Loss:    46.281471, Tokens per Sec:     3620, Lr: 0.000200
2022-01-18 13:18:06,460 - INFO - joeynmt.training - Epoch  13, Step:    34200, Batch Loss:    14.928256, Tokens per Sec:     3757, Lr: 0.000200
2022-01-18 13:18:24,564 - INFO - joeynmt.training - Epoch  13, Step:    34300, Batch Loss:    23.633163, Tokens per Sec:     3702, Lr: 0.000200
2022-01-18 13:18:42,978 - INFO - joeynmt.training - Epoch  13, Step:    34400, Batch Loss:    28.351471, Tokens per Sec:     3665, Lr: 0.000200
2022-01-18 13:19:01,078 - INFO - joeynmt.training - Epoch  13, Step:    34500, Batch Loss:    28.341442, Tokens per Sec:     3740, Lr: 0.000200
2022-01-18 13:19:07,454 - INFO - joeynmt.training - Epoch  13: total training loss 80928.95
2022-01-18 13:19:07,454 - INFO - joeynmt.training - EPOCH 14
2022-01-18 13:19:19,667 - INFO - joeynmt.training - Epoch  14, Step:    34600, Batch Loss:    35.525478, Tokens per Sec:     3698, Lr: 0.000200
2022-01-18 13:19:38,142 - INFO - joeynmt.training - Epoch  14, Step:    34700, Batch Loss:    30.262260, Tokens per Sec:     3749, Lr: 0.000200
2022-01-18 13:19:56,547 - INFO - joeynmt.training - Epoch  14, Step:    34800, Batch Loss:    28.418747, Tokens per Sec:     3741, Lr: 0.000200
2022-01-18 13:20:14,937 - INFO - joeynmt.training - Epoch  14, Step:    34900, Batch Loss:    26.360098, Tokens per Sec:     3629, Lr: 0.000200
2022-01-18 13:20:33,278 - INFO - joeynmt.training - Epoch  14, Step:    35000, Batch Loss:    20.379297, Tokens per Sec:     3690, Lr: 0.000200
2022-01-18 13:24:36,377 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 13:25:09,218 - INFO - joeynmt.helpers - delete models/B_ablation/34000.ckpt
2022-01-18 13:25:09,300 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/34000.ckpt
2022-01-18 13:25:09,301 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/34000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/34000.ckpt')
2022-01-18 13:25:09,322 - INFO - joeynmt.training - Example #0
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 13:25:09,322 - INFO - joeynmt.training - Example #1
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 7 | 32 74 | 8 1 | 17 51 | 12 50 | 20 67 | 19 23 | 71 6 | 14 61 | 56 59 | 16 37 | 22 42 | 72 10 | 66 57 | 36 None | 30 7 | 26 0
2022-01-18 13:25:09,322 - INFO - joeynmt.training - Example #2
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:25:09,322 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 2 | 37 None | 4 16 | 11 40 | 21 46 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:25:09,322 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    35000: bleu:  37.35, loss: 191798.5000, ppl:   3.2909, duration: 276.0436s
2022-01-18 13:25:27,788 - INFO - joeynmt.training - Epoch  14, Step:    35100, Batch Loss:    18.852171, Tokens per Sec:     3593, Lr: 0.000200
2022-01-18 13:25:46,225 - INFO - joeynmt.training - Epoch  14, Step:    35200, Batch Loss:    39.306046, Tokens per Sec:     3638, Lr: 0.000200
2022-01-18 13:26:05,180 - INFO - joeynmt.training - Epoch  14, Step:    35300, Batch Loss:    37.766407, Tokens per Sec:     3695, Lr: 0.000200
2022-01-18 13:26:23,577 - INFO - joeynmt.training - Epoch  14, Step:    35400, Batch Loss:    44.458595, Tokens per Sec:     3604, Lr: 0.000200
2022-01-18 13:26:42,062 - INFO - joeynmt.training - Epoch  14, Step:    35500, Batch Loss:    31.133978, Tokens per Sec:     3725, Lr: 0.000200
2022-01-18 13:27:00,751 - INFO - joeynmt.training - Epoch  14, Step:    35600, Batch Loss:    22.842535, Tokens per Sec:     3559, Lr: 0.000200
2022-01-18 13:27:19,313 - INFO - joeynmt.training - Epoch  14, Step:    35700, Batch Loss:    23.518078, Tokens per Sec:     3666, Lr: 0.000200
2022-01-18 13:27:37,777 - INFO - joeynmt.training - Epoch  14, Step:    35800, Batch Loss:    18.232582, Tokens per Sec:     3687, Lr: 0.000200
2022-01-18 13:27:56,107 - INFO - joeynmt.training - Epoch  14, Step:    35900, Batch Loss:    12.566750, Tokens per Sec:     3634, Lr: 0.000200
2022-01-18 13:28:14,774 - INFO - joeynmt.training - Epoch  14, Step:    36000, Batch Loss:    28.532434, Tokens per Sec:     3688, Lr: 0.000200
2022-01-18 13:32:15,562 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 13:32:48,627 - INFO - joeynmt.helpers - delete models/B_ablation/35000.ckpt
2022-01-18 13:32:48,707 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/35000.ckpt
2022-01-18 13:32:48,708 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/35000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/35000.ckpt')
2022-01-18 13:32:48,730 - INFO - joeynmt.training - Example #0
2022-01-18 13:32:48,730 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 13:32:48,730 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 13:32:48,730 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 2 7 | 25 5 | 37 13 | 8 12 | 33 17
2022-01-18 13:32:48,730 - INFO - joeynmt.training - Example #1
2022-01-18 13:32:48,730 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 13:32:48,730 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 13:32:48,730 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 20 41 | 21 67 | 19 53 | 71 23 | 14 6 | 56 61 | 16 10 | 22 42 | 66 37 | 36 73 | 30 59 | 26 None | 17 None
2022-01-18 13:32:48,730 - INFO - joeynmt.training - Example #2
2022-01-18 13:32:48,731 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 13:32:48,731 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:32:48,731 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 40 | 11 16 | 21 30 | 42 47 | 39 6 | 22 48 | 19 5
2022-01-18 13:32:48,731 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    36000: bleu:  38.20, loss: 190651.6094, ppl:   3.2675, duration: 273.9564s
2022-01-18 13:33:07,114 - INFO - joeynmt.training - Epoch  14, Step:    36100, Batch Loss:    27.670910, Tokens per Sec:     3624, Lr: 0.000200
2022-01-18 13:33:25,676 - INFO - joeynmt.training - Epoch  14, Step:    36200, Batch Loss:    14.464202, Tokens per Sec:     3582, Lr: 0.000200
2022-01-18 13:33:43,949 - INFO - joeynmt.training - Epoch  14, Step:    36300, Batch Loss:    42.951466, Tokens per Sec:     3696, Lr: 0.000200
2022-01-18 13:34:02,390 - INFO - joeynmt.training - Epoch  14, Step:    36400, Batch Loss:    24.866877, Tokens per Sec:     3705, Lr: 0.000200
2022-01-18 13:34:20,869 - INFO - joeynmt.training - Epoch  14, Step:    36500, Batch Loss:    18.914335, Tokens per Sec:     3695, Lr: 0.000200
2022-01-18 13:34:39,093 - INFO - joeynmt.training - Epoch  14, Step:    36600, Batch Loss:    31.407446, Tokens per Sec:     3754, Lr: 0.000200
2022-01-18 13:34:57,535 - INFO - joeynmt.training - Epoch  14, Step:    36700, Batch Loss:    31.193163, Tokens per Sec:     3717, Lr: 0.000200
2022-01-18 13:35:16,072 - INFO - joeynmt.training - Epoch  14, Step:    36800, Batch Loss:    18.069607, Tokens per Sec:     3589, Lr: 0.000200
2022-01-18 13:35:34,362 - INFO - joeynmt.training - Epoch  14, Step:    36900, Batch Loss:    39.618382, Tokens per Sec:     3655, Lr: 0.000200
2022-01-18 13:35:53,074 - INFO - joeynmt.training - Epoch  14, Step:    37000, Batch Loss:    16.308926, Tokens per Sec:     3566, Lr: 0.000200
2022-01-18 13:39:55,231 - INFO - joeynmt.training - Example #0
2022-01-18 13:39:55,231 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 13:39:55,231 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 13:39:55,231 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 13:39:55,231 - INFO - joeynmt.training - Example #1
2022-01-18 13:39:55,232 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 13:39:55,232 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 13:39:55,232 - INFO - joeynmt.training - 	Hypothesis: 13 7 | 35 0 | 65 50 | 32 74 | 8 51 | 17 46 | 12 41 | 20 67 | 19 42 | 71 10 | 14 23 | 56 37 | 16 6 | 22 None | 72 59 | 66 42 | 30 61 | 26 None | 36 None
2022-01-18 13:39:55,232 - INFO - joeynmt.training - Example #2
2022-01-18 13:39:55,232 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 13:39:55,232 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:39:55,232 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 16 | 11 40 | 21 47 | 42 5 | 39 30 | 19 48
2022-01-18 13:39:55,232 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    37000: bleu:  37.92, loss: 190626.5312, ppl:   3.2670, duration: 242.1576s
2022-01-18 13:40:13,987 - INFO - joeynmt.training - Epoch  14, Step:    37100, Batch Loss:    18.849344, Tokens per Sec:     3680, Lr: 0.000200
2022-01-18 13:40:29,674 - INFO - joeynmt.training - Epoch  14: total training loss 77939.30
2022-01-18 13:40:29,675 - INFO - joeynmt.training - EPOCH 15
2022-01-18 13:40:32,916 - INFO - joeynmt.training - Epoch  15, Step:    37200, Batch Loss:    39.712322, Tokens per Sec:     3487, Lr: 0.000200
2022-01-18 13:40:51,646 - INFO - joeynmt.training - Epoch  15, Step:    37300, Batch Loss:    17.001549, Tokens per Sec:     3689, Lr: 0.000200
2022-01-18 13:41:10,108 - INFO - joeynmt.training - Epoch  15, Step:    37400, Batch Loss:    24.067228, Tokens per Sec:     3597, Lr: 0.000200
2022-01-18 13:41:28,490 - INFO - joeynmt.training - Epoch  15, Step:    37500, Batch Loss:    32.044487, Tokens per Sec:     3658, Lr: 0.000200
2022-01-18 13:41:47,032 - INFO - joeynmt.training - Epoch  15, Step:    37600, Batch Loss:    25.523193, Tokens per Sec:     3690, Lr: 0.000200
2022-01-18 13:42:05,767 - INFO - joeynmt.training - Epoch  15, Step:    37700, Batch Loss:    18.026035, Tokens per Sec:     3726, Lr: 0.000200
2022-01-18 13:42:24,184 - INFO - joeynmt.training - Epoch  15, Step:    37800, Batch Loss:    18.941832, Tokens per Sec:     3734, Lr: 0.000200
2022-01-18 13:42:42,401 - INFO - joeynmt.training - Epoch  15, Step:    37900, Batch Loss:    17.676498, Tokens per Sec:     3730, Lr: 0.000200
2022-01-18 13:43:01,192 - INFO - joeynmt.training - Epoch  15, Step:    38000, Batch Loss:    41.931427, Tokens per Sec:     3647, Lr: 0.000200
2022-01-18 13:47:03,961 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 13:47:36,733 - INFO - joeynmt.helpers - delete models/B_ablation/36000.ckpt
2022-01-18 13:47:36,815 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/36000.ckpt
2022-01-18 13:47:36,816 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/36000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/36000.ckpt')
2022-01-18 13:47:36,837 - INFO - joeynmt.training - Example #0
2022-01-18 13:47:36,837 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 13:47:36,837 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 13:47:36,837 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 13:47:36,837 - INFO - joeynmt.training - Example #1
2022-01-18 13:47:36,837 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 13:47:36,837 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 13:47:36,837 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 50 | 65 74 | 32 7 | 8 51 | 21 41 | 20 67 | 19 73 | 71 1 | 14 6 | 56 23 | 16 61 | 22 42 | 72 10 | 66 37 | 30 63 | 36 None | 26 None | 30 None
2022-01-18 13:47:36,837 - INFO - joeynmt.training - Example #2
2022-01-18 13:47:36,837 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 13:47:36,838 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:47:36,838 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 2 | 37 None | 4 16 | 11 40 | 21 47 | 42 6 | 39 5 | 22 48 | 19 30
2022-01-18 13:47:36,838 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    38000: bleu:  39.41, loss: 188357.0625, ppl:   3.2213, duration: 275.6452s
2022-01-18 13:47:55,203 - INFO - joeynmt.training - Epoch  15, Step:    38100, Batch Loss:    18.366964, Tokens per Sec:     3747, Lr: 0.000200
2022-01-18 13:48:13,724 - INFO - joeynmt.training - Epoch  15, Step:    38200, Batch Loss:    41.854076, Tokens per Sec:     3659, Lr: 0.000200
2022-01-18 13:48:32,114 - INFO - joeynmt.training - Epoch  15, Step:    38300, Batch Loss:    18.406467, Tokens per Sec:     3725, Lr: 0.000200
2022-01-18 13:48:50,416 - INFO - joeynmt.training - Epoch  15, Step:    38400, Batch Loss:    47.004421, Tokens per Sec:     3662, Lr: 0.000200
2022-01-18 13:49:08,958 - INFO - joeynmt.training - Epoch  15, Step:    38500, Batch Loss:    31.235334, Tokens per Sec:     3652, Lr: 0.000200
2022-01-18 13:49:27,344 - INFO - joeynmt.training - Epoch  15, Step:    38600, Batch Loss:    30.308834, Tokens per Sec:     3679, Lr: 0.000200
2022-01-18 13:49:45,674 - INFO - joeynmt.training - Epoch  15, Step:    38700, Batch Loss:    19.391428, Tokens per Sec:     3631, Lr: 0.000200
2022-01-18 13:50:04,278 - INFO - joeynmt.training - Epoch  15, Step:    38800, Batch Loss:    24.304350, Tokens per Sec:     3663, Lr: 0.000200
2022-01-18 13:50:22,800 - INFO - joeynmt.training - Epoch  15, Step:    38900, Batch Loss:    53.262466, Tokens per Sec:     3545, Lr: 0.000200
2022-01-18 13:50:41,357 - INFO - joeynmt.training - Epoch  15, Step:    39000, Batch Loss:    31.948515, Tokens per Sec:     3676, Lr: 0.000200
2022-01-18 13:54:44,601 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 13:55:23,924 - INFO - joeynmt.helpers - delete models/B_ablation/38000.ckpt
2022-01-18 13:55:24,023 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/38000.ckpt
2022-01-18 13:55:24,035 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/38000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/38000.ckpt')
2022-01-18 13:55:24,104 - INFO - joeynmt.training - Example #0
2022-01-18 13:55:24,104 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 13:55:24,104 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 13:55:24,104 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 13:55:24,104 - INFO - joeynmt.training - Example #1
2022-01-18 13:55:24,104 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 13:55:24,104 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 13:55:24,104 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 50 | 32 74 | 8 51 | 12 46 | 20 67 | 21 41 | 19 0 | 14 61 | 56 59 | 16 23 | 22 37 | 72 10 | 66 42 | 36 6 | 30 70 | 26 70
2022-01-18 13:55:24,104 - INFO - joeynmt.training - Example #2
2022-01-18 13:55:24,105 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 13:55:24,105 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 13:55:24,105 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 16 | 11 2 | 21 47 | 42 6 | 39 5 | 19 48 | 22 30
2022-01-18 13:55:24,105 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    39000: bleu:  39.72, loss: 186182.3281, ppl:   3.1781, duration: 282.7477s
2022-01-18 13:55:42,997 - INFO - joeynmt.training - Epoch  15, Step:    39100, Batch Loss:    23.401648, Tokens per Sec:     3593, Lr: 0.000200
2022-01-18 13:56:16,139 - INFO - joeynmt.training - Epoch  15, Step:    39200, Batch Loss:    28.955414, Tokens per Sec:     2061, Lr: 0.000200
2022-01-18 13:57:05,889 - INFO - joeynmt.training - Epoch  15, Step:    39300, Batch Loss:    15.146278, Tokens per Sec:     1338, Lr: 0.000200
2022-01-18 13:57:32,932 - INFO - joeynmt.training - Epoch  15, Step:    39400, Batch Loss:    17.353348, Tokens per Sec:     2485, Lr: 0.000200
2022-01-18 13:57:51,177 - INFO - joeynmt.training - Epoch  15, Step:    39500, Batch Loss:    22.335575, Tokens per Sec:     3710, Lr: 0.000200
2022-01-18 13:58:09,775 - INFO - joeynmt.training - Epoch  15, Step:    39600, Batch Loss:    35.265659, Tokens per Sec:     3540, Lr: 0.000200
2022-01-18 13:58:27,769 - INFO - joeynmt.training - Epoch  15, Step:    39700, Batch Loss:    25.244024, Tokens per Sec:     3746, Lr: 0.000200
2022-01-18 13:58:45,951 - INFO - joeynmt.training - Epoch  15, Step:    39800, Batch Loss:    39.772686, Tokens per Sec:     3648, Lr: 0.000200
2022-01-18 13:58:51,935 - INFO - joeynmt.training - Epoch  15: total training loss 74897.47
2022-01-18 13:58:51,936 - INFO - joeynmt.training - EPOCH 16
2022-01-18 13:59:04,026 - INFO - joeynmt.training - Epoch  16, Step:    39900, Batch Loss:    25.993124, Tokens per Sec:     3759, Lr: 0.000200
2022-01-18 13:59:22,172 - INFO - joeynmt.training - Epoch  16, Step:    40000, Batch Loss:    17.288033, Tokens per Sec:     3590, Lr: 0.000200
2022-01-18 14:03:20,429 - INFO - joeynmt.training - Example #0
2022-01-18 14:03:20,430 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 14:03:20,430 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 14:03:20,430 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 14:03:20,430 - INFO - joeynmt.training - Example #1
2022-01-18 14:03:20,430 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 14:03:20,430 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 14:03:20,430 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 74 | 8 51 | 12 46 | 20 67 | 21 41 | 19 42 | 71 53 | 14 6 | 56 61 | 16 23 | 22 10 | 72 59 | 66 37 | 30 73 | 26 67
2022-01-18 14:03:20,430 - INFO - joeynmt.training - Example #2
2022-01-18 14:03:20,430 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 14:03:20,430 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:03:20,431 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 30
2022-01-18 14:03:20,431 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    40000: bleu:  39.28, loss: 189859.7500, ppl:   3.2515, duration: 238.2585s
2022-01-18 14:03:39,109 - INFO - joeynmt.training - Epoch  16, Step:    40100, Batch Loss:    21.862120, Tokens per Sec:     3694, Lr: 0.000200
2022-01-18 14:03:57,470 - INFO - joeynmt.training - Epoch  16, Step:    40200, Batch Loss:    16.810091, Tokens per Sec:     3700, Lr: 0.000200
2022-01-18 14:04:15,666 - INFO - joeynmt.training - Epoch  16, Step:    40300, Batch Loss:    31.849867, Tokens per Sec:     3599, Lr: 0.000200
2022-01-18 14:04:34,101 - INFO - joeynmt.training - Epoch  16, Step:    40400, Batch Loss:    48.812294, Tokens per Sec:     3743, Lr: 0.000200
2022-01-18 14:04:52,680 - INFO - joeynmt.training - Epoch  16, Step:    40500, Batch Loss:    40.280449, Tokens per Sec:     3726, Lr: 0.000200
2022-01-18 14:05:10,933 - INFO - joeynmt.training - Epoch  16, Step:    40600, Batch Loss:    22.675716, Tokens per Sec:     3714, Lr: 0.000200
2022-01-18 14:05:29,419 - INFO - joeynmt.training - Epoch  16, Step:    40700, Batch Loss:    72.552582, Tokens per Sec:     3707, Lr: 0.000200
2022-01-18 14:05:48,170 - INFO - joeynmt.training - Epoch  16, Step:    40800, Batch Loss:    28.898678, Tokens per Sec:     3568, Lr: 0.000200
2022-01-18 14:06:06,496 - INFO - joeynmt.training - Epoch  16, Step:    40900, Batch Loss:    17.438490, Tokens per Sec:     3566, Lr: 0.000200
2022-01-18 14:06:25,006 - INFO - joeynmt.training - Epoch  16, Step:    41000, Batch Loss:    60.405991, Tokens per Sec:     3719, Lr: 0.000200
2022-01-18 14:10:27,964 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 14:11:01,127 - INFO - joeynmt.helpers - delete models/B_ablation/39000.ckpt
2022-01-18 14:11:01,210 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/39000.ckpt
2022-01-18 14:11:01,210 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/39000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/39000.ckpt')
2022-01-18 14:11:01,231 - INFO - joeynmt.training - Example #0
2022-01-18 14:11:01,231 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 14:11:01,231 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 14:11:01,231 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 14:11:01,231 - INFO - joeynmt.training - Example #1
2022-01-18 14:11:01,232 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 14:11:01,232 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 14:11:01,232 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 7 | 8 1 | 21 41 | 17 67 | 20 73 | 19 53 | 71 74 | 14 6 | 56 61 | 16 42 | 22 10 | 72 23 | 66 37 | 36 63 | 26 None | 30 73
2022-01-18 14:11:01,232 - INFO - joeynmt.training - Example #2
2022-01-18 14:11:01,232 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 14:11:01,232 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:11:01,232 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 16 | 11 40 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:11:01,232 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    41000: bleu:  39.90, loss: 184993.5938, ppl:   3.1547, duration: 276.2253s
2022-01-18 14:11:19,608 - INFO - joeynmt.training - Epoch  16, Step:    41100, Batch Loss:    47.970417, Tokens per Sec:     3692, Lr: 0.000200
2022-01-18 14:11:38,549 - INFO - joeynmt.training - Epoch  16, Step:    41200, Batch Loss:    27.368311, Tokens per Sec:     3554, Lr: 0.000200
2022-01-18 14:11:57,082 - INFO - joeynmt.training - Epoch  16, Step:    41300, Batch Loss:    24.655493, Tokens per Sec:     3608, Lr: 0.000200
2022-01-18 14:12:15,963 - INFO - joeynmt.training - Epoch  16, Step:    41400, Batch Loss:    63.233356, Tokens per Sec:     3502, Lr: 0.000200
2022-01-18 14:12:34,662 - INFO - joeynmt.training - Epoch  16, Step:    41500, Batch Loss:    21.535254, Tokens per Sec:     3459, Lr: 0.000200
2022-01-18 14:12:52,873 - INFO - joeynmt.training - Epoch  16, Step:    41600, Batch Loss:    17.804844, Tokens per Sec:     3816, Lr: 0.000200
2022-01-18 14:13:11,097 - INFO - joeynmt.training - Epoch  16, Step:    41700, Batch Loss:    15.690921, Tokens per Sec:     3901, Lr: 0.000200
2022-01-18 14:13:29,198 - INFO - joeynmt.training - Epoch  16, Step:    41800, Batch Loss:    23.403189, Tokens per Sec:     3733, Lr: 0.000200
2022-01-18 14:13:46,723 - INFO - joeynmt.training - Epoch  16, Step:    41900, Batch Loss:    40.042717, Tokens per Sec:     3869, Lr: 0.000200
2022-01-18 14:14:04,762 - INFO - joeynmt.training - Epoch  16, Step:    42000, Batch Loss:    26.331310, Tokens per Sec:     3635, Lr: 0.000200
2022-01-18 14:18:08,169 - INFO - joeynmt.training - Example #0
2022-01-18 14:18:08,170 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 14:18:08,170 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 14:18:08,170 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 14:18:08,170 - INFO - joeynmt.training - Example #1
2022-01-18 14:18:08,170 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 14:18:08,170 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 14:18:08,170 - INFO - joeynmt.training - 	Hypothesis: 13 63 | 35 0 | 65 50 | 32 74 | 8 1 | 12 46 | 21 67 | 20 73 | 19 42 | 71 58 | 14 37 | 56 10 | 16 23 | 72 63 | 66 61 | 36 6 | 30 7 | 26 63
2022-01-18 14:18:08,170 - INFO - joeynmt.training - Example #2
2022-01-18 14:18:08,171 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 14:18:08,171 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:18:08,171 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:18:08,171 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    42000: bleu:  39.74, loss: 184099.6094, ppl:   3.1372, duration: 243.4081s
2022-01-18 14:18:26,816 - INFO - joeynmt.training - Epoch  16, Step:    42100, Batch Loss:    32.457321, Tokens per Sec:     3649, Lr: 0.000200
2022-01-18 14:18:45,776 - INFO - joeynmt.training - Epoch  16, Step:    42200, Batch Loss:    25.585453, Tokens per Sec:     3538, Lr: 0.000200
2022-01-18 14:19:04,242 - INFO - joeynmt.training - Epoch  16, Step:    42300, Batch Loss:    34.345570, Tokens per Sec:     3632, Lr: 0.000200
2022-01-18 14:19:22,549 - INFO - joeynmt.training - Epoch  16, Step:    42400, Batch Loss:    34.099354, Tokens per Sec:     3707, Lr: 0.000200
2022-01-18 14:19:39,175 - INFO - joeynmt.training - Epoch  16: total training loss 72084.99
2022-01-18 14:19:39,175 - INFO - joeynmt.training - EPOCH 17
2022-01-18 14:19:40,891 - INFO - joeynmt.training - Epoch  17, Step:    42500, Batch Loss:    14.281890, Tokens per Sec:     3678, Lr: 0.000200
2022-01-18 14:19:59,507 - INFO - joeynmt.training - Epoch  17, Step:    42600, Batch Loss:    18.444979, Tokens per Sec:     3558, Lr: 0.000200
2022-01-18 14:20:17,948 - INFO - joeynmt.training - Epoch  17, Step:    42700, Batch Loss:    15.275667, Tokens per Sec:     3658, Lr: 0.000200
2022-01-18 14:20:36,545 - INFO - joeynmt.training - Epoch  17, Step:    42800, Batch Loss:    35.872478, Tokens per Sec:     3531, Lr: 0.000200
2022-01-18 14:20:55,220 - INFO - joeynmt.training - Epoch  17, Step:    42900, Batch Loss:    21.729309, Tokens per Sec:     3772, Lr: 0.000200
2022-01-18 14:21:13,674 - INFO - joeynmt.training - Epoch  17, Step:    43000, Batch Loss:    30.226946, Tokens per Sec:     3781, Lr: 0.000200
2022-01-18 14:25:19,668 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 14:25:52,345 - INFO - joeynmt.helpers - delete models/B_ablation/41000.ckpt
2022-01-18 14:25:52,424 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/41000.ckpt
2022-01-18 14:25:52,425 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/41000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/41000.ckpt')
2022-01-18 14:25:52,461 - INFO - joeynmt.training - Example #0
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Hypothesis: 34 19 | 32 36 | 31 30 | 35 7 | 2 None | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 14:25:52,462 - INFO - joeynmt.training - Example #1
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 7 | 8 74 | 12 41 | 17 46 | 20 67 | 19 6 | 71 51 | 14 23 | 56 63 | 16 42 | 22 37 | 72 10 | 66 63 | 36 61 | 30 59 | 26 63
2022-01-18 14:25:52,462 - INFO - joeynmt.training - Example #2
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:25:52,462 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:25:52,463 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    43000: bleu:  40.48, loss: 183874.7969, ppl:   3.1329, duration: 278.7877s
2022-01-18 14:26:11,032 - INFO - joeynmt.training - Epoch  17, Step:    43100, Batch Loss:    37.134838, Tokens per Sec:     3671, Lr: 0.000200
2022-01-18 14:26:29,507 - INFO - joeynmt.training - Epoch  17, Step:    43200, Batch Loss:    22.416473, Tokens per Sec:     3743, Lr: 0.000200
2022-01-18 14:26:47,486 - INFO - joeynmt.training - Epoch  17, Step:    43300, Batch Loss:    43.302212, Tokens per Sec:     3797, Lr: 0.000200
2022-01-18 14:27:05,842 - INFO - joeynmt.training - Epoch  17, Step:    43400, Batch Loss:    26.038595, Tokens per Sec:     3655, Lr: 0.000200
2022-01-18 14:27:24,355 - INFO - joeynmt.training - Epoch  17, Step:    43500, Batch Loss:    14.310583, Tokens per Sec:     3560, Lr: 0.000200
2022-01-18 14:27:42,712 - INFO - joeynmt.training - Epoch  17, Step:    43600, Batch Loss:    16.411451, Tokens per Sec:     3502, Lr: 0.000200
2022-01-18 14:28:01,286 - INFO - joeynmt.training - Epoch  17, Step:    43700, Batch Loss:    23.755465, Tokens per Sec:     3626, Lr: 0.000200
2022-01-18 14:28:19,809 - INFO - joeynmt.training - Epoch  17, Step:    43800, Batch Loss:    40.364780, Tokens per Sec:     3646, Lr: 0.000200
2022-01-18 14:28:37,913 - INFO - joeynmt.training - Epoch  17, Step:    43900, Batch Loss:    15.490350, Tokens per Sec:     3667, Lr: 0.000200
2022-01-18 14:28:56,362 - INFO - joeynmt.training - Epoch  17, Step:    44000, Batch Loss:    25.358555, Tokens per Sec:     3680, Lr: 0.000200
2022-01-18 14:32:57,627 - INFO - joeynmt.training - Example #0
2022-01-18 14:32:57,627 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 14:32:57,627 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 14:32:57,627 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 14:32:57,627 - INFO - joeynmt.training - Example #1
2022-01-18 14:32:57,628 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 14:32:57,628 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 14:32:57,628 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 51 | 21 41 | 20 67 | 19 73 | 71 53 | 14 23 | 56 6 | 16 10 | 22 42 | 72 37 | 66 61 | 36 63 | 30 74 | 26 67 | 17 46
2022-01-18 14:32:57,628 - INFO - joeynmt.training - Example #2
2022-01-18 14:32:57,628 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 14:32:57,628 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:32:57,628 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 40 | 11 16 | 21 47 | 42 6 | 39 5 | 22 48 | 19 30
2022-01-18 14:32:57,628 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    44000: bleu:  39.95, loss: 182458.5156, ppl:   3.1054, duration: 241.2650s
2022-01-18 14:33:15,976 - INFO - joeynmt.training - Epoch  17, Step:    44100, Batch Loss:    25.074350, Tokens per Sec:     3657, Lr: 0.000200
2022-01-18 14:33:34,129 - INFO - joeynmt.training - Epoch  17, Step:    44200, Batch Loss:    26.703970, Tokens per Sec:     3614, Lr: 0.000200
2022-01-18 14:33:52,416 - INFO - joeynmt.training - Epoch  17, Step:    44300, Batch Loss:    26.835733, Tokens per Sec:     3785, Lr: 0.000200
2022-01-18 14:34:11,252 - INFO - joeynmt.training - Epoch  17, Step:    44400, Batch Loss:    47.498543, Tokens per Sec:     3597, Lr: 0.000200
2022-01-18 14:34:29,917 - INFO - joeynmt.training - Epoch  17, Step:    44500, Batch Loss:    46.006081, Tokens per Sec:     3666, Lr: 0.000200
2022-01-18 14:34:48,565 - INFO - joeynmt.training - Epoch  17, Step:    44600, Batch Loss:    19.831009, Tokens per Sec:     3693, Lr: 0.000200
2022-01-18 14:35:06,853 - INFO - joeynmt.training - Epoch  17, Step:    44700, Batch Loss:    15.115586, Tokens per Sec:     3605, Lr: 0.000200
2022-01-18 14:35:25,232 - INFO - joeynmt.training - Epoch  17, Step:    44800, Batch Loss:    25.310614, Tokens per Sec:     3739, Lr: 0.000200
2022-01-18 14:35:43,793 - INFO - joeynmt.training - Epoch  17, Step:    44900, Batch Loss:    52.038029, Tokens per Sec:     3611, Lr: 0.000200
2022-01-18 14:36:02,316 - INFO - joeynmt.training - Epoch  17, Step:    45000, Batch Loss:    22.366661, Tokens per Sec:     3604, Lr: 0.000200
2022-01-18 14:40:02,045 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 14:40:34,846 - INFO - joeynmt.helpers - delete models/B_ablation/43000.ckpt
2022-01-18 14:40:34,921 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/43000.ckpt
2022-01-18 14:40:34,922 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/43000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/43000.ckpt')
2022-01-18 14:40:34,953 - INFO - joeynmt.training - Example #0
2022-01-18 14:40:34,953 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 14:40:34,953 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 14:40:34,953 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 14:40:34,953 - INFO - joeynmt.training - Example #1
2022-01-18 14:40:34,954 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 14:40:34,954 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 14:40:34,954 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 50 | 65 74 | 32 7 | 8 51 | 12 41 | 17 46 | 20 67 | 19 58 | 71 53 | 14 6 | 56 61 | 16 73 | 22 42 | 72 10 | 66 23 | 36 63 | 30 37 | 26 None
2022-01-18 14:40:34,954 - INFO - joeynmt.training - Example #2
2022-01-18 14:40:34,954 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 14:40:34,954 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:40:34,954 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:40:34,954 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    45000: bleu:  41.27, loss: 178848.1406, ppl:   3.0366, duration: 272.6374s
2022-01-18 14:40:53,854 - INFO - joeynmt.training - Epoch  17, Step:    45100, Batch Loss:    27.908464, Tokens per Sec:     3622, Lr: 0.000200
2022-01-18 14:41:02,575 - INFO - joeynmt.training - Epoch  17: total training loss 68936.85
2022-01-18 14:41:02,576 - INFO - joeynmt.training - EPOCH 18
2022-01-18 14:41:12,252 - INFO - joeynmt.training - Epoch  18, Step:    45200, Batch Loss:    35.135048, Tokens per Sec:     3722, Lr: 0.000200
2022-01-18 14:41:30,522 - INFO - joeynmt.training - Epoch  18, Step:    45300, Batch Loss:    24.476904, Tokens per Sec:     3714, Lr: 0.000200
2022-01-18 14:41:49,198 - INFO - joeynmt.training - Epoch  18, Step:    45400, Batch Loss:    36.025352, Tokens per Sec:     3664, Lr: 0.000200
2022-01-18 14:42:07,858 - INFO - joeynmt.training - Epoch  18, Step:    45500, Batch Loss:    37.314808, Tokens per Sec:     3549, Lr: 0.000200
2022-01-18 14:42:26,467 - INFO - joeynmt.training - Epoch  18, Step:    45600, Batch Loss:    12.871230, Tokens per Sec:     3639, Lr: 0.000200
2022-01-18 14:42:45,155 - INFO - joeynmt.training - Epoch  18, Step:    45700, Batch Loss:    18.546665, Tokens per Sec:     3570, Lr: 0.000200
2022-01-18 14:43:03,671 - INFO - joeynmt.training - Epoch  18, Step:    45800, Batch Loss:    17.152912, Tokens per Sec:     3714, Lr: 0.000200
2022-01-18 14:43:22,351 - INFO - joeynmt.training - Epoch  18, Step:    45900, Batch Loss:    20.879942, Tokens per Sec:     3666, Lr: 0.000200
2022-01-18 14:43:41,006 - INFO - joeynmt.training - Epoch  18, Step:    46000, Batch Loss:    27.351624, Tokens per Sec:     3699, Lr: 0.000200
2022-01-18 14:47:42,955 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 14:48:15,682 - INFO - joeynmt.helpers - delete models/B_ablation/45000.ckpt
2022-01-18 14:48:15,761 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/45000.ckpt
2022-01-18 14:48:15,762 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/45000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/45000.ckpt')
2022-01-18 14:48:15,786 - INFO - joeynmt.training - Example #0
2022-01-18 14:48:15,786 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 14:48:15,786 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 14:48:15,786 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 14:48:15,786 - INFO - joeynmt.training - Example #1
2022-01-18 14:48:15,786 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 14:48:15,786 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 14:48:15,786 - INFO - joeynmt.training - 	Hypothesis: 13 6 | 35 0 | 65 50 | 32 74 | 8 51 | 12 46 | 17 41 | 20 67 | 19 73 | 71 53 | 14 37 | 56 23 | 16 10 | 22 42 | 72 59 | 66 63 | 36 61 | 30 63 | 26 7
2022-01-18 14:48:15,786 - INFO - joeynmt.training - Example #2
2022-01-18 14:48:15,787 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 14:48:15,787 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:48:15,787 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 16 | 11 40 | 21 47 | 42 6 | 39 5 | 22 48 | 19 30
2022-01-18 14:48:15,787 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    46000: bleu:  41.32, loss: 179457.7031, ppl:   3.0481, duration: 274.7801s
2022-01-18 14:48:34,377 - INFO - joeynmt.training - Epoch  18, Step:    46100, Batch Loss:    33.039219, Tokens per Sec:     3729, Lr: 0.000200
2022-01-18 14:48:53,152 - INFO - joeynmt.training - Epoch  18, Step:    46200, Batch Loss:    19.127439, Tokens per Sec:     3617, Lr: 0.000200
2022-01-18 14:49:11,704 - INFO - joeynmt.training - Epoch  18, Step:    46300, Batch Loss:    22.594692, Tokens per Sec:     3564, Lr: 0.000200
2022-01-18 14:49:30,242 - INFO - joeynmt.training - Epoch  18, Step:    46400, Batch Loss:     9.870346, Tokens per Sec:     3602, Lr: 0.000200
2022-01-18 14:49:48,940 - INFO - joeynmt.training - Epoch  18, Step:    46500, Batch Loss:    40.812073, Tokens per Sec:     3577, Lr: 0.000200
2022-01-18 14:50:07,607 - INFO - joeynmt.training - Epoch  18, Step:    46600, Batch Loss:    39.048508, Tokens per Sec:     3626, Lr: 0.000200
2022-01-18 14:50:26,288 - INFO - joeynmt.training - Epoch  18, Step:    46700, Batch Loss:    22.089193, Tokens per Sec:     3660, Lr: 0.000200
2022-01-18 14:50:44,920 - INFO - joeynmt.training - Epoch  18, Step:    46800, Batch Loss:    20.866514, Tokens per Sec:     3662, Lr: 0.000200
2022-01-18 14:51:03,680 - INFO - joeynmt.training - Epoch  18, Step:    46900, Batch Loss:    12.170269, Tokens per Sec:     3573, Lr: 0.000200
2022-01-18 14:51:22,306 - INFO - joeynmt.training - Epoch  18, Step:    47000, Batch Loss:    30.941389, Tokens per Sec:     3564, Lr: 0.000200
2022-01-18 14:55:23,441 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 14:55:56,171 - INFO - joeynmt.helpers - delete models/B_ablation/46000.ckpt
2022-01-18 14:55:56,255 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/46000.ckpt
2022-01-18 14:55:56,255 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/46000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/46000.ckpt')
2022-01-18 14:55:56,277 - INFO - joeynmt.training - Example #0
2022-01-18 14:55:56,277 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 14:55:56,277 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 14:55:56,277 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 14:55:56,277 - INFO - joeynmt.training - Example #1
2022-01-18 14:55:56,277 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 14:55:56,277 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 14:55:56,278 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 51 | 12 41 | 17 1 | 20 67 | 19 53 | 71 7 | 14 61 | 56 23 | 16 73 | 22 42 | 72 10 | 66 37 | 36 6 | 30 63 | 26 59
2022-01-18 14:55:56,278 - INFO - joeynmt.training - Example #2
2022-01-18 14:55:56,278 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 14:55:56,278 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:55:56,278 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 14:55:56,278 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    47000: bleu:  41.92, loss: 173268.2969, ppl:   2.9331, duration: 273.9719s
2022-01-18 14:56:14,954 - INFO - joeynmt.training - Epoch  18, Step:    47100, Batch Loss:    22.278965, Tokens per Sec:     3667, Lr: 0.000200
2022-01-18 14:56:33,616 - INFO - joeynmt.training - Epoch  18, Step:    47200, Batch Loss:    18.823027, Tokens per Sec:     3591, Lr: 0.000200
2022-01-18 14:56:52,336 - INFO - joeynmt.training - Epoch  18, Step:    47300, Batch Loss:    16.602495, Tokens per Sec:     3582, Lr: 0.000200
2022-01-18 14:57:10,767 - INFO - joeynmt.training - Epoch  18, Step:    47400, Batch Loss:    20.381224, Tokens per Sec:     3593, Lr: 0.000200
2022-01-18 14:57:29,180 - INFO - joeynmt.training - Epoch  18, Step:    47500, Batch Loss:    14.185891, Tokens per Sec:     3600, Lr: 0.000200
2022-01-18 14:57:47,673 - INFO - joeynmt.training - Epoch  18, Step:    47600, Batch Loss:    21.411125, Tokens per Sec:     3697, Lr: 0.000200
2022-01-18 14:58:06,319 - INFO - joeynmt.training - Epoch  18, Step:    47700, Batch Loss:    22.781839, Tokens per Sec:     3689, Lr: 0.000200
2022-01-18 14:58:25,012 - INFO - joeynmt.training - Epoch  18, Step:    47800, Batch Loss:    24.090719, Tokens per Sec:     3503, Lr: 0.000200
2022-01-18 14:58:25,470 - INFO - joeynmt.training - Epoch  18: total training loss 64915.17
2022-01-18 14:58:25,470 - INFO - joeynmt.training - EPOCH 19
2022-01-18 14:58:43,743 - INFO - joeynmt.training - Epoch  19, Step:    47900, Batch Loss:    12.101027, Tokens per Sec:     3659, Lr: 0.000200
2022-01-18 14:59:02,266 - INFO - joeynmt.training - Epoch  19, Step:    48000, Batch Loss:    11.224622, Tokens per Sec:     3545, Lr: 0.000200
2022-01-18 15:03:04,135 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 15:03:36,893 - INFO - joeynmt.helpers - delete models/B_ablation/47000.ckpt
2022-01-18 15:03:36,975 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/47000.ckpt
2022-01-18 15:03:36,976 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/47000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/47000.ckpt')
2022-01-18 15:03:36,998 - INFO - joeynmt.training - Example #0
2022-01-18 15:03:36,998 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 15:03:36,998 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 15:03:36,999 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 15:03:36,999 - INFO - joeynmt.training - Example #1
2022-01-18 15:03:36,999 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 15:03:36,999 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 15:03:36,999 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 51 | 12 41 | 20 67 | 21 46 | 19 53 | 71 61 | 14 6 | 56 23 | 16 42 | 22 10 | 72 37 | 66 63 | 30 None | 26 None | 36 None
2022-01-18 15:03:36,999 - INFO - joeynmt.training - Example #2
2022-01-18 15:03:36,999 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 15:03:37,000 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:03:37,000 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 2 | 4 16 | 11 40 | 21 47 | 42 6 | 39 5 | 22 48 | 19 None
2022-01-18 15:03:37,000 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    48000: bleu:  43.28, loss: 170688.1250, ppl:   2.8865, duration: 274.7333s
2022-01-18 15:03:55,812 - INFO - joeynmt.training - Epoch  19, Step:    48100, Batch Loss:    19.904961, Tokens per Sec:     3684, Lr: 0.000200
2022-01-18 15:04:14,490 - INFO - joeynmt.training - Epoch  19, Step:    48200, Batch Loss:    28.443859, Tokens per Sec:     3622, Lr: 0.000200
2022-01-18 15:04:33,320 - INFO - joeynmt.training - Epoch  19, Step:    48300, Batch Loss:     8.928701, Tokens per Sec:     3645, Lr: 0.000200
2022-01-18 15:04:51,997 - INFO - joeynmt.training - Epoch  19, Step:    48400, Batch Loss:    36.861176, Tokens per Sec:     3640, Lr: 0.000200
2022-01-18 15:05:10,734 - INFO - joeynmt.training - Epoch  19, Step:    48500, Batch Loss:    31.042376, Tokens per Sec:     3632, Lr: 0.000200
2022-01-18 15:05:29,563 - INFO - joeynmt.training - Epoch  19, Step:    48600, Batch Loss:    13.622939, Tokens per Sec:     3613, Lr: 0.000200
2022-01-18 15:05:48,212 - INFO - joeynmt.training - Epoch  19, Step:    48700, Batch Loss:    16.491224, Tokens per Sec:     3501, Lr: 0.000200
2022-01-18 15:06:06,942 - INFO - joeynmt.training - Epoch  19, Step:    48800, Batch Loss:    13.715052, Tokens per Sec:     3647, Lr: 0.000200
2022-01-18 15:06:25,623 - INFO - joeynmt.training - Epoch  19, Step:    48900, Batch Loss:    20.469852, Tokens per Sec:     3568, Lr: 0.000200
2022-01-18 15:06:44,330 - INFO - joeynmt.training - Epoch  19, Step:    49000, Batch Loss:    41.865822, Tokens per Sec:     3620, Lr: 0.000200
2022-01-18 15:10:48,978 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 15:11:21,854 - INFO - joeynmt.helpers - delete models/B_ablation/48000.ckpt
2022-01-18 15:11:21,939 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/48000.ckpt
2022-01-18 15:11:21,940 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/48000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/48000.ckpt')
2022-01-18 15:11:21,960 - INFO - joeynmt.training - Example #0
2022-01-18 15:11:21,960 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 15:11:21,960 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 15:11:21,961 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 15:11:21,961 - INFO - joeynmt.training - Example #1
2022-01-18 15:11:21,961 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 15:11:21,961 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 15:11:21,961 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 50 | 65 74 | 32 7 | 8 1 | 17 46 | 12 51 | 20 67 | 19 53 | 71 0 | 14 6 | 56 10 | 16 42 | 22 37 | 72 23 | 66 63 | 36 None | 30 61 | 26 70
2022-01-18 15:11:21,961 - INFO - joeynmt.training - Example #2
2022-01-18 15:11:21,961 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 15:11:21,961 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:11:21,961 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:11:21,961 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    49000: bleu:  44.88, loss: 167621.3594, ppl:   2.8321, duration: 277.6306s
2022-01-18 15:11:40,473 - INFO - joeynmt.training - Epoch  19, Step:    49100, Batch Loss:    15.578116, Tokens per Sec:     3694, Lr: 0.000200
2022-01-18 15:11:58,802 - INFO - joeynmt.training - Epoch  19, Step:    49200, Batch Loss:    18.588364, Tokens per Sec:     3590, Lr: 0.000200
2022-01-18 15:12:17,138 - INFO - joeynmt.training - Epoch  19, Step:    49300, Batch Loss:    23.664547, Tokens per Sec:     3606, Lr: 0.000200
2022-01-18 15:12:35,591 - INFO - joeynmt.training - Epoch  19, Step:    49400, Batch Loss:    12.635651, Tokens per Sec:     3734, Lr: 0.000200
2022-01-18 15:12:54,072 - INFO - joeynmt.training - Epoch  19, Step:    49500, Batch Loss:    14.816278, Tokens per Sec:     3659, Lr: 0.000200
2022-01-18 15:13:12,879 - INFO - joeynmt.training - Epoch  19, Step:    49600, Batch Loss:    25.073565, Tokens per Sec:     3653, Lr: 0.000200
2022-01-18 15:13:31,710 - INFO - joeynmt.training - Epoch  19, Step:    49700, Batch Loss:    18.864372, Tokens per Sec:     3594, Lr: 0.000200
2022-01-18 15:13:50,713 - INFO - joeynmt.training - Epoch  19, Step:    49800, Batch Loss:    22.760241, Tokens per Sec:     3576, Lr: 0.000200
2022-01-18 15:14:09,140 - INFO - joeynmt.training - Epoch  19, Step:    49900, Batch Loss:    15.603243, Tokens per Sec:     3596, Lr: 0.000200
2022-01-18 15:14:27,214 - INFO - joeynmt.training - Epoch  19, Step:    50000, Batch Loss:    19.080061, Tokens per Sec:     3639, Lr: 0.000200
2022-01-18 15:18:29,004 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 15:19:01,779 - INFO - joeynmt.helpers - delete models/B_ablation/49000.ckpt
2022-01-18 15:19:01,867 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/49000.ckpt
2022-01-18 15:19:01,868 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/49000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/49000.ckpt')
2022-01-18 15:19:01,891 - INFO - joeynmt.training - Example #0
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 15:19:01,892 - INFO - joeynmt.training - Example #1
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 74 | 32 50 | 8 51 | 12 46 | 17 1 | 20 67 | 21 10 | 19 53 | 71 53 | 14 6 | 56 42 | 16 73 | 22 23 | 72 63 | 36 61 | 30 59 | 26 37
2022-01-18 15:19:01,892 - INFO - joeynmt.training - Example #2
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:19:01,892 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 40 | 11 16 | 21 47 | 42 6 | 39 5 | 22 48 | 19 30
2022-01-18 15:19:01,892 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    50000: bleu:  45.25, loss: 164273.2969, ppl:   2.7738, duration: 274.6781s
2022-01-18 15:19:20,782 - INFO - joeynmt.training - Epoch  19, Step:    50100, Batch Loss:    15.841860, Tokens per Sec:     3627, Lr: 0.000200
2022-01-18 15:19:39,427 - INFO - joeynmt.training - Epoch  19, Step:    50200, Batch Loss:    22.171427, Tokens per Sec:     3650, Lr: 0.000200
2022-01-18 15:19:57,908 - INFO - joeynmt.training - Epoch  19, Step:    50300, Batch Loss:    18.562452, Tokens per Sec:     3671, Lr: 0.000200
2022-01-18 15:20:16,401 - INFO - joeynmt.training - Epoch  19, Step:    50400, Batch Loss:    24.803135, Tokens per Sec:     3515, Lr: 0.000200
2022-01-18 15:20:27,687 - INFO - joeynmt.training - Epoch  19: total training loss 60580.40
2022-01-18 15:20:27,688 - INFO - joeynmt.training - EPOCH 20
2022-01-18 15:20:35,055 - INFO - joeynmt.training - Epoch  20, Step:    50500, Batch Loss:    26.688892, Tokens per Sec:     3601, Lr: 0.000200
2022-01-18 15:20:53,811 - INFO - joeynmt.training - Epoch  20, Step:    50600, Batch Loss:    20.110445, Tokens per Sec:     3619, Lr: 0.000200
2022-01-18 15:21:12,514 - INFO - joeynmt.training - Epoch  20, Step:    50700, Batch Loss:    14.304546, Tokens per Sec:     3628, Lr: 0.000200
2022-01-18 15:21:31,352 - INFO - joeynmt.training - Epoch  20, Step:    50800, Batch Loss:    11.612542, Tokens per Sec:     3565, Lr: 0.000200
2022-01-18 15:21:50,097 - INFO - joeynmt.training - Epoch  20, Step:    50900, Batch Loss:    16.744425, Tokens per Sec:     3564, Lr: 0.000200
2022-01-18 15:22:08,772 - INFO - joeynmt.training - Epoch  20, Step:    51000, Batch Loss:    24.287264, Tokens per Sec:     3715, Lr: 0.000200
2022-01-18 15:26:10,229 - INFO - joeynmt.training - Example #0
2022-01-18 15:26:10,230 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 15:26:10,230 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 15:26:10,230 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 15:26:10,230 - INFO - joeynmt.training - Example #1
2022-01-18 15:26:10,230 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 15:26:10,230 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 15:26:10,230 - INFO - joeynmt.training - 	Hypothesis: 13 1 | 35 0 | 65 50 | 32 74 | 8 51 | 12 46 | 17 67 | 21 41 | 19 53 | 71 58 | 14 61 | 56 59 | 16 42 | 22 10 | 72 23 | 66 37 | 36 6 | 30 63
2022-01-18 15:26:10,230 - INFO - joeynmt.training - Example #2
2022-01-18 15:26:10,231 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 15:26:10,231 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:26:10,231 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 40 | 11 16 | 21 47 | 42 6 | 39 5 | 22 48 | 19 30
2022-01-18 15:26:10,231 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    51000: bleu:  45.06, loss: 165362.4062, ppl:   2.7926, duration: 241.4584s
2022-01-18 15:26:29,192 - INFO - joeynmt.training - Epoch  20, Step:    51100, Batch Loss:    23.509642, Tokens per Sec:     3604, Lr: 0.000200
2022-01-18 15:26:47,985 - INFO - joeynmt.training - Epoch  20, Step:    51200, Batch Loss:    35.655296, Tokens per Sec:     3559, Lr: 0.000200
2022-01-18 15:27:07,029 - INFO - joeynmt.training - Epoch  20, Step:    51300, Batch Loss:    22.053410, Tokens per Sec:     3570, Lr: 0.000200
2022-01-18 15:27:25,923 - INFO - joeynmt.training - Epoch  20, Step:    51400, Batch Loss:    17.297119, Tokens per Sec:     3468, Lr: 0.000200
2022-01-18 15:27:44,762 - INFO - joeynmt.training - Epoch  20, Step:    51500, Batch Loss:    23.900688, Tokens per Sec:     3597, Lr: 0.000200
2022-01-18 15:28:03,966 - INFO - joeynmt.training - Epoch  20, Step:    51600, Batch Loss:    23.394321, Tokens per Sec:     3508, Lr: 0.000200
2022-01-18 15:28:22,681 - INFO - joeynmt.training - Epoch  20, Step:    51700, Batch Loss:    15.033744, Tokens per Sec:     3667, Lr: 0.000200
2022-01-18 15:28:41,127 - INFO - joeynmt.training - Epoch  20, Step:    51800, Batch Loss:    23.858225, Tokens per Sec:     3689, Lr: 0.000200
2022-01-18 15:28:59,120 - INFO - joeynmt.training - Epoch  20, Step:    51900, Batch Loss:     8.909075, Tokens per Sec:     3712, Lr: 0.000200
2022-01-18 15:29:17,158 - INFO - joeynmt.training - Epoch  20, Step:    52000, Batch Loss:    48.671089, Tokens per Sec:     3617, Lr: 0.000200
2022-01-18 15:33:17,912 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 15:33:50,922 - INFO - joeynmt.helpers - delete models/B_ablation/50000.ckpt
2022-01-18 15:33:51,009 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/50000.ckpt
2022-01-18 15:33:51,009 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/50000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/50000.ckpt')
2022-01-18 15:33:51,039 - INFO - joeynmt.training - Example #0
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 15:33:51,040 - INFO - joeynmt.training - Example #1
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 74 | 32 50 | 8 1 | 12 46 | 20 67 | 21 41 | 19 53 | 71 0 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 23 | 36 6 | 30 37
2022-01-18 15:33:51,040 - INFO - joeynmt.training - Example #2
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:33:51,040 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:33:51,040 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    52000: bleu:  45.63, loss: 163587.7812, ppl:   2.7620, duration: 273.8823s
2022-01-18 15:34:09,736 - INFO - joeynmt.training - Epoch  20, Step:    52100, Batch Loss:    40.359684, Tokens per Sec:     3685, Lr: 0.000200
2022-01-18 15:34:28,401 - INFO - joeynmt.training - Epoch  20, Step:    52200, Batch Loss:    22.683575, Tokens per Sec:     3617, Lr: 0.000200
2022-01-18 15:34:47,143 - INFO - joeynmt.training - Epoch  20, Step:    52300, Batch Loss:    25.800692, Tokens per Sec:     3555, Lr: 0.000200
2022-01-18 15:35:05,518 - INFO - joeynmt.training - Epoch  20, Step:    52400, Batch Loss:    28.176098, Tokens per Sec:     3658, Lr: 0.000200
2022-01-18 15:35:23,999 - INFO - joeynmt.training - Epoch  20, Step:    52500, Batch Loss:    23.278893, Tokens per Sec:     3608, Lr: 0.000200
2022-01-18 15:35:42,253 - INFO - joeynmt.training - Epoch  20, Step:    52600, Batch Loss:    19.240427, Tokens per Sec:     3637, Lr: 0.000200
2022-01-18 15:36:00,644 - INFO - joeynmt.training - Epoch  20, Step:    52700, Batch Loss:    26.736399, Tokens per Sec:     3607, Lr: 0.000200
2022-01-18 15:36:19,149 - INFO - joeynmt.training - Epoch  20, Step:    52800, Batch Loss:    24.454062, Tokens per Sec:     3644, Lr: 0.000200
2022-01-18 15:36:38,267 - INFO - joeynmt.training - Epoch  20, Step:    52900, Batch Loss:    11.440675, Tokens per Sec:     3675, Lr: 0.000200
2022-01-18 15:36:57,325 - INFO - joeynmt.training - Epoch  20, Step:    53000, Batch Loss:    13.136001, Tokens per Sec:     3566, Lr: 0.000200
2022-01-18 15:40:58,984 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 15:41:31,740 - INFO - joeynmt.helpers - delete models/B_ablation/52000.ckpt
2022-01-18 15:41:31,831 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/52000.ckpt
2022-01-18 15:41:31,831 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/52000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/52000.ckpt')
2022-01-18 15:41:31,855 - INFO - joeynmt.training - Example #0
2022-01-18 15:41:31,855 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 15:41:31,855 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 15:41:31,855 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 15:41:31,855 - INFO - joeynmt.training - Example #1
2022-01-18 15:41:31,855 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 15:41:31,855 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 15:41:31,855 - INFO - joeynmt.training - 	Hypothesis: 13 6 | 35 50 | 65 74 | 32 1 | 8 46 | 12 41 | 17 51 | 20 67 | 19 58 | 71 53 | 14 61 | 56 59 | 16 73 | 22 10 | 72 37 | 66 23 | 36 63 | 30 None
2022-01-18 15:41:31,855 - INFO - joeynmt.training - Example #2
2022-01-18 15:41:31,855 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 15:41:31,856 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:41:31,856 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 45 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:41:31,856 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    53000: bleu:  46.48, loss: 160090.6250, ppl:   2.7027, duration: 274.5295s
2022-01-18 15:41:50,490 - INFO - joeynmt.training - Epoch  20, Step:    53100, Batch Loss:    28.091614, Tokens per Sec:     3680, Lr: 0.000200
2022-01-18 15:41:53,559 - INFO - joeynmt.training - Epoch  20: total training loss 57485.28
2022-01-18 15:41:53,559 - INFO - joeynmt.training - EPOCH 21
2022-01-18 15:42:08,866 - INFO - joeynmt.training - Epoch  21, Step:    53200, Batch Loss:    13.273917, Tokens per Sec:     3590, Lr: 0.000200
2022-01-18 15:42:27,468 - INFO - joeynmt.training - Epoch  21, Step:    53300, Batch Loss:    19.614573, Tokens per Sec:     3540, Lr: 0.000200
2022-01-18 15:42:46,277 - INFO - joeynmt.training - Epoch  21, Step:    53400, Batch Loss:    21.010754, Tokens per Sec:     3653, Lr: 0.000200
2022-01-18 15:43:05,138 - INFO - joeynmt.training - Epoch  21, Step:    53500, Batch Loss:    19.211432, Tokens per Sec:     3636, Lr: 0.000200
2022-01-18 15:43:23,912 - INFO - joeynmt.training - Epoch  21, Step:    53600, Batch Loss:    23.717581, Tokens per Sec:     3641, Lr: 0.000200
2022-01-18 15:43:42,602 - INFO - joeynmt.training - Epoch  21, Step:    53700, Batch Loss:    17.834650, Tokens per Sec:     3726, Lr: 0.000200
2022-01-18 15:44:00,912 - INFO - joeynmt.training - Epoch  21, Step:    53800, Batch Loss:    15.971766, Tokens per Sec:     3714, Lr: 0.000200
2022-01-18 15:44:19,411 - INFO - joeynmt.training - Epoch  21, Step:    53900, Batch Loss:     9.966374, Tokens per Sec:     3646, Lr: 0.000200
2022-01-18 15:44:38,358 - INFO - joeynmt.training - Epoch  21, Step:    54000, Batch Loss:    22.023232, Tokens per Sec:     3508, Lr: 0.000200
2022-01-18 15:48:41,827 - INFO - joeynmt.training - Example #0
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 15:48:41,828 - INFO - joeynmt.training - Example #1
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 50 | 65 74 | 32 7 | 21 51 | 17 46 | 12 41 | 20 67 | 19 53 | 71 58 | 14 6 | 56 61 | 16 42 | 22 10 | 72 23 | 66 37 | 36 63 | 30 70
2022-01-18 15:48:41,828 - INFO - joeynmt.training - Example #2
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:48:41,828 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:48:41,829 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    54000: bleu:  45.77, loss: 163669.4531, ppl:   2.7634, duration: 243.4704s
2022-01-18 15:49:00,640 - INFO - joeynmt.training - Epoch  21, Step:    54100, Batch Loss:    16.013477, Tokens per Sec:     3466, Lr: 0.000200
2022-01-18 15:49:19,436 - INFO - joeynmt.training - Epoch  21, Step:    54200, Batch Loss:    24.071924, Tokens per Sec:     3638, Lr: 0.000200
2022-01-18 15:49:37,802 - INFO - joeynmt.training - Epoch  21, Step:    54300, Batch Loss:    17.899214, Tokens per Sec:     3519, Lr: 0.000200
2022-01-18 15:49:56,288 - INFO - joeynmt.training - Epoch  21, Step:    54400, Batch Loss:    18.074068, Tokens per Sec:     3692, Lr: 0.000200
2022-01-18 15:50:14,832 - INFO - joeynmt.training - Epoch  21, Step:    54500, Batch Loss:    21.876591, Tokens per Sec:     3537, Lr: 0.000200
2022-01-18 15:50:33,587 - INFO - joeynmt.training - Epoch  21, Step:    54600, Batch Loss:    30.913284, Tokens per Sec:     3617, Lr: 0.000200
2022-01-18 15:50:52,915 - INFO - joeynmt.training - Epoch  21, Step:    54700, Batch Loss:    14.364921, Tokens per Sec:     3499, Lr: 0.000200
2022-01-18 15:51:11,550 - INFO - joeynmt.training - Epoch  21, Step:    54800, Batch Loss:    11.010447, Tokens per Sec:     3639, Lr: 0.000200
2022-01-18 15:51:30,252 - INFO - joeynmt.training - Epoch  21, Step:    54900, Batch Loss:    14.392990, Tokens per Sec:     3547, Lr: 0.000200
2022-01-18 15:51:49,182 - INFO - joeynmt.training - Epoch  21, Step:    55000, Batch Loss:    13.365952, Tokens per Sec:     3564, Lr: 0.000200
2022-01-18 15:55:49,417 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 15:56:22,121 - INFO - joeynmt.helpers - delete models/B_ablation/53000.ckpt
2022-01-18 15:56:22,199 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/53000.ckpt
2022-01-18 15:56:22,200 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/53000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/53000.ckpt')
2022-01-18 15:56:22,219 - INFO - joeynmt.training - Example #0
2022-01-18 15:56:22,219 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 15:56:22,219 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 15:56:22,219 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 15:56:22,219 - INFO - joeynmt.training - Example #1
2022-01-18 15:56:22,219 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 15:56:22,219 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 15:56:22,219 - INFO - joeynmt.training - 	Hypothesis: 13 51 | 35 50 | 65 74 | 32 1 | 8 46 | 12 41 | 17 42 | 21 67 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 23 | 72 10 | 36 6 | 30 63 | 26 37 | 14 0
2022-01-18 15:56:22,219 - INFO - joeynmt.training - Example #2
2022-01-18 15:56:22,219 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 15:56:22,219 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:56:22,220 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 16 | 11 40 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 15:56:22,220 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    55000: bleu:  47.56, loss: 159487.7344, ppl:   2.6926, duration: 273.0370s
2022-01-18 15:56:40,830 - INFO - joeynmt.training - Epoch  21, Step:    55100, Batch Loss:    22.472904, Tokens per Sec:     3684, Lr: 0.000200
2022-01-18 15:56:59,330 - INFO - joeynmt.training - Epoch  21, Step:    55200, Batch Loss:    16.982550, Tokens per Sec:     3666, Lr: 0.000200
2022-01-18 15:57:18,053 - INFO - joeynmt.training - Epoch  21, Step:    55300, Batch Loss:    26.624615, Tokens per Sec:     3725, Lr: 0.000200
2022-01-18 15:57:36,637 - INFO - joeynmt.training - Epoch  21, Step:    55400, Batch Loss:    13.584863, Tokens per Sec:     3613, Lr: 0.000200
2022-01-18 15:57:55,334 - INFO - joeynmt.training - Epoch  21, Step:    55500, Batch Loss:    37.325981, Tokens per Sec:     3596, Lr: 0.000200
2022-01-18 15:58:14,272 - INFO - joeynmt.training - Epoch  21, Step:    55600, Batch Loss:    15.671163, Tokens per Sec:     3518, Lr: 0.000200
2022-01-18 15:58:32,787 - INFO - joeynmt.training - Epoch  21, Step:    55700, Batch Loss:    10.716328, Tokens per Sec:     3561, Lr: 0.000200
2022-01-18 15:58:47,267 - INFO - joeynmt.training - Epoch  21: total training loss 54745.92
2022-01-18 15:58:47,267 - INFO - joeynmt.training - EPOCH 22
2022-01-18 15:58:51,434 - INFO - joeynmt.training - Epoch  22, Step:    55800, Batch Loss:    14.720782, Tokens per Sec:     3422, Lr: 0.000200
2022-01-18 15:59:10,349 - INFO - joeynmt.training - Epoch  22, Step:    55900, Batch Loss:    15.891689, Tokens per Sec:     3640, Lr: 0.000200
2022-01-18 15:59:29,040 - INFO - joeynmt.training - Epoch  22, Step:    56000, Batch Loss:    16.354696, Tokens per Sec:     3670, Lr: 0.000200
2022-01-18 16:03:33,035 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 16:04:05,736 - INFO - joeynmt.helpers - delete models/B_ablation/55000.ckpt
2022-01-18 16:04:05,815 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/55000.ckpt
2022-01-18 16:04:05,816 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/55000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/55000.ckpt')
2022-01-18 16:04:05,848 - INFO - joeynmt.training - Example #0
2022-01-18 16:04:05,848 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 16:04:05,848 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 16:04:05,848 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 16:04:05,848 - INFO - joeynmt.training - Example #1
2022-01-18 16:04:05,848 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 16:04:05,848 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 16:04:05,849 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 50 | 65 74 | 32 7 | 8 51 | 12 46 | 17 1 | 20 67 | 21 53 | 19 None | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 23 | 36 6 | 26 63
2022-01-18 16:04:05,849 - INFO - joeynmt.training - Example #2
2022-01-18 16:04:05,849 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 16:04:05,849 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:04:05,849 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:04:05,849 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    56000: bleu:  48.01, loss: 160530.0000, ppl:   2.7100, duration: 276.8081s
2022-01-18 16:04:24,150 - INFO - joeynmt.training - Epoch  22, Step:    56100, Batch Loss:    19.773609, Tokens per Sec:     3568, Lr: 0.000200
2022-01-18 16:04:42,664 - INFO - joeynmt.training - Epoch  22, Step:    56200, Batch Loss:     8.077484, Tokens per Sec:     3588, Lr: 0.000200
2022-01-18 16:05:01,269 - INFO - joeynmt.training - Epoch  22, Step:    56300, Batch Loss:     8.635167, Tokens per Sec:     3483, Lr: 0.000200
2022-01-18 16:05:19,693 - INFO - joeynmt.training - Epoch  22, Step:    56400, Batch Loss:    25.468958, Tokens per Sec:     3623, Lr: 0.000200
2022-01-18 16:05:38,063 - INFO - joeynmt.training - Epoch  22, Step:    56500, Batch Loss:    29.775736, Tokens per Sec:     3683, Lr: 0.000200
2022-01-18 16:05:56,473 - INFO - joeynmt.training - Epoch  22, Step:    56600, Batch Loss:    19.553850, Tokens per Sec:     3679, Lr: 0.000200
2022-01-18 16:06:14,846 - INFO - joeynmt.training - Epoch  22, Step:    56700, Batch Loss:    11.972970, Tokens per Sec:     3717, Lr: 0.000200
2022-01-18 16:06:33,290 - INFO - joeynmt.training - Epoch  22, Step:    56800, Batch Loss:    23.353634, Tokens per Sec:     3679, Lr: 0.000200
2022-01-18 16:06:51,944 - INFO - joeynmt.training - Epoch  22, Step:    56900, Batch Loss:    17.438766, Tokens per Sec:     3669, Lr: 0.000200
2022-01-18 16:07:10,541 - INFO - joeynmt.training - Epoch  22, Step:    57000, Batch Loss:    18.226370, Tokens per Sec:     3630, Lr: 0.000200
2022-01-18 16:11:12,520 - INFO - joeynmt.training - Example #0
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 16:11:12,521 - INFO - joeynmt.training - Example #1
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Hypothesis: 13 1 | 35 50 | 65 7 | 32 74 | 8 51 | 12 41 | 17 46 | 20 67 | 21 42 | 19 53 | 71 58 | 14 61 | 56 6 | 16 73 | 22 37 | 72 10 | 66 23 | 36 63 | 30 70
2022-01-18 16:11:12,521 - INFO - joeynmt.training - Example #2
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:11:12,521 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 5 | 39 47 | 22 6 | 19 48
2022-01-18 16:11:12,521 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    57000: bleu:  47.90, loss: 158713.7188, ppl:   2.6796, duration: 241.9797s
2022-01-18 16:11:31,292 - INFO - joeynmt.training - Epoch  22, Step:    57100, Batch Loss:    15.733740, Tokens per Sec:     3555, Lr: 0.000200
2022-01-18 16:11:50,019 - INFO - joeynmt.training - Epoch  22, Step:    57200, Batch Loss:    21.573679, Tokens per Sec:     3647, Lr: 0.000200
2022-01-18 16:12:08,623 - INFO - joeynmt.training - Epoch  22, Step:    57300, Batch Loss:     5.483773, Tokens per Sec:     3516, Lr: 0.000200
2022-01-18 16:12:26,968 - INFO - joeynmt.training - Epoch  22, Step:    57400, Batch Loss:    16.873951, Tokens per Sec:     3646, Lr: 0.000200
2022-01-18 16:12:45,787 - INFO - joeynmt.training - Epoch  22, Step:    57500, Batch Loss:    15.957957, Tokens per Sec:     3666, Lr: 0.000200
2022-01-18 16:13:04,597 - INFO - joeynmt.training - Epoch  22, Step:    57600, Batch Loss:    18.123064, Tokens per Sec:     3591, Lr: 0.000200
2022-01-18 16:13:23,477 - INFO - joeynmt.training - Epoch  22, Step:    57700, Batch Loss:    32.043251, Tokens per Sec:     3579, Lr: 0.000200
2022-01-18 16:13:42,259 - INFO - joeynmt.training - Epoch  22, Step:    57800, Batch Loss:    30.544628, Tokens per Sec:     3574, Lr: 0.000200
2022-01-18 16:14:00,739 - INFO - joeynmt.training - Epoch  22, Step:    57900, Batch Loss:    14.338037, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 16:14:19,527 - INFO - joeynmt.training - Epoch  22, Step:    58000, Batch Loss:    19.039068, Tokens per Sec:     3659, Lr: 0.000200
2022-01-18 16:18:17,958 - INFO - joeynmt.training - Example #0
2022-01-18 16:18:17,960 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 16:18:17,960 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 16:18:17,960 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 16:18:17,960 - INFO - joeynmt.training - Example #1
2022-01-18 16:18:17,961 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 16:18:17,961 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 16:18:17,961 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 7 | 32 50 | 8 46 | 12 51 | 17 41 | 21 74 | 19 53 | 71 6 | 14 61 | 56 59 | 16 67 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 None
2022-01-18 16:18:17,961 - INFO - joeynmt.training - Example #2
2022-01-18 16:18:17,961 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 16:18:17,961 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:18:17,961 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:18:17,961 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    58000: bleu:  47.96, loss: 158256.2500, ppl:   2.6720, duration: 238.4333s
2022-01-18 16:18:36,893 - INFO - joeynmt.training - Epoch  22, Step:    58100, Batch Loss:    11.690257, Tokens per Sec:     3538, Lr: 0.000200
2022-01-18 16:18:55,521 - INFO - joeynmt.training - Epoch  22, Step:    58200, Batch Loss:    10.083833, Tokens per Sec:     3613, Lr: 0.000200
2022-01-18 16:19:14,226 - INFO - joeynmt.training - Epoch  22, Step:    58300, Batch Loss:    24.933001, Tokens per Sec:     3501, Lr: 0.000200
2022-01-18 16:19:32,962 - INFO - joeynmt.training - Epoch  22, Step:    58400, Batch Loss:    14.791596, Tokens per Sec:     3580, Lr: 0.000200
2022-01-18 16:19:40,896 - INFO - joeynmt.training - Epoch  22: total training loss 52226.44
2022-01-18 16:19:40,896 - INFO - joeynmt.training - EPOCH 23
2022-01-18 16:19:51,900 - INFO - joeynmt.training - Epoch  23, Step:    58500, Batch Loss:    10.197394, Tokens per Sec:     3722, Lr: 0.000200
2022-01-18 16:20:10,552 - INFO - joeynmt.training - Epoch  23, Step:    58600, Batch Loss:    28.749992, Tokens per Sec:     3645, Lr: 0.000200
2022-01-18 16:20:28,978 - INFO - joeynmt.training - Epoch  23, Step:    58700, Batch Loss:     8.247484, Tokens per Sec:     3554, Lr: 0.000200
2022-01-18 16:20:47,880 - INFO - joeynmt.training - Epoch  23, Step:    58800, Batch Loss:    10.792717, Tokens per Sec:     3734, Lr: 0.000200
2022-01-18 16:21:06,552 - INFO - joeynmt.training - Epoch  23, Step:    58900, Batch Loss:    15.573764, Tokens per Sec:     3476, Lr: 0.000200
2022-01-18 16:21:25,265 - INFO - joeynmt.training - Epoch  23, Step:    59000, Batch Loss:    14.948705, Tokens per Sec:     3566, Lr: 0.000200
2022-01-18 16:25:29,853 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 16:26:02,810 - INFO - joeynmt.helpers - delete models/B_ablation/56000.ckpt
2022-01-18 16:26:02,895 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/56000.ckpt
2022-01-18 16:26:02,896 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/56000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/56000.ckpt')
2022-01-18 16:26:02,917 - INFO - joeynmt.training - Example #0
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 16:26:02,917 - INFO - joeynmt.training - Example #1
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 51 | 12 46 | 17 41 | 20 67 | 21 73 | 19 53 | 71 7 | 14 61 | 56 59 | 16 42 | 22 37 | 72 10 | 66 23 | 36 63 | 30 6 | 26 63
2022-01-18 16:26:02,917 - INFO - joeynmt.training - Example #2
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:26:02,917 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:26:02,917 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    59000: bleu:  49.02, loss: 159928.0000, ppl:   2.6999, duration: 277.6524s
2022-01-18 16:26:21,806 - INFO - joeynmt.training - Epoch  23, Step:    59100, Batch Loss:    14.168515, Tokens per Sec:     3623, Lr: 0.000200
2022-01-18 16:26:40,300 - INFO - joeynmt.training - Epoch  23, Step:    59200, Batch Loss:    15.032734, Tokens per Sec:     3522, Lr: 0.000200
2022-01-18 16:26:59,039 - INFO - joeynmt.training - Epoch  23, Step:    59300, Batch Loss:    15.644284, Tokens per Sec:     3595, Lr: 0.000200
2022-01-18 16:27:17,728 - INFO - joeynmt.training - Epoch  23, Step:    59400, Batch Loss:    24.045868, Tokens per Sec:     3622, Lr: 0.000200
2022-01-18 16:27:36,495 - INFO - joeynmt.training - Epoch  23, Step:    59500, Batch Loss:    20.393097, Tokens per Sec:     3498, Lr: 0.000200
2022-01-18 16:27:55,118 - INFO - joeynmt.training - Epoch  23, Step:    59600, Batch Loss:    14.799225, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 16:28:13,937 - INFO - joeynmt.training - Epoch  23, Step:    59700, Batch Loss:    13.605898, Tokens per Sec:     3561, Lr: 0.000200
2022-01-18 16:28:32,584 - INFO - joeynmt.training - Epoch  23, Step:    59800, Batch Loss:    20.377031, Tokens per Sec:     3688, Lr: 0.000200
2022-01-18 16:28:51,324 - INFO - joeynmt.training - Epoch  23, Step:    59900, Batch Loss:    30.330225, Tokens per Sec:     3671, Lr: 0.000200
2022-01-18 16:29:10,052 - INFO - joeynmt.training - Epoch  23, Step:    60000, Batch Loss:    27.624575, Tokens per Sec:     3506, Lr: 0.000200
2022-01-18 16:33:16,619 - INFO - joeynmt.training - Example #0
2022-01-18 16:33:16,883 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 16:33:16,883 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 16:33:16,883 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 16:33:16,883 - INFO - joeynmt.training - Example #1
2022-01-18 16:33:16,884 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 16:33:16,884 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 16:33:16,884 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 51 | 12 41 | 17 46 | 20 67 | 21 42 | 19 53 | 71 6 | 14 61 | 56 59 | 16 73 | 72 10 | 66 23 | 36 37 | 30 63 | 26 70
2022-01-18 16:33:16,884 - INFO - joeynmt.training - Example #2
2022-01-18 16:33:16,884 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 16:33:16,884 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:33:16,885 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 2 | 37 None | 4 40 | 11 16 | 21 5 | 42 47 | 39 6 | 22 48 | 19 5
2022-01-18 16:33:16,885 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    60000: bleu:  48.09, loss: 158986.0156, ppl:   2.6842, duration: 246.8322s
2022-01-18 16:34:03,023 - INFO - joeynmt.training - Epoch  23, Step:    60100, Batch Loss:    18.484884, Tokens per Sec:     1498, Lr: 0.000200
2022-01-18 16:34:21,904 - INFO - joeynmt.training - Epoch  23, Step:    60200, Batch Loss:    17.326603, Tokens per Sec:     3663, Lr: 0.000200
2022-01-18 16:34:51,491 - INFO - joeynmt.training - Epoch  23, Step:    60300, Batch Loss:    38.123962, Tokens per Sec:     2254, Lr: 0.000200
2022-01-18 16:35:18,209 - INFO - joeynmt.training - Epoch  23, Step:    60400, Batch Loss:    17.619114, Tokens per Sec:     2487, Lr: 0.000200
2022-01-18 16:35:37,938 - INFO - joeynmt.training - Epoch  23, Step:    60500, Batch Loss:    19.581377, Tokens per Sec:     3497, Lr: 0.000200
2022-01-18 16:36:27,210 - INFO - joeynmt.training - Epoch  23, Step:    60600, Batch Loss:    22.072777, Tokens per Sec:     1348, Lr: 0.000200
2022-01-18 16:37:10,942 - INFO - joeynmt.training - Epoch  23, Step:    60700, Batch Loss:    17.032928, Tokens per Sec:     1552, Lr: 0.000200
2022-01-18 16:37:29,467 - INFO - joeynmt.training - Epoch  23, Step:    60800, Batch Loss:    16.927038, Tokens per Sec:     3728, Lr: 0.000200
2022-01-18 16:37:48,129 - INFO - joeynmt.training - Epoch  23, Step:    60900, Batch Loss:    25.329943, Tokens per Sec:     3533, Lr: 0.000200
2022-01-18 16:38:06,727 - INFO - joeynmt.training - Epoch  23, Step:    61000, Batch Loss:    13.905216, Tokens per Sec:     3722, Lr: 0.000200
2022-01-18 16:42:08,382 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 16:42:41,162 - INFO - joeynmt.helpers - delete models/B_ablation/59000.ckpt
2022-01-18 16:42:41,248 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/59000.ckpt
2022-01-18 16:42:41,248 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/59000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/59000.ckpt')
2022-01-18 16:42:41,269 - INFO - joeynmt.training - Example #0
2022-01-18 16:42:41,269 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 16:42:41,269 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 16:42:41,269 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 16:42:41,269 - INFO - joeynmt.training - Example #1
2022-01-18 16:42:41,269 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 16:42:41,269 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 16:42:41,269 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 74 | 8 51 | 12 46 | 17 1 | 21 67 | 19 53 | 71 58 | 14 6 | 56 61 | 16 73 | 72 10 | 66 37 | 36 None | 26 23 | 30 63 | 20 67
2022-01-18 16:42:41,269 - INFO - joeynmt.training - Example #2
2022-01-18 16:42:41,269 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 16:42:41,270 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:42:41,270 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:42:41,270 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    61000: bleu:  49.48, loss: 155176.4219, ppl:   2.6214, duration: 274.5420s
2022-01-18 16:42:59,529 - INFO - joeynmt.training - Epoch  23: total training loss 49941.86
2022-01-18 16:42:59,530 - INFO - joeynmt.training - EPOCH 24
2022-01-18 16:43:00,134 - INFO - joeynmt.training - Epoch  24, Step:    61100, Batch Loss:    11.709008, Tokens per Sec:     4154, Lr: 0.000200
2022-01-18 16:43:18,698 - INFO - joeynmt.training - Epoch  24, Step:    61200, Batch Loss:    15.979028, Tokens per Sec:     3631, Lr: 0.000200
2022-01-18 16:43:37,257 - INFO - joeynmt.training - Epoch  24, Step:    61300, Batch Loss:    12.828402, Tokens per Sec:     3711, Lr: 0.000200
2022-01-18 16:43:55,990 - INFO - joeynmt.training - Epoch  24, Step:    61400, Batch Loss:    10.165256, Tokens per Sec:     3521, Lr: 0.000200
2022-01-18 16:44:14,775 - INFO - joeynmt.training - Epoch  24, Step:    61500, Batch Loss:    16.496332, Tokens per Sec:     3501, Lr: 0.000200
2022-01-18 16:44:33,761 - INFO - joeynmt.training - Epoch  24, Step:    61600, Batch Loss:     8.178349, Tokens per Sec:     3602, Lr: 0.000200
2022-01-18 16:44:52,496 - INFO - joeynmt.training - Epoch  24, Step:    61700, Batch Loss:    34.897964, Tokens per Sec:     3590, Lr: 0.000200
2022-01-18 16:45:11,280 - INFO - joeynmt.training - Epoch  24, Step:    61800, Batch Loss:    21.303381, Tokens per Sec:     3530, Lr: 0.000200
2022-01-18 16:45:30,180 - INFO - joeynmt.training - Epoch  24, Step:    61900, Batch Loss:    18.559355, Tokens per Sec:     3588, Lr: 0.000200
2022-01-18 16:45:48,732 - INFO - joeynmt.training - Epoch  24, Step:    62000, Batch Loss:    12.414377, Tokens per Sec:     3485, Lr: 0.000200
2022-01-18 16:49:54,691 - INFO - joeynmt.training - Example #0
2022-01-18 16:49:54,691 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 16:49:54,691 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 16:49:54,691 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 16:49:54,692 - INFO - joeynmt.training - Example #1
2022-01-18 16:49:54,692 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 16:49:54,692 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 16:49:54,692 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 53 | 65 50 | 32 74 | 8 51 | 12 41 | 17 46 | 21 67 | 19 58 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 6 | 30 63 | 26 23
2022-01-18 16:49:54,692 - INFO - joeynmt.training - Example #2
2022-01-18 16:49:54,692 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 16:49:54,692 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:49:54,692 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 16 | 11 40 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:49:54,692 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    62000: bleu:  48.95, loss: 156952.5781, ppl:   2.6505, duration: 245.9600s
2022-01-18 16:50:12,894 - INFO - joeynmt.training - Epoch  24, Step:    62100, Batch Loss:    17.018003, Tokens per Sec:     3800, Lr: 0.000200
2022-01-18 16:50:31,434 - INFO - joeynmt.training - Epoch  24, Step:    62200, Batch Loss:    13.764973, Tokens per Sec:     3596, Lr: 0.000200
2022-01-18 16:50:50,277 - INFO - joeynmt.training - Epoch  24, Step:    62300, Batch Loss:    31.040079, Tokens per Sec:     3619, Lr: 0.000200
2022-01-18 16:51:09,460 - INFO - joeynmt.training - Epoch  24, Step:    62400, Batch Loss:    22.473259, Tokens per Sec:     3611, Lr: 0.000200
2022-01-18 16:51:28,469 - INFO - joeynmt.training - Epoch  24, Step:    62500, Batch Loss:     8.781434, Tokens per Sec:     3440, Lr: 0.000200
2022-01-18 16:51:47,266 - INFO - joeynmt.training - Epoch  24, Step:    62600, Batch Loss:    39.992348, Tokens per Sec:     3682, Lr: 0.000200
2022-01-18 16:52:06,122 - INFO - joeynmt.training - Epoch  24, Step:    62700, Batch Loss:    15.291410, Tokens per Sec:     3670, Lr: 0.000200
2022-01-18 16:52:24,910 - INFO - joeynmt.training - Epoch  24, Step:    62800, Batch Loss:    18.370010, Tokens per Sec:     3662, Lr: 0.000200
2022-01-18 16:52:43,610 - INFO - joeynmt.training - Epoch  24, Step:    62900, Batch Loss:    32.692158, Tokens per Sec:     3597, Lr: 0.000200
2022-01-18 16:53:02,403 - INFO - joeynmt.training - Epoch  24, Step:    63000, Batch Loss:    13.564926, Tokens per Sec:     3587, Lr: 0.000200
2022-01-18 16:57:01,585 - INFO - joeynmt.training - Example #0
2022-01-18 16:57:01,587 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 16:57:01,588 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 16:57:01,588 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 16:57:01,588 - INFO - joeynmt.training - Example #1
2022-01-18 16:57:01,588 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 16:57:01,588 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 16:57:01,588 - INFO - joeynmt.training - 	Hypothesis: 13 51 | 35 50 | 65 46 | 32 74 | 8 1 | 12 41 | 17 67 | 21 73 | 19 53 | 71 58 | 14 61 | 56 6 | 16 42 | 22 37 | 72 10 | 66 23 | 36 63 | 30 70 | 26 None
2022-01-18 16:57:01,588 - INFO - joeynmt.training - Example #2
2022-01-18 16:57:01,589 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 16:57:01,589 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:57:01,589 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 16:57:01,589 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    63000: bleu:  49.19, loss: 157582.1562, ppl:   2.6609, duration: 239.1860s
2022-01-18 16:57:20,384 - INFO - joeynmt.training - Epoch  24, Step:    63100, Batch Loss:    17.822329, Tokens per Sec:     3659, Lr: 0.000200
2022-01-18 16:57:39,257 - INFO - joeynmt.training - Epoch  24, Step:    63200, Batch Loss:    23.702461, Tokens per Sec:     3603, Lr: 0.000200
2022-01-18 16:57:58,091 - INFO - joeynmt.training - Epoch  24, Step:    63300, Batch Loss:    16.384045, Tokens per Sec:     3646, Lr: 0.000200
2022-01-18 16:58:16,610 - INFO - joeynmt.training - Epoch  24, Step:    63400, Batch Loss:    24.711313, Tokens per Sec:     3554, Lr: 0.000200
2022-01-18 16:58:36,272 - INFO - joeynmt.training - Epoch  24, Step:    63500, Batch Loss:    10.242499, Tokens per Sec:     3479, Lr: 0.000200
2022-01-18 16:58:55,448 - INFO - joeynmt.training - Epoch  24, Step:    63600, Batch Loss:    14.420382, Tokens per Sec:     3612, Lr: 0.000200
2022-01-18 16:59:14,183 - INFO - joeynmt.training - Epoch  24, Step:    63700, Batch Loss:    18.217564, Tokens per Sec:     3469, Lr: 0.000200
2022-01-18 16:59:23,883 - INFO - joeynmt.training - Epoch  24: total training loss 47848.41
2022-01-18 16:59:23,883 - INFO - joeynmt.training - EPOCH 25
2022-01-18 16:59:32,817 - INFO - joeynmt.training - Epoch  25, Step:    63800, Batch Loss:    21.929569, Tokens per Sec:     3718, Lr: 0.000200
2022-01-18 16:59:51,237 - INFO - joeynmt.training - Epoch  25, Step:    63900, Batch Loss:    14.697277, Tokens per Sec:     3609, Lr: 0.000200
2022-01-18 17:00:10,246 - INFO - joeynmt.training - Epoch  25, Step:    64000, Batch Loss:    21.873653, Tokens per Sec:     3587, Lr: 0.000200
2022-01-18 17:04:11,845 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 17:04:44,857 - INFO - joeynmt.helpers - delete models/B_ablation/61000.ckpt
2022-01-18 17:04:44,942 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/61000.ckpt
2022-01-18 17:04:44,943 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/61000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/61000.ckpt')
2022-01-18 17:04:44,969 - INFO - joeynmt.training - Example #0
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 17:04:44,969 - INFO - joeynmt.training - Example #1
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 74 | 8 51 | 12 41 | 20 67 | 21 73 | 19 58 | 71 53 | 14 61 | 56 6 | 16 42 | 22 37 | 72 10 | 66 23 | 36 63 | 30 70 | 26 None
2022-01-18 17:04:44,969 - INFO - joeynmt.training - Example #2
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:04:44,969 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 30 | 4 45 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:04:44,970 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    64000: bleu:  49.93, loss: 157784.5000, ppl:   2.6642, duration: 274.7235s
2022-01-18 17:05:03,760 - INFO - joeynmt.training - Epoch  25, Step:    64100, Batch Loss:     5.823252, Tokens per Sec:     3565, Lr: 0.000200
2022-01-18 17:05:22,617 - INFO - joeynmt.training - Epoch  25, Step:    64200, Batch Loss:    16.093405, Tokens per Sec:     3523, Lr: 0.000200
2022-01-18 17:05:41,282 - INFO - joeynmt.training - Epoch  25, Step:    64300, Batch Loss:    22.079044, Tokens per Sec:     3547, Lr: 0.000200
2022-01-18 17:06:00,088 - INFO - joeynmt.training - Epoch  25, Step:    64400, Batch Loss:    25.057199, Tokens per Sec:     3603, Lr: 0.000200
2022-01-18 17:06:18,905 - INFO - joeynmt.training - Epoch  25, Step:    64500, Batch Loss:    16.204355, Tokens per Sec:     3599, Lr: 0.000200
2022-01-18 17:06:37,642 - INFO - joeynmt.training - Epoch  25, Step:    64600, Batch Loss:    11.705425, Tokens per Sec:     3551, Lr: 0.000200
2022-01-18 17:06:56,274 - INFO - joeynmt.training - Epoch  25, Step:    64700, Batch Loss:    16.360199, Tokens per Sec:     3639, Lr: 0.000200
2022-01-18 17:07:15,384 - INFO - joeynmt.training - Epoch  25, Step:    64800, Batch Loss:     8.702240, Tokens per Sec:     3498, Lr: 0.000200
2022-01-18 17:07:33,888 - INFO - joeynmt.training - Epoch  25, Step:    64900, Batch Loss:    13.803911, Tokens per Sec:     3586, Lr: 0.000200
2022-01-18 17:07:52,688 - INFO - joeynmt.training - Epoch  25, Step:    65000, Batch Loss:    13.024909, Tokens per Sec:     3538, Lr: 0.000200
2022-01-18 17:11:56,850 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 17:12:29,615 - INFO - joeynmt.helpers - delete models/B_ablation/64000.ckpt
2022-01-18 17:12:29,703 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/64000.ckpt
2022-01-18 17:12:29,703 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/64000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/64000.ckpt')
2022-01-18 17:12:29,727 - INFO - joeynmt.training - Example #0
2022-01-18 17:12:29,727 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 17:12:29,727 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 17:12:29,727 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 17:12:29,727 - INFO - joeynmt.training - Example #1
2022-01-18 17:12:29,728 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 17:12:29,728 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 17:12:29,728 - INFO - joeynmt.training - 	Hypothesis: 13 50 | 35 7 | 65 74 | 32 32 1 | 8 51 | 12 41 | 17 46 | 21 67 | 19 53 | 71 58 | 14 6 | 56 42 | 16 73 | 72 10 | 66 37 | 36 None | 30 63 | 26 23 | 20 67
2022-01-18 17:12:29,728 - INFO - joeynmt.training - Example #2
2022-01-18 17:12:29,728 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 17:12:29,728 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:12:29,728 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:12:29,728 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    65000: bleu:  51.13, loss: 155219.6094, ppl:   2.6221, duration: 277.0401s
2022-01-18 17:12:48,613 - INFO - joeynmt.training - Epoch  25, Step:    65100, Batch Loss:    20.447830, Tokens per Sec:     3574, Lr: 0.000200
2022-01-18 17:13:07,581 - INFO - joeynmt.training - Epoch  25, Step:    65200, Batch Loss:    17.301987, Tokens per Sec:     3628, Lr: 0.000200
2022-01-18 17:13:26,281 - INFO - joeynmt.training - Epoch  25, Step:    65300, Batch Loss:    13.099142, Tokens per Sec:     3702, Lr: 0.000200
2022-01-18 17:13:45,198 - INFO - joeynmt.training - Epoch  25, Step:    65400, Batch Loss:     8.286504, Tokens per Sec:     3533, Lr: 0.000200
2022-01-18 17:14:03,716 - INFO - joeynmt.training - Epoch  25, Step:    65500, Batch Loss:     9.143229, Tokens per Sec:     3656, Lr: 0.000200
2022-01-18 17:14:22,398 - INFO - joeynmt.training - Epoch  25, Step:    65600, Batch Loss:     5.509159, Tokens per Sec:     3584, Lr: 0.000200
2022-01-18 17:14:41,022 - INFO - joeynmt.training - Epoch  25, Step:    65700, Batch Loss:    19.256277, Tokens per Sec:     3502, Lr: 0.000200
2022-01-18 17:14:59,690 - INFO - joeynmt.training - Epoch  25, Step:    65800, Batch Loss:    15.059654, Tokens per Sec:     3646, Lr: 0.000200
2022-01-18 17:15:18,496 - INFO - joeynmt.training - Epoch  25, Step:    65900, Batch Loss:    18.498228, Tokens per Sec:     3695, Lr: 0.000200
2022-01-18 17:15:37,201 - INFO - joeynmt.training - Epoch  25, Step:    66000, Batch Loss:    20.019083, Tokens per Sec:     3699, Lr: 0.000200
2022-01-18 17:19:38,078 - INFO - joeynmt.training - Example #0
2022-01-18 17:19:38,079 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 17:19:38,079 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 17:19:38,079 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 17:19:38,079 - INFO - joeynmt.training - Example #1
2022-01-18 17:19:38,079 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 17:19:38,079 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 17:19:38,079 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 41 | 12 46 | 20 67 | 21 51 | 19 53 | 71 44 | 14 61 | 56 6 | 16 73 | 22 42 | 72 10 | 66 37 | 36 None | 30 23 | 26 63
2022-01-18 17:19:38,079 - INFO - joeynmt.training - Example #2
2022-01-18 17:19:38,079 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 17:19:38,079 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:19:38,080 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:19:38,080 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    66000: bleu:  49.77, loss: 155194.8281, ppl:   2.6217, duration: 240.8784s
2022-01-18 17:19:56,533 - INFO - joeynmt.training - Epoch  25, Step:    66100, Batch Loss:     8.082087, Tokens per Sec:     3773, Lr: 0.000200
2022-01-18 17:20:15,325 - INFO - joeynmt.training - Epoch  25, Step:    66200, Batch Loss:     9.057191, Tokens per Sec:     3681, Lr: 0.000200
2022-01-18 17:20:34,075 - INFO - joeynmt.training - Epoch  25, Step:    66300, Batch Loss:    23.004196, Tokens per Sec:     3575, Lr: 0.000200
2022-01-18 17:20:52,695 - INFO - joeynmt.training - Epoch  25, Step:    66400, Batch Loss:    18.878458, Tokens per Sec:     3644, Lr: 0.000200
2022-01-18 17:20:53,921 - INFO - joeynmt.training - Epoch  25: total training loss 45569.49
2022-01-18 17:20:53,921 - INFO - joeynmt.training - EPOCH 26
2022-01-18 17:21:11,128 - INFO - joeynmt.training - Epoch  26, Step:    66500, Batch Loss:    20.896231, Tokens per Sec:     3608, Lr: 0.000200
2022-01-18 17:21:29,861 - INFO - joeynmt.training - Epoch  26, Step:    66600, Batch Loss:    20.108761, Tokens per Sec:     3678, Lr: 0.000200
2022-01-18 17:21:48,600 - INFO - joeynmt.training - Epoch  26, Step:    66700, Batch Loss:     4.512001, Tokens per Sec:     3669, Lr: 0.000200
2022-01-18 17:22:07,421 - INFO - joeynmt.training - Epoch  26, Step:    66800, Batch Loss:    17.774006, Tokens per Sec:     3571, Lr: 0.000200
2022-01-18 17:22:26,276 - INFO - joeynmt.training - Epoch  26, Step:    66900, Batch Loss:     8.759866, Tokens per Sec:     3698, Lr: 0.000200
2022-01-18 17:22:45,170 - INFO - joeynmt.training - Epoch  26, Step:    67000, Batch Loss:    16.123169, Tokens per Sec:     3634, Lr: 0.000200
2022-01-18 17:26:46,580 - INFO - joeynmt.training - Example #0
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 17:26:46,581 - INFO - joeynmt.training - Example #1
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 7 | 65 50 | 32 74 | 8 51 | 12 41 | 17 46 | 20 67 | 21 42 | 19 53 | 71 0 | 14 61 | 56 59 | 16 73 | 22 23 | 72 10 | 66 37 | 36 6 | 30 63
2022-01-18 17:26:46,581 - INFO - joeynmt.training - Example #2
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:26:46,581 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:26:46,582 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    67000: bleu:  50.33, loss: 155607.6875, ppl:   2.6284, duration: 241.4113s
2022-01-18 17:27:05,402 - INFO - joeynmt.training - Epoch  26, Step:    67100, Batch Loss:    15.935999, Tokens per Sec:     3598, Lr: 0.000200
2022-01-18 17:27:24,329 - INFO - joeynmt.training - Epoch  26, Step:    67200, Batch Loss:    18.798088, Tokens per Sec:     3585, Lr: 0.000200
2022-01-18 17:27:43,180 - INFO - joeynmt.training - Epoch  26, Step:    67300, Batch Loss:    16.467976, Tokens per Sec:     3632, Lr: 0.000200
2022-01-18 17:28:01,804 - INFO - joeynmt.training - Epoch  26, Step:    67400, Batch Loss:    22.088966, Tokens per Sec:     3618, Lr: 0.000200
2022-01-18 17:28:20,353 - INFO - joeynmt.training - Epoch  26, Step:    67500, Batch Loss:     8.920214, Tokens per Sec:     3564, Lr: 0.000200
2022-01-18 17:28:38,915 - INFO - joeynmt.training - Epoch  26, Step:    67600, Batch Loss:    12.481896, Tokens per Sec:     3586, Lr: 0.000200
2022-01-18 17:28:57,633 - INFO - joeynmt.training - Epoch  26, Step:    67700, Batch Loss:    12.106219, Tokens per Sec:     3609, Lr: 0.000200
2022-01-18 17:29:16,409 - INFO - joeynmt.training - Epoch  26, Step:    67800, Batch Loss:    11.066875, Tokens per Sec:     3701, Lr: 0.000200
2022-01-18 17:29:35,001 - INFO - joeynmt.training - Epoch  26, Step:    67900, Batch Loss:    23.385996, Tokens per Sec:     3623, Lr: 0.000200
2022-01-18 17:29:53,733 - INFO - joeynmt.training - Epoch  26, Step:    68000, Batch Loss:    16.136209, Tokens per Sec:     3623, Lr: 0.000200
2022-01-18 17:33:54,782 - INFO - joeynmt.training - Example #0
2022-01-18 17:33:54,783 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 17:33:54,783 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 17:33:54,783 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 17:33:54,783 - INFO - joeynmt.training - Example #1
2022-01-18 17:33:54,783 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 17:33:54,783 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 17:33:54,783 - INFO - joeynmt.training - 	Hypothesis: 13 61 | 35 0 | 65 50 | 32 7 | 8 46 | 12 1 | 20 67 | 21 42 | 19 58 | 71 53 | 14 6 | 56 59 | 16 73 | 22 10 | 72 37 | 66 23 | 36 63 | 30 70 | 26 70
2022-01-18 17:33:54,784 - INFO - joeynmt.training - Example #2
2022-01-18 17:33:54,784 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 17:33:54,784 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:33:54,784 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:33:54,784 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    68000: bleu:  50.30, loss: 157653.3438, ppl:   2.6621, duration: 241.0502s
2022-01-18 17:34:13,559 - INFO - joeynmt.training - Epoch  26, Step:    68100, Batch Loss:    18.641661, Tokens per Sec:     3573, Lr: 0.000200
2022-01-18 17:34:32,172 - INFO - joeynmt.training - Epoch  26, Step:    68200, Batch Loss:    17.565229, Tokens per Sec:     3709, Lr: 0.000200
2022-01-18 17:34:50,884 - INFO - joeynmt.training - Epoch  26, Step:    68300, Batch Loss:     9.310925, Tokens per Sec:     3499, Lr: 0.000200
2022-01-18 17:35:09,809 - INFO - joeynmt.training - Epoch  26, Step:    68400, Batch Loss:    13.221029, Tokens per Sec:     3593, Lr: 0.000200
2022-01-18 17:35:28,406 - INFO - joeynmt.training - Epoch  26, Step:    68500, Batch Loss:     8.491792, Tokens per Sec:     3516, Lr: 0.000200
2022-01-18 17:35:47,061 - INFO - joeynmt.training - Epoch  26, Step:    68600, Batch Loss:     7.829791, Tokens per Sec:     3679, Lr: 0.000200
2022-01-18 17:36:05,801 - INFO - joeynmt.training - Epoch  26, Step:    68700, Batch Loss:    15.663479, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 17:36:24,591 - INFO - joeynmt.training - Epoch  26, Step:    68800, Batch Loss:    12.882299, Tokens per Sec:     3542, Lr: 0.000200
2022-01-18 17:36:43,360 - INFO - joeynmt.training - Epoch  26, Step:    68900, Batch Loss:     9.079438, Tokens per Sec:     3634, Lr: 0.000200
2022-01-18 17:37:02,086 - INFO - joeynmt.training - Epoch  26, Step:    69000, Batch Loss:    31.904827, Tokens per Sec:     3654, Lr: 0.000200
2022-01-18 17:41:03,713 - INFO - joeynmt.training - Example #0
2022-01-18 17:41:03,715 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 17:41:03,715 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 17:41:03,715 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12 | 2 30
2022-01-18 17:41:03,715 - INFO - joeynmt.training - Example #1
2022-01-18 17:41:03,715 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 17:41:03,715 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 17:41:03,715 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 74 | 8 51 | 12 46 | 20 67 | 21 73 | 19 53 | 71 58 | 14 61 | 56 6 | 16 42 | 22 10 | 72 23 | 66 37 | 36 None | 30 70 | 26 63
2022-01-18 17:41:03,716 - INFO - joeynmt.training - Example #2
2022-01-18 17:41:03,716 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 17:41:03,716 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:41:03,716 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:41:03,716 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    69000: bleu:  50.88, loss: 155483.0625, ppl:   2.6264, duration: 241.6298s
2022-01-18 17:41:14,065 - INFO - joeynmt.training - Epoch  26: total training loss 43575.77
2022-01-18 17:41:14,065 - INFO - joeynmt.training - EPOCH 27
2022-01-18 17:41:22,324 - INFO - joeynmt.training - Epoch  27, Step:    69100, Batch Loss:    25.704960, Tokens per Sec:     3727, Lr: 0.000200
2022-01-18 17:41:40,798 - INFO - joeynmt.training - Epoch  27, Step:    69200, Batch Loss:    10.925426, Tokens per Sec:     3716, Lr: 0.000200
2022-01-18 17:41:59,547 - INFO - joeynmt.training - Epoch  27, Step:    69300, Batch Loss:     7.247270, Tokens per Sec:     3671, Lr: 0.000200
2022-01-18 17:42:18,070 - INFO - joeynmt.training - Epoch  27, Step:    69400, Batch Loss:    20.319620, Tokens per Sec:     3659, Lr: 0.000200
2022-01-18 17:42:36,581 - INFO - joeynmt.training - Epoch  27, Step:    69500, Batch Loss:    11.649116, Tokens per Sec:     3609, Lr: 0.000200
2022-01-18 17:42:55,217 - INFO - joeynmt.training - Epoch  27, Step:    69600, Batch Loss:    21.217075, Tokens per Sec:     3617, Lr: 0.000200
2022-01-18 17:43:13,827 - INFO - joeynmt.training - Epoch  27, Step:    69700, Batch Loss:    15.413127, Tokens per Sec:     3498, Lr: 0.000200
2022-01-18 17:43:32,728 - INFO - joeynmt.training - Epoch  27, Step:    69800, Batch Loss:    12.270824, Tokens per Sec:     3595, Lr: 0.000200
2022-01-18 17:43:51,905 - INFO - joeynmt.training - Epoch  27, Step:    69900, Batch Loss:    10.831101, Tokens per Sec:     3499, Lr: 0.000200
2022-01-18 17:44:10,712 - INFO - joeynmt.training - Epoch  27, Step:    70000, Batch Loss:    15.556747, Tokens per Sec:     3589, Lr: 0.000200
2022-01-18 17:48:12,623 - INFO - joeynmt.training - Example #0
2022-01-18 17:48:12,624 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 17:48:12,624 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 17:48:12,624 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 12 | 25 5 | 37 17 | 8 13 | 33 None
2022-01-18 17:48:12,624 - INFO - joeynmt.training - Example #1
2022-01-18 17:48:12,624 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 17:48:12,625 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 17:48:12,625 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 0 | 65 50 | 32 74 | 8 46 | 12 41 | 17 51 | 20 67 | 19 53 | 71 59 | 14 61 | 56 6 | 16 42 | 22 37 | 72 10 | 66 23 | 36 None | 30 70 | 26 63
2022-01-18 17:48:12,625 - INFO - joeynmt.training - Example #2
2022-01-18 17:48:12,625 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 17:48:12,625 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:48:12,625 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:48:12,625 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    70000: bleu:  50.77, loss: 156860.4844, ppl:   2.6490, duration: 241.9126s
2022-01-18 17:48:31,236 - INFO - joeynmt.training - Epoch  27, Step:    70100, Batch Loss:    18.173792, Tokens per Sec:     3611, Lr: 0.000200
2022-01-18 17:48:49,918 - INFO - joeynmt.training - Epoch  27, Step:    70200, Batch Loss:    16.077042, Tokens per Sec:     3585, Lr: 0.000200
2022-01-18 17:49:08,750 - INFO - joeynmt.training - Epoch  27, Step:    70300, Batch Loss:    19.023396, Tokens per Sec:     3560, Lr: 0.000200
2022-01-18 17:49:27,432 - INFO - joeynmt.training - Epoch  27, Step:    70400, Batch Loss:    18.278339, Tokens per Sec:     3560, Lr: 0.000200
2022-01-18 17:49:46,212 - INFO - joeynmt.training - Epoch  27, Step:    70500, Batch Loss:    14.849588, Tokens per Sec:     3672, Lr: 0.000200
2022-01-18 17:50:04,934 - INFO - joeynmt.training - Epoch  27, Step:    70600, Batch Loss:    13.072385, Tokens per Sec:     3734, Lr: 0.000200
2022-01-18 17:50:23,760 - INFO - joeynmt.training - Epoch  27, Step:    70700, Batch Loss:     9.532122, Tokens per Sec:     3637, Lr: 0.000200
2022-01-18 17:50:42,232 - INFO - joeynmt.training - Epoch  27, Step:    70800, Batch Loss:    14.920185, Tokens per Sec:     3601, Lr: 0.000200
2022-01-18 17:51:00,860 - INFO - joeynmt.training - Epoch  27, Step:    70900, Batch Loss:    10.473818, Tokens per Sec:     3616, Lr: 0.000200
2022-01-18 17:51:19,466 - INFO - joeynmt.training - Epoch  27, Step:    71000, Batch Loss:    11.453546, Tokens per Sec:     3672, Lr: 0.000200
2022-01-18 17:55:24,059 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 17:55:56,858 - INFO - joeynmt.helpers - delete models/B_ablation/65000.ckpt
2022-01-18 17:55:56,941 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/65000.ckpt
2022-01-18 17:55:56,941 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/65000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/65000.ckpt')
2022-01-18 17:55:56,984 - INFO - joeynmt.training - Example #0
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 17:55:56,985 - INFO - joeynmt.training - Example #1
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 50 | 65 74 | 32 46 | 8 51 | 12 41 | 17 1 | 20 67 | 19 53 | 71 58 | 14 61 | 56 6 | 16 73 | 22 42 | 72 10 | 66 37 | 36 None | 30 63 | 26 23
2022-01-18 17:55:56,985 - INFO - joeynmt.training - Example #2
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:55:56,985 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 17:55:56,985 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    71000: bleu:  51.57, loss: 156754.3438, ppl:   2.6472, duration: 277.5184s
2022-01-18 17:56:15,598 - INFO - joeynmt.training - Epoch  27, Step:    71100, Batch Loss:    15.896301, Tokens per Sec:     3712, Lr: 0.000200
2022-01-18 17:56:34,242 - INFO - joeynmt.training - Epoch  27, Step:    71200, Batch Loss:    10.323113, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 17:56:52,908 - INFO - joeynmt.training - Epoch  27, Step:    71300, Batch Loss:     9.036818, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 17:57:11,498 - INFO - joeynmt.training - Epoch  27, Step:    71400, Batch Loss:    19.501139, Tokens per Sec:     3654, Lr: 0.000200
2022-01-18 17:57:29,950 - INFO - joeynmt.training - Epoch  27, Step:    71500, Batch Loss:    23.997456, Tokens per Sec:     3586, Lr: 0.000200
2022-01-18 17:57:48,683 - INFO - joeynmt.training - Epoch  27, Step:    71600, Batch Loss:    14.640483, Tokens per Sec:     3607, Lr: 0.000200
2022-01-18 17:58:07,417 - INFO - joeynmt.training - Epoch  27, Step:    71700, Batch Loss:     9.542502, Tokens per Sec:     3579, Lr: 0.000200
2022-01-18 17:58:08,710 - INFO - joeynmt.training - Epoch  27: total training loss 41699.32
2022-01-18 17:58:08,710 - INFO - joeynmt.training - EPOCH 28
2022-01-18 17:58:26,234 - INFO - joeynmt.training - Epoch  28, Step:    71800, Batch Loss:    15.020829, Tokens per Sec:     3535, Lr: 0.000200
2022-01-18 17:58:44,994 - INFO - joeynmt.training - Epoch  28, Step:    71900, Batch Loss:    13.724524, Tokens per Sec:     3537, Lr: 0.000200
2022-01-18 17:59:03,628 - INFO - joeynmt.training - Epoch  28, Step:    72000, Batch Loss:     8.798944, Tokens per Sec:     3570, Lr: 0.000200
2022-01-18 18:03:05,796 - INFO - joeynmt.training - Example #0
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 18:03:05,797 - INFO - joeynmt.training - Example #1
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 20 67 | 21 53 | 19 7 | 71 58 | 14 61 | 56 50 | 16 42 | 22 10 | 72 37 | 66 23 | 36 6 | 30 70 | 26 63 | 35 51 | 65 74 | 32 1 | 8 41
2022-01-18 18:03:05,797 - INFO - joeynmt.training - Example #2
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:03:05,797 - INFO - joeynmt.training - 	Hypothesis: 8 24 | 23 46 | 50 2 | 37 None | 4 40 | 11 16 | 21 47 | 42 6 | 39 5 | 22 48 | 19 None
2022-01-18 18:03:05,797 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    72000: bleu:  51.03, loss: 159078.2500, ppl:   2.6857, duration: 242.1693s
2022-01-18 18:03:24,463 - INFO - joeynmt.training - Epoch  28, Step:    72100, Batch Loss:    14.683203, Tokens per Sec:     3736, Lr: 0.000200
2022-01-18 18:03:43,139 - INFO - joeynmt.training - Epoch  28, Step:    72200, Batch Loss:    23.544012, Tokens per Sec:     3701, Lr: 0.000200
2022-01-18 18:04:01,832 - INFO - joeynmt.training - Epoch  28, Step:    72300, Batch Loss:    16.098108, Tokens per Sec:     3507, Lr: 0.000200
2022-01-18 18:04:20,561 - INFO - joeynmt.training - Epoch  28, Step:    72400, Batch Loss:     7.492954, Tokens per Sec:     3683, Lr: 0.000200
2022-01-18 18:04:39,255 - INFO - joeynmt.training - Epoch  28, Step:    72500, Batch Loss:    13.594313, Tokens per Sec:     3753, Lr: 0.000200
2022-01-18 18:04:57,759 - INFO - joeynmt.training - Epoch  28, Step:    72600, Batch Loss:    29.631021, Tokens per Sec:     3533, Lr: 0.000200
2022-01-18 18:05:16,329 - INFO - joeynmt.training - Epoch  28, Step:    72700, Batch Loss:     8.918628, Tokens per Sec:     3564, Lr: 0.000200
2022-01-18 18:05:35,083 - INFO - joeynmt.training - Epoch  28, Step:    72800, Batch Loss:    42.745247, Tokens per Sec:     3675, Lr: 0.000200
2022-01-18 18:05:53,559 - INFO - joeynmt.training - Epoch  28, Step:    72900, Batch Loss:    17.936750, Tokens per Sec:     3517, Lr: 0.000200
2022-01-18 18:06:12,187 - INFO - joeynmt.training - Epoch  28, Step:    73000, Batch Loss:    16.646606, Tokens per Sec:     3603, Lr: 0.000200
2022-01-18 18:10:13,464 - INFO - joeynmt.training - Example #0
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 18:10:13,465 - INFO - joeynmt.training - Example #1
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 50 | 65 53 | 32 74 | 8 51 | 12 41 | 20 67 | 21 46 | 19 0 | 71 63 | 14 61 | 56 59 | 16 42 | 22 10 | 72 23 | 66 37 | 36 6 | 30 70 | 26 61
2022-01-18 18:10:13,465 - INFO - joeynmt.training - Example #2
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:10:13,465 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:10:13,466 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    73000: bleu:  51.42, loss: 157687.0312, ppl:   2.6626, duration: 241.2779s
2022-01-18 18:10:32,293 - INFO - joeynmt.training - Epoch  28, Step:    73100, Batch Loss:     7.997988, Tokens per Sec:     3505, Lr: 0.000200
2022-01-18 18:10:50,692 - INFO - joeynmt.training - Epoch  28, Step:    73200, Batch Loss:    17.781036, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 18:11:09,132 - INFO - joeynmt.training - Epoch  28, Step:    73300, Batch Loss:    14.156273, Tokens per Sec:     3719, Lr: 0.000200
2022-01-18 18:11:28,091 - INFO - joeynmt.training - Epoch  28, Step:    73400, Batch Loss:    14.910812, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 18:11:46,790 - INFO - joeynmt.training - Epoch  28, Step:    73500, Batch Loss:    13.370174, Tokens per Sec:     3599, Lr: 0.000200
2022-01-18 18:12:05,572 - INFO - joeynmt.training - Epoch  28, Step:    73600, Batch Loss:    11.735666, Tokens per Sec:     3620, Lr: 0.000200
2022-01-18 18:12:24,155 - INFO - joeynmt.training - Epoch  28, Step:    73700, Batch Loss:    12.348514, Tokens per Sec:     3653, Lr: 0.000200
2022-01-18 18:12:42,860 - INFO - joeynmt.training - Epoch  28, Step:    73800, Batch Loss:    16.079197, Tokens per Sec:     3533, Lr: 0.000200
2022-01-18 18:13:01,375 - INFO - joeynmt.training - Epoch  28, Step:    73900, Batch Loss:    19.448448, Tokens per Sec:     3587, Lr: 0.000200
2022-01-18 18:13:20,037 - INFO - joeynmt.training - Epoch  28, Step:    74000, Batch Loss:    12.536763, Tokens per Sec:     3594, Lr: 0.000200
2022-01-18 18:17:22,222 - INFO - joeynmt.training - Example #0
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 18:17:22,223 - INFO - joeynmt.training - Example #1
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 50 | 65 74 | 32 1 | 8 51 | 12 46 | 17 67 | 21 73 | 19 53 | 71 58 | 14 6 | 56 61 | 16 42 | 22 10 | 72 37 | 66 23 | 36 None | 30 63 | 26 37
2022-01-18 18:17:22,223 - INFO - joeynmt.training - Example #2
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:17:22,223 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:17:22,223 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    74000: bleu:  51.46, loss: 155546.1250, ppl:   2.6274, duration: 242.1862s
2022-01-18 18:17:40,737 - INFO - joeynmt.training - Epoch  28, Step:    74100, Batch Loss:    21.279245, Tokens per Sec:     3503, Lr: 0.000200
2022-01-18 18:17:59,269 - INFO - joeynmt.training - Epoch  28, Step:    74200, Batch Loss:     8.571399, Tokens per Sec:     3700, Lr: 0.000200
2022-01-18 18:18:18,161 - INFO - joeynmt.training - Epoch  28, Step:    74300, Batch Loss:    21.756573, Tokens per Sec:     3675, Lr: 0.000200
2022-01-18 18:18:30,590 - INFO - joeynmt.training - Epoch  28: total training loss 39983.59
2022-01-18 18:18:30,590 - INFO - joeynmt.training - EPOCH 29
2022-01-18 18:18:36,613 - INFO - joeynmt.training - Epoch  29, Step:    74400, Batch Loss:    13.115480, Tokens per Sec:     3472, Lr: 0.000200
2022-01-18 18:18:55,195 - INFO - joeynmt.training - Epoch  29, Step:    74500, Batch Loss:     6.629651, Tokens per Sec:     3630, Lr: 0.000200
2022-01-18 18:19:13,889 - INFO - joeynmt.training - Epoch  29, Step:    74600, Batch Loss:    16.401888, Tokens per Sec:     3602, Lr: 0.000200
2022-01-18 18:19:32,634 - INFO - joeynmt.training - Epoch  29, Step:    74700, Batch Loss:     9.197884, Tokens per Sec:     3658, Lr: 0.000200
2022-01-18 18:19:51,391 - INFO - joeynmt.training - Epoch  29, Step:    74800, Batch Loss:    15.972207, Tokens per Sec:     3613, Lr: 0.000200
2022-01-18 18:20:10,051 - INFO - joeynmt.training - Epoch  29, Step:    74900, Batch Loss:    17.605810, Tokens per Sec:     3660, Lr: 0.000200
2022-01-18 18:20:28,883 - INFO - joeynmt.training - Epoch  29, Step:    75000, Batch Loss:    14.418267, Tokens per Sec:     3569, Lr: 0.000200
2022-01-18 18:24:30,940 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 18:25:04,184 - INFO - joeynmt.helpers - delete models/B_ablation/71000.ckpt
2022-01-18 18:25:04,261 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/71000.ckpt
2022-01-18 18:25:04,262 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/71000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/71000.ckpt')
2022-01-18 18:25:04,295 - INFO - joeynmt.training - Example #0
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 18:25:04,296 - INFO - joeynmt.training - Example #1
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 20 67 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 70 | 26 6 | 35 50 | 65 7 | 32 74 | 8 51 | 17 41 | 12 46
2022-01-18 18:25:04,296 - INFO - joeynmt.training - Example #2
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:25:04,296 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 45 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:25:04,296 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    75000: bleu:  52.09, loss: 156855.3438, ppl:   2.6489, duration: 275.4126s
2022-01-18 18:25:23,101 - INFO - joeynmt.training - Epoch  29, Step:    75100, Batch Loss:    14.678185, Tokens per Sec:     3755, Lr: 0.000200
2022-01-18 18:25:41,631 - INFO - joeynmt.training - Epoch  29, Step:    75200, Batch Loss:    19.375450, Tokens per Sec:     3529, Lr: 0.000200
2022-01-18 18:26:00,069 - INFO - joeynmt.training - Epoch  29, Step:    75300, Batch Loss:     9.745017, Tokens per Sec:     3576, Lr: 0.000200
2022-01-18 18:26:18,747 - INFO - joeynmt.training - Epoch  29, Step:    75400, Batch Loss:     8.091231, Tokens per Sec:     3696, Lr: 0.000200
2022-01-18 18:26:37,220 - INFO - joeynmt.training - Epoch  29, Step:    75500, Batch Loss:    14.778157, Tokens per Sec:     3701, Lr: 0.000200
2022-01-18 18:26:56,145 - INFO - joeynmt.training - Epoch  29, Step:    75600, Batch Loss:    12.026599, Tokens per Sec:     3587, Lr: 0.000200
2022-01-18 18:27:14,694 - INFO - joeynmt.training - Epoch  29, Step:    75700, Batch Loss:    14.010402, Tokens per Sec:     3669, Lr: 0.000200
2022-01-18 18:27:33,227 - INFO - joeynmt.training - Epoch  29, Step:    75800, Batch Loss:    22.138021, Tokens per Sec:     3668, Lr: 0.000200
2022-01-18 18:27:51,683 - INFO - joeynmt.training - Epoch  29, Step:    75900, Batch Loss:     7.961072, Tokens per Sec:     3540, Lr: 0.000200
2022-01-18 18:28:10,123 - INFO - joeynmt.training - Epoch  29, Step:    76000, Batch Loss:    11.913108, Tokens per Sec:     3633, Lr: 0.000200
2022-01-18 18:32:11,378 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2022-01-18 18:32:44,103 - INFO - joeynmt.helpers - delete models/B_ablation/75000.ckpt
2022-01-18 18:32:44,175 - INFO - joeynmt.helpers - delete /home/students/meier/AMR_ablation/models/B_ablation/75000.ckpt
2022-01-18 18:32:44,176 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /home/students/meier/AMR_ablation/models/B_ablation/75000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/home/students/meier/AMR_ablation/models/B_ablation/75000.ckpt')
2022-01-18 18:32:44,196 - INFO - joeynmt.training - Example #0
2022-01-18 18:32:44,196 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 18:32:44,196 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 18:32:44,196 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 18:32:44,196 - INFO - joeynmt.training - Example #1
2022-01-18 18:32:44,196 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 18:32:44,196 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 18:32:44,196 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 74 | 8 46 | 17 51 | 20 67 | 12 41 | 19 53 | 71 58 | 14 6 | 56 61 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70
2022-01-18 18:32:44,197 - INFO - joeynmt.training - Example #2
2022-01-18 18:32:44,197 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 18:32:44,197 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:32:44,197 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:32:44,197 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    76000: bleu:  52.39, loss: 156426.0781, ppl:   2.6418, duration: 274.0735s
2022-01-18 18:33:02,722 - INFO - joeynmt.training - Epoch  29, Step:    76100, Batch Loss:    15.735245, Tokens per Sec:     3696, Lr: 0.000200
2022-01-18 18:33:21,433 - INFO - joeynmt.training - Epoch  29, Step:    76200, Batch Loss:     9.894967, Tokens per Sec:     3616, Lr: 0.000200
2022-01-18 18:33:39,937 - INFO - joeynmt.training - Epoch  29, Step:    76300, Batch Loss:    17.764271, Tokens per Sec:     3567, Lr: 0.000200
2022-01-18 18:33:58,672 - INFO - joeynmt.training - Epoch  29, Step:    76400, Batch Loss:    13.739395, Tokens per Sec:     3595, Lr: 0.000200
2022-01-18 18:34:17,591 - INFO - joeynmt.training - Epoch  29, Step:    76500, Batch Loss:    16.287815, Tokens per Sec:     3636, Lr: 0.000200
2022-01-18 18:34:36,337 - INFO - joeynmt.training - Epoch  29, Step:    76600, Batch Loss:    24.312342, Tokens per Sec:     3642, Lr: 0.000200
2022-01-18 18:34:55,065 - INFO - joeynmt.training - Epoch  29, Step:    76700, Batch Loss:    15.160117, Tokens per Sec:     3675, Lr: 0.000200
2022-01-18 18:35:13,824 - INFO - joeynmt.training - Epoch  29, Step:    76800, Batch Loss:    12.643706, Tokens per Sec:     3499, Lr: 0.000200
2022-01-18 18:35:32,753 - INFO - joeynmt.training - Epoch  29, Step:    76900, Batch Loss:    12.471499, Tokens per Sec:     3600, Lr: 0.000200
2022-01-18 18:35:51,563 - INFO - joeynmt.training - Epoch  29, Step:    77000, Batch Loss:    13.959696, Tokens per Sec:     3562, Lr: 0.000200
2022-01-18 18:39:54,641 - INFO - joeynmt.training - Example #0
2022-01-18 18:39:54,642 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 18:39:54,642 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 18:39:54,642 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 18:39:54,642 - INFO - joeynmt.training - Example #1
2022-01-18 18:39:54,642 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 18:39:54,642 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 18:39:54,642 - INFO - joeynmt.training - 	Hypothesis: 13 0 | 35 7 | 65 50 | 32 74 | 8 46 | 17 41 | 12 51 | 20 67 | 19 53 | 71 58 | 14 6 | 56 61 | 16 73 | 22 42 | 72 10 | 66 37 | 36 63 | 26 23 | 21 10
2022-01-18 18:39:54,642 - INFO - joeynmt.training - Example #2
2022-01-18 18:39:54,643 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 18:39:54,643 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:39:54,643 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 45 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:39:54,643 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    77000: bleu:  52.15, loss: 156323.3750, ppl:   2.6402, duration: 243.0796s
2022-01-18 18:39:58,374 - INFO - joeynmt.training - Epoch  29: total training loss 37963.98
2022-01-18 18:39:58,374 - INFO - joeynmt.training - EPOCH 30
2022-01-18 18:40:13,333 - INFO - joeynmt.training - Epoch  30, Step:    77100, Batch Loss:    21.269650, Tokens per Sec:     3649, Lr: 0.000200
2022-01-18 18:40:32,012 - INFO - joeynmt.training - Epoch  30, Step:    77200, Batch Loss:    19.346941, Tokens per Sec:     3684, Lr: 0.000200
2022-01-18 18:40:50,669 - INFO - joeynmt.training - Epoch  30, Step:    77300, Batch Loss:     9.792873, Tokens per Sec:     3609, Lr: 0.000200
2022-01-18 18:41:09,325 - INFO - joeynmt.training - Epoch  30, Step:    77400, Batch Loss:    12.314875, Tokens per Sec:     3650, Lr: 0.000200
2022-01-18 18:41:27,856 - INFO - joeynmt.training - Epoch  30, Step:    77500, Batch Loss:    15.670593, Tokens per Sec:     3644, Lr: 0.000200
2022-01-18 18:41:46,492 - INFO - joeynmt.training - Epoch  30, Step:    77600, Batch Loss:    20.467678, Tokens per Sec:     3627, Lr: 0.000200
2022-01-18 18:42:05,166 - INFO - joeynmt.training - Epoch  30, Step:    77700, Batch Loss:    12.587060, Tokens per Sec:     3608, Lr: 0.000200
2022-01-18 18:42:24,047 - INFO - joeynmt.training - Epoch  30, Step:    77800, Batch Loss:    13.606282, Tokens per Sec:     3631, Lr: 0.000200
2022-01-18 18:42:42,831 - INFO - joeynmt.training - Epoch  30, Step:    77900, Batch Loss:    21.381914, Tokens per Sec:     3604, Lr: 0.000200
2022-01-18 18:43:01,201 - INFO - joeynmt.training - Epoch  30, Step:    78000, Batch Loss:    14.538554, Tokens per Sec:     3517, Lr: 0.000200
2022-01-18 18:47:04,544 - INFO - joeynmt.training - Example #0
2022-01-18 18:47:04,545 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 18:47:04,545 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 18:47:04,545 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 18:47:04,545 - INFO - joeynmt.training - Example #1
2022-01-18 18:47:04,545 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 18:47:04,546 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 18:47:04,546 - INFO - joeynmt.training - 	Hypothesis: 13 58 | 35 53 | 65 50 | 32 74 | 8 41 | 12 46 | 17 1 | 21 67 | 19 0 | 71 10 | 14 6 | 56 59 | 16 73 | 22 42 | 72 37 | 66 23 | 36 63 | 30 37 | 26 61
2022-01-18 18:47:04,546 - INFO - joeynmt.training - Example #2
2022-01-18 18:47:04,546 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 18:47:04,546 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:47:04,546 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:47:04,546 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    78000: bleu:  52.23, loss: 157702.0156, ppl:   2.6629, duration: 243.3448s
2022-01-18 18:47:23,177 - INFO - joeynmt.training - Epoch  30, Step:    78100, Batch Loss:    12.538813, Tokens per Sec:     3523, Lr: 0.000200
2022-01-18 18:47:42,021 - INFO - joeynmt.training - Epoch  30, Step:    78200, Batch Loss:    14.906520, Tokens per Sec:     3596, Lr: 0.000200
2022-01-18 18:48:00,884 - INFO - joeynmt.training - Epoch  30, Step:    78300, Batch Loss:    12.065884, Tokens per Sec:     3619, Lr: 0.000200
2022-01-18 18:48:19,581 - INFO - joeynmt.training - Epoch  30, Step:    78400, Batch Loss:     9.308286, Tokens per Sec:     3638, Lr: 0.000200
2022-01-18 18:48:38,450 - INFO - joeynmt.training - Epoch  30, Step:    78500, Batch Loss:    15.917197, Tokens per Sec:     3592, Lr: 0.000200
2022-01-18 18:48:57,136 - INFO - joeynmt.training - Epoch  30, Step:    78600, Batch Loss:     9.802511, Tokens per Sec:     3601, Lr: 0.000200
2022-01-18 18:49:15,734 - INFO - joeynmt.training - Epoch  30, Step:    78700, Batch Loss:    10.351904, Tokens per Sec:     3470, Lr: 0.000200
2022-01-18 18:49:34,259 - INFO - joeynmt.training - Epoch  30, Step:    78800, Batch Loss:     7.980776, Tokens per Sec:     3624, Lr: 0.000200
2022-01-18 18:49:52,886 - INFO - joeynmt.training - Epoch  30, Step:    78900, Batch Loss:     8.265190, Tokens per Sec:     3655, Lr: 0.000200
2022-01-18 18:50:11,613 - INFO - joeynmt.training - Epoch  30, Step:    79000, Batch Loss:     5.839516, Tokens per Sec:     3610, Lr: 0.000200
2022-01-18 18:54:12,887 - INFO - joeynmt.training - Example #0
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Source:     ( 34 / 9 :29 ( 32 / 4 :29 ( 31 / 11 :15 ( 35 / 28 :20 ( 2 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 25 / 40 :29 ( 37 / 3 :27 ( 8 / 39 ) ) ) :29-of ( 33 / 22 ) ) ) ) SEP ( 24 / 9 :29 ( 19 / 4 :29 ( 36 / 11 :15 ( 30 / 28 :20 ( 7 / 20 :1 16 :14 38 :0 18 ) :10 26 ) :29 ( 5 / 40 :29 ( 17 / 3 :27 ( 13 / 39 ) ) ) :29-of ( 12 / 22 ) ) ) )
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Reference:  34 24 | 32 19 | 31 36 | 33 12 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Hypothesis: 34 24 | 32 19 | 31 36 | 35 30 | 2 7 | 25 5 | 37 17 | 8 13 | 33 12
2022-01-18 18:54:12,888 - INFO - joeynmt.training - Example #1
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Source:     ( 13 / 31 :49 ( 35 / 54 :55 ( 65 / 33 :52 ( 32 / 60 ) :64 8 :27 12 :27 17 :27 21 ) ) :34 ( 8 / 29 ) :44 ( 12 / 38 ) :39 ( 17 / 20 ) :69 ( 21 / 15 ) :47-of ( 19 / 5 :55-of ( 71 / 28 ) :55-of ( 14 / 11 ) :55-of ( 56 / 62 ) :43-of ( 16 / 4 :55 ( 22 / 57 :55 ( 72 / 40 :52 ( 66 / 48 ) ) :68 ( 36 / 31 :49 ( 30 / 2 ) :34 ( 26 / 2 ) ) ) ) ) ) SEP ( 58 / 28 :55 ( 53 / 5 :47 ( 0 / 31 :49 ( 7 / 54 :55 ( 50 / 33 :52 ( 74 / 60 ) :24-of 1 :55-of 51 :55-of 41 :55-of 46 ) ) :34 ( 1 / 29 ) :44 ( 51 / 38 ) :39 ( 41 / 67 ) :69 ( 46 / 15 ) ) :25 ( 73 / 4 :43 53 :55 ( 42 / 57 :55 ( 10 / 40 :52 ( 37 / 48 ) ) :68 ( 23 / 31 :49 ( 63 / 2 ) :34 ( 70 / 6 ) ) ) ) :55-of ( 61 / 11 ) :55-of ( 59 / 62 ) ) )
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Reference:  13 0 | 19 53 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 23 | 30 63 | 26 70 | 35 7 | 65 50 | 32 74 | 8 1 | 12 51 | 17 41 | 21 46
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Hypothesis: 13 6 | 35 50 | 65 53 | 32 74 | 8 46 | 12 41 | 17 51 | 20 67 | 19 0 | 71 58 | 14 61 | 56 59 | 16 73 | 22 42 | 72 10 | 66 37 | 36 None | 30 23 | 26 63
2022-01-18 18:54:12,888 - INFO - joeynmt.training - Example #2
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Source:     ( 8 / 29 :20 ( 23 / 13 :32 ( 50 / 33 ) :32 ( 37 / 18 ) :25 ( 4 / 10 :36 ( 11 / 36 :20 15 :41 49 ) :9 3 ) :17 ( 21 / 14 :43 ( 42 / 12 :34 ( 39 / 38 :32 ( 22 / 27 ) ) :31 ( 19 / 0 ) ) ) ) ) SEP ( 24 / 13 :32 ( 46 / 33 ) :17 ( 2 / 14 :43 ( 47 / 12 :34 ( 6 / 38 :32 ( 5 / 27 ) ) :31 ( 48 / 0 ) ) ) :26-of ( 30 / 45 :43 ( 40 / 10 :36 ( 16 / 36 :20 15 :41 49 ) :34-of 2 :9 3 ) ) )
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Reference:  8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:54:12,888 - INFO - joeynmt.training - 	Hypothesis: 8 None | 23 24 | 50 46 | 37 None | 4 40 | 11 16 | 21 2 | 42 47 | 39 6 | 22 5 | 19 48
2022-01-18 18:54:12,888 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    79000: bleu:  52.35, loss: 158372.1719, ppl:   2.6740, duration: 241.2751s
2022-01-18 18:54:31,626 - INFO - joeynmt.training - Epoch  30, Step:    79100, Batch Loss:    12.507953, Tokens per Sec:     3558, Lr: 0.000200
2022-01-18 18:54:50,455 - INFO - joeynmt.training - Epoch  30, Step:    79200, Batch Loss:     8.735082, Tokens per Sec:     3621, Lr: 0.000200
2022-01-18 18:55:09,134 - INFO - joeynmt.training - Epoch  30, Step:    79300, Batch Loss:    11.410407, Tokens per Sec:     3648, Lr: 0.000200
2022-01-18 18:55:27,825 - INFO - joeynmt.training - Epoch  30, Step:    79400, Batch Loss:    12.542036, Tokens per Sec:     3642, Lr: 0.000200
2022-01-18 18:55:46,477 - INFO - joeynmt.training - Epoch  30, Step:    79500, Batch Loss:    13.434518, Tokens per Sec:     3599, Lr: 0.000200
2022-01-18 18:56:05,232 - INFO - joeynmt.training - Epoch  30, Step:    79600, Batch Loss:    19.230074, Tokens per Sec:     3690, Lr: 0.000200
2022-01-18 18:56:19,692 - INFO - joeynmt.training - Epoch  30: total training loss 36551.46
2022-01-18 18:56:19,693 - INFO - joeynmt.training - Training ended after  30 epochs.
2022-01-18 18:56:19,693 - INFO - joeynmt.training - Best validation result (greedy) at step    76000:  52.39 eval_metric.
2022-01-18 18:56:19,714 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 8192
2022-01-18 18:56:19,715 - INFO - joeynmt.prediction - Loading model from models/B_ablation/76000.ckpt
2022-01-18 18:56:19,958 - INFO - joeynmt.model - Building an encoder-decoder model...
2022-01-18 18:56:20,328 - INFO - joeynmt.model - Enc-dec model built.
2022-01-18 18:56:20,431 - INFO - joeynmt.prediction - Decoding on dev set (~/AMR_ablation/data/B_data/dev/b_dev.tgt)...
2022-01-18 19:04:01,623 - INFO - joeynmt.prediction -  dev bleu[13a]:  54.01 [Beam search decoding with beam size = 5 and alpha = 1.0]
2022-01-18 19:04:01,663 - INFO - joeynmt.prediction - Translations saved to: models/B_ablation/00076000.hyps.dev
2022-01-18 19:04:01,664 - INFO - joeynmt.prediction - Decoding on test set (~/AMR_ablation/data/B_data/test/b_test.tgt)...
2022-01-18 19:05:21,538 - INFO - joeynmt.prediction - No references given for test -> no evaluation.
2022-01-18 19:05:21,550 - INFO - joeynmt.prediction - Translations saved to: models/B_ablation/00076000.hyps.test
